{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Class indices in the range [0, C) where CC is the number of classes;\n",
    "if ignore_index is specified, this loss also accepts this class index (this index may not necessarily be in the class range).\n",
    "The unreduced (i.e. with reduction set to 'none') loss for this case can be described as:\n",
    "\n",
    "$$ l(X, \\mathbf{y})=L=\\left\\{l_{1}, \\ldots, l_{N}\\right\\}^{\\top}, \\quad l_{n}=-\\mathbf{w}_{\\mathbf{y}_{n}} \\log \\frac{\\exp \\left(X_{n, \\mathbf{y}_{n}}\\right)}{\\sum_{c=1}^{C} \\exp \\left(X_{n, c}\\right)} $$\n",
    "\n",
    "where $X$ is the input, $\\mathbf{y}$ is the target, $\\mathbf{w}$ is the weight, $C$ is the number of classes,\n",
    "and $N$ spans the minibatch dimension as well as $ d_{1}, \\ldots, d_{k}$ for the K-dimensional case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Input: $(N, C)$(where $C$ = number of classes\n",
    "\n",
    "* Target: $(N) $ where each value is $ 0 \\leq \\text{targets}[i] \\leq C $\n",
    "\n",
    "* Output: If reduction is ‘none’, same shape as the target. Otherwise, scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.,  1.,  2.],\n        [ 3.,  4.,  5.],\n        [ 6.,  7.,  8.],\n        [ 9., 10., 11.]])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = torch.arange(12, dtype=torch.float32).reshape(4, 3)\n",
    "y_target = torch.tensor([0, 2, 1, 2])\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.1576)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(x_input, y_target,\n",
    "                # 类别权重参考NLLLoss\n",
    "                weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.1576)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss()(input=x_input,\n",
    "                      target=y_target)  # ★★★★★要求:整数向量(最小值为0,最大值为input.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4076, 0.4076, 1.4076, 0.4076])\n",
      "tensor(1.1576)\n",
      "tensor(4.6304)\n"
     ]
    }
   ],
   "source": [
    "print(nn.CrossEntropyLoss(reduction='none')(x_input, y_target))\n",
    "print(nn.CrossEntropyLoss(reduction='mean')(x_input, y_target))  # 默认reduction='mean',参考BCELos\n",
    "print(nn.CrossEntropyLoss(reduction='sum')(x_input, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6304)\n",
      "tensor(9.2608)\n"
     ]
    }
   ],
   "source": [
    "loss_sum = nn.CrossEntropyLoss(reduction='sum')(input=x_input,\n",
    "                                                target=y_target)\n",
    "\n",
    "loss_sum_double = nn.CrossEntropyLoss(reduction='sum')(input=x_input.repeat(2, 1),\n",
    "                                                       target=y_target.repeat(2))\n",
    "print(loss_sum)\n",
    "print(loss_sum_double)  # loss_sum的两倍"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0000, 0.4076, 1.4076, 0.4076])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target为0的损失直接为0(NLP任务中可指定ignore_index填充项)\n",
    "'''\n",
    "ignore_index (int, optional) –\n",
    "    Specifies a target value that is ignored and does not contribute to the input gradient.\n",
    "    When size_average is True, the loss is averaged over non-ignored targets.\n",
    "    Note that ignore_index is only applicable when the target contains class indices.\n",
    "'''\n",
    "nn.CrossEntropyLoss(reduction='none', ignore_index=0)(x_input,\n",
    "                                                      y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "上式计算步骤如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.4076, -1.4076, -0.4076],\n        [-2.4076, -1.4076, -0.4076],\n        [-2.4076, -1.4076, -0.4076],\n        [-2.4076, -1.4076, -0.4076]])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsoftmax_output = F.log_softmax(x_input, dim=1)  # 注意:dim=1\n",
    "logsoftmax_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1576)\n"
     ]
    }
   ],
   "source": [
    "nlloss_output = F.nll_loss(logsoftmax_output, y_target)\n",
    "print(nlloss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0886a02735466d80c36da7d0d184a8055779d3e497a063b4720b0317b8699033"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}