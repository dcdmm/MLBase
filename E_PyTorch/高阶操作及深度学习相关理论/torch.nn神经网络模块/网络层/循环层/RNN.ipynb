{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 30])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 100)\n",
    "\n",
    "rnn = nn.RNN(input_size=100, hidden_size=30)\n",
    "\n",
    "out, h = rnn(x)  # 单层,序列长度为1\n",
    "\n",
    "print(out.shape)\n",
    "print(out - h)  # 此时out=h;即相当于RNNCell(只输出h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 10]) torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=100,  # The number of expected features in the input x\n",
    "             hidden_size=10,  # 隐含变量的维度大小(即权重矩阵W_{ih}、W_{hh}中的hidden_size)\n",
    "             num_layers=2,  # 循环神经网络层数.若num_layers=2,则第2层的输入是第1层的输出(层与层之间的参数相互独立)\n",
    "             nonlinearity='tanh',  # 非线性激活函数类型,也可以设置为'relu'.默认nonlinearity='tanh'\n",
    "             bias=True,  # 是否添加偏置.默认bias=True\n",
    "             batch_first=False,  # 如果batch_first=True,则输入张量大小为(N,T,C),而不是(T,N,C).默认batch_first=False\n",
    "             dropout=0.5)  # 如果这个值非零,则在循环神经网络最后输出的基础上加上丢弃层,丢弃的概率由输入的dropout确定.默认dropout=0\n",
    "\n",
    "x = torch.randn(20, 3, 100)  # 输入的默认形状为(T,N,C),其中T为序列的长度,N为min-batch的大小,C为输入的特征数目\n",
    "h_0 = torch.ones((2, 3, 10))  # (L*D, N, hidden_size),其中L为循环神经网络层数,D为1(单向)或2(双向)\n",
    "out, h = rnn(x, hx=h_0)  # 自定义h_0,默认h_0为全0张量\n",
    "# out.shape=(T, N, D*hidden_size);h.shape=(L*D, N, hidden_size)\n",
    "# 若设置batch_first=True===>out.shape=(N, T, D*hidden_size);h.shape不变,仍为(L*D, N, hidden_size)\n",
    "print(out.shape, h.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([10, 100])\n",
      "weight_hh_l0   shape= torch.Size([10, 10])\n",
      "bias_ih_l0   shape= torch.Size([10])\n",
      "bias_hh_l0   shape= torch.Size([10])\n",
      "weight_ih_l1   shape= torch.Size([10, 10])\n",
      "weight_hh_l1   shape= torch.Size([10, 10])\n",
      "bias_ih_l1   shape= torch.Size([10])\n",
      "bias_hh_l1   shape= torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "~RNN.weight_ih_l[k] –\n",
    "    the learnable input-hidden weights of the k-th layer, of shape (hidden_size, input_size) for k = 0.\n",
    "    Otherwise, the shape is (hidden_size, num_directions * hidden_size)\n",
    "~RNN.weight_hh_l[k] –\n",
    "    the learnable hidden-hidden weights of the k-th layer, of shape (hidden_size, hidden_size)\n",
    "~RNN.bias_ih_l[k] –\n",
    "    the learnable input-hidden bias of the k-th layer, of shape (hidden_size)\n",
    "~RNN.bias_hh_l[k] –\n",
    "    the learnable hidden-hidden bias of the k-th layer, of shape (hidden_size)\n",
    "'''\n",
    "for name, param in rnn.named_parameters():\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 30]) torch.Size([4, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "b_run = nn.RNN(input_size=100, hidden_size=15, num_layers=2,\n",
    "               bidirectional=True)  # 是否为设置为双向循环神经网络,默认为False\n",
    "\n",
    "# 此时b_h_0为正向hx(shape=(2, 3, 15))和反向hx(shape=(2, 3, 15))在第0个维度的拼接\n",
    "b_h_0 = torch.ones((4, 3, 15))\n",
    "\n",
    "# ★★★★★b_out中T(训练的长度)信息仍然保留\n",
    "b_out, b_h = b_run(x, hx=b_h_0)\n",
    "# b_out为每个序列最后一层的输出(双向则第二维度*2);b_h为最后一个序列每层的输出(双向则第0维度*2)\n",
    "print(b_out.shape, b_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([15, 100])\n",
      "weight_hh_l0   shape= torch.Size([15, 15])\n",
      "bias_ih_l0   shape= torch.Size([15])\n",
      "bias_hh_l0   shape= torch.Size([15])\n",
      "weight_ih_l0_reverse   shape= torch.Size([15, 100])\n",
      "weight_hh_l0_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l0_reverse   shape= torch.Size([15])\n",
      "bias_hh_l0_reverse   shape= torch.Size([15])\n",
      "weight_ih_l1   shape= torch.Size([15, 30])\n",
      "weight_hh_l1   shape= torch.Size([15, 15])\n",
      "bias_ih_l1   shape= torch.Size([15])\n",
      "bias_hh_l1   shape= torch.Size([15])\n",
      "weight_ih_l1_reverse   shape= torch.Size([15, 30])\n",
      "weight_hh_l1_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l1_reverse   shape= torch.Size([15])\n",
      "bias_hh_l1_reverse   shape= torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for name, param in b_run.named_parameters():\n",
    "    '''正向和反向两个方向的循环神经网络有各自的相互独立的参数'''\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0664,  0.2473,  0.1546, -0.0315,  0.0291,  0.1714,  0.0860,  0.0098,\n         -0.2483, -0.0639, -0.1112, -0.0952,  0.2200, -0.0205, -0.0586],\n        [ 0.0651,  0.0607, -0.0787,  0.1104, -0.0989, -0.0302,  0.1479, -0.1122,\n          0.0369,  0.0201,  0.0712, -0.0413,  0.2326,  0.0024,  0.1086],\n        [ 0.1771,  0.0170, -0.0488, -0.1944, -0.1664,  0.0313, -0.0879,  0.0117,\n         -0.0224,  0.2021, -0.0964, -0.1600,  0.1889, -0.0350,  0.1536],\n        [-0.0929, -0.1903, -0.0715, -0.1468,  0.1804,  0.1231,  0.2238, -0.0177,\n         -0.1376, -0.1275, -0.1319, -0.0322, -0.0056,  0.0703, -0.1925],\n        [-0.0739, -0.0251,  0.2277, -0.2348, -0.1723, -0.2342, -0.1074, -0.0144,\n          0.1352, -0.0979, -0.0080,  0.2348,  0.0218,  0.2503,  0.1275],\n        [-0.2253, -0.2495,  0.1496,  0.1250,  0.1055, -0.1759,  0.2489,  0.0976,\n         -0.1971,  0.1816, -0.1607, -0.2418, -0.1232, -0.2426,  0.1417],\n        [-0.2137, -0.2436,  0.2119, -0.1771,  0.0787, -0.1323,  0.2321, -0.1492,\n          0.1263, -0.2502,  0.1844, -0.0877,  0.0099,  0.0994, -0.2520],\n        [ 0.1457,  0.0219,  0.0744, -0.2111, -0.0916,  0.1721, -0.0441,  0.0494,\n          0.0566,  0.1161, -0.1548,  0.0207,  0.1406, -0.1254,  0.2285],\n        [ 0.0583,  0.1292,  0.2517, -0.0355,  0.1196, -0.2124, -0.0782, -0.0585,\n         -0.0229,  0.2546, -0.2400,  0.0203,  0.0332,  0.2565,  0.2053],\n        [-0.1028,  0.2482,  0.2133,  0.2277, -0.0776,  0.0560,  0.2198,  0.1722,\n          0.1863, -0.0739, -0.2225,  0.1193,  0.2235,  0.0655,  0.2344],\n        [ 0.1905,  0.2561,  0.1541,  0.2483, -0.1377, -0.0612,  0.0827,  0.0606,\n         -0.0012,  0.1546, -0.0780, -0.0273,  0.2483,  0.2550,  0.0246],\n        [ 0.1370, -0.0792,  0.1173, -0.0828, -0.0177,  0.0488, -0.2231,  0.1061,\n          0.2240,  0.1616, -0.0388,  0.0085,  0.2581, -0.1080,  0.1034],\n        [ 0.1688, -0.0914,  0.0806, -0.2123, -0.0272,  0.0326,  0.0304,  0.1226,\n         -0.2127, -0.2475, -0.1424, -0.0846,  0.0656,  0.0465,  0.2214],\n        [ 0.0863,  0.2461, -0.0084,  0.2303,  0.1401, -0.1002,  0.0744, -0.0782,\n          0.2246, -0.1395,  0.0470, -0.0695, -0.1534,  0.2428,  0.1881],\n        [ 0.2402, -0.0709, -0.0192,  0.0374,  0.1040, -0.1927,  0.2084,  0.1495,\n         -0.1109,  0.2409, -0.0111, -0.0735,  0.0047,  0.2295, -0.0861]],\n       requires_grad=True)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_hh_l0  # all the weights and biases are initialized from U(-\\sqrt{k}, \\sqrt{k}), where k=1/hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 7.3919e-02,  1.6725e-01,  1.7216e-01, -2.1449e-01, -1.2055e-01,\n         -1.0914e-01, -1.5915e-01,  7.6740e-02, -6.1194e-02, -8.4321e-02,\n          4.7601e-02, -1.2521e-01,  8.4071e-02, -6.5983e-02,  5.8618e-02,\n         -5.5857e-02, -2.5500e-01, -7.3008e-02,  8.7387e-02,  4.2918e-02,\n         -2.1365e-01, -2.2813e-01, -1.5030e-01, -4.8744e-02, -2.0532e-01,\n          1.5509e-01,  1.8230e-01, -3.2281e-02,  1.3973e-01,  2.2606e-01],\n        [-2.2368e-01, -1.0966e-01,  2.1165e-01, -1.9476e-01,  2.3308e-01,\n          2.2298e-04, -1.0636e-01, -7.1339e-02,  1.5072e-01,  2.3525e-01,\n         -7.4957e-02, -8.4542e-02, -4.1271e-02,  8.6316e-02, -2.5298e-01,\n          7.0691e-02,  6.1845e-02, -1.9606e-01,  2.0044e-01,  2.3732e-01,\n          1.8926e-01, -1.4666e-01,  1.6441e-01,  2.1130e-01, -2.2511e-01,\n         -1.9511e-01, -4.4169e-02,  2.3833e-01,  5.8038e-02,  2.2865e-01],\n        [-1.9751e-01, -2.5524e-01, -4.8606e-02, -1.2614e-02, -1.4625e-01,\n          3.6212e-02, -3.2268e-02, -1.3621e-01, -8.5093e-02,  3.4199e-02,\n         -1.9643e-01, -1.1042e-01,  6.5799e-02, -1.8286e-01,  1.2811e-01,\n          1.3542e-01, -1.8333e-01,  1.1707e-01,  1.6528e-01,  1.4617e-01,\n          2.3827e-01,  9.7010e-02, -7.8223e-02,  2.1502e-01,  2.4582e-01,\n         -1.3067e-01, -1.6473e-01,  1.9241e-01, -3.2960e-02, -1.2340e-02],\n        [-1.4616e-01,  1.9183e-01, -1.9669e-01, -8.4182e-02, -2.2861e-01,\n         -6.9412e-02, -1.6674e-01, -2.2082e-01,  6.4952e-02,  1.9586e-01,\n         -2.2740e-01, -2.7904e-02,  2.5238e-01,  6.8645e-02, -7.9113e-02,\n          7.4811e-02, -1.7062e-01, -2.3045e-01,  2.4802e-01, -5.6661e-02,\n          1.4415e-01,  2.0186e-01,  7.4425e-02, -3.1233e-02, -1.8740e-01,\n          1.4483e-01,  9.6015e-02, -4.8728e-02, -1.8136e-01, -2.5800e-01],\n        [ 4.4451e-02, -3.5019e-02, -1.8592e-03,  1.7532e-01, -5.5400e-02,\n          2.4267e-03, -4.0077e-02,  1.8869e-01,  3.1113e-02, -9.4523e-02,\n         -2.5629e-01,  1.9662e-01,  2.2653e-01,  4.3952e-02, -1.5315e-01,\n         -1.9953e-01, -2.4063e-01, -1.9885e-01,  2.4235e-01, -1.3655e-01,\n          9.5912e-02,  6.4740e-04,  1.3607e-01,  1.0227e-01,  1.2482e-01,\n         -1.9766e-01,  2.0556e-01, -1.4573e-01,  4.1816e-02, -1.4988e-01],\n        [-3.5192e-02, -2.1904e-01,  2.1868e-01,  6.1057e-02,  4.1382e-02,\n         -3.6521e-02, -3.2052e-02,  1.6630e-01,  1.2800e-01,  1.2173e-01,\n          7.0728e-02,  1.2240e-01, -1.4097e-01,  1.0437e-02,  2.5218e-01,\n          1.3188e-01, -9.4642e-02,  1.2213e-01, -1.0573e-01, -1.7643e-01,\n         -4.1767e-02,  1.0136e-01,  1.7307e-01, -2.2266e-01, -2.5675e-01,\n         -1.4396e-01, -9.1527e-02,  2.1888e-01,  4.3353e-03, -1.0480e-01],\n        [ 1.8129e-01,  1.0965e-01, -2.3609e-01, -1.1692e-01, -1.7826e-01,\n          8.7850e-03, -3.4116e-02, -1.4249e-01,  2.5004e-01,  3.5641e-03,\n          1.6946e-01, -7.4023e-02, -1.7172e-02, -2.4689e-01,  1.6423e-01,\n         -1.1237e-02,  7.9647e-02, -1.1112e-01, -1.6305e-01,  2.0014e-01,\n         -3.8082e-02, -8.9270e-02, -3.8233e-02, -2.2811e-01,  7.0903e-02,\n          4.4566e-02,  5.7293e-02,  8.7351e-02,  6.1962e-02,  1.8154e-01],\n        [-1.7769e-01, -2.2261e-01, -5.7212e-02, -2.0349e-01, -1.5202e-01,\n         -2.0917e-01,  2.4931e-01, -1.1912e-01,  2.0152e-01,  8.5418e-02,\n          5.1144e-02, -1.0999e-01, -4.5192e-02, -1.6643e-01,  8.5397e-02,\n          1.0348e-01, -8.5551e-02,  1.9914e-01, -5.9260e-02, -2.9042e-02,\n          1.1308e-01, -1.0972e-01, -2.1119e-01, -7.7599e-02, -1.5311e-01,\n         -2.3417e-01, -1.2956e-01,  1.4677e-01,  6.3786e-02, -1.7793e-01],\n        [-6.6583e-02,  3.5303e-02,  2.0616e-02,  2.2870e-01, -1.3404e-01,\n          2.3857e-02, -2.0315e-01, -3.9841e-02, -1.9510e-01,  1.9666e-01,\n         -2.4865e-01, -1.7387e-01, -7.8190e-03, -1.0622e-01,  2.4267e-01,\n         -1.5000e-02, -1.5771e-01,  7.1556e-02, -1.8955e-01, -1.0161e-01,\n         -2.2632e-01,  1.4399e-01, -1.2966e-02, -7.8989e-02,  1.1675e-01,\n         -1.4003e-01, -2.0619e-01,  1.4894e-01, -2.2685e-01, -3.4271e-02],\n        [ 1.8082e-01,  8.1561e-02, -9.0971e-02,  2.4696e-01, -2.2228e-01,\n         -1.7899e-01, -1.4254e-02,  1.1661e-01,  2.3880e-01, -2.8640e-02,\n         -1.6835e-02, -1.2537e-01,  1.6590e-01,  1.3498e-01, -1.5739e-01,\n         -1.3630e-01,  3.7165e-02, -5.0299e-02, -2.1075e-01, -1.6362e-01,\n         -2.0798e-01,  1.2310e-01,  6.6457e-02,  1.3056e-01,  1.3798e-01,\n          1.3066e-02,  1.9229e-01, -6.1527e-02,  8.4389e-02,  5.7524e-03],\n        [-2.2703e-01,  2.2104e-01,  2.2512e-01, -2.2262e-01,  1.6405e-01,\n          2.0462e-01, -2.3663e-01,  1.1960e-02, -1.5435e-01,  1.7837e-01,\n          2.5737e-01, -8.9657e-02, -2.3617e-01, -1.1918e-01,  5.7637e-02,\n          1.9562e-01,  1.5213e-01, -4.2694e-02, -1.9537e-01,  1.8895e-01,\n          2.0044e-01, -6.8056e-02,  1.8971e-01,  6.0318e-02,  1.6130e-01,\n          2.0834e-01,  2.5343e-01, -1.7002e-01, -5.4327e-02, -1.6779e-01],\n        [ 3.1773e-02,  1.0958e-01,  2.1108e-01, -2.2179e-01,  4.7394e-02,\n          1.3718e-01,  2.2427e-01, -1.5589e-01,  4.0898e-04, -1.7680e-01,\n          2.3931e-01, -2.1100e-01, -1.0673e-01, -1.4303e-01, -3.0843e-02,\n         -1.8318e-01,  8.8941e-02, -6.6534e-02,  2.3842e-01, -1.2767e-01,\n          1.9598e-01, -1.9099e-01, -2.3128e-01,  9.9158e-02, -2.4737e-01,\n          6.8412e-02, -1.0724e-01,  2.0835e-01, -2.4330e-01,  2.3483e-01],\n        [-2.5524e-02,  1.4949e-01, -2.2074e-01,  1.3217e-01, -2.5134e-01,\n         -4.9541e-03,  1.1613e-01, -2.5781e-01,  5.0157e-02, -1.8424e-01,\n         -1.5304e-01,  9.2188e-02,  2.0981e-01, -7.5315e-02, -3.0936e-02,\n          1.8754e-01, -2.0980e-01, -2.1373e-01,  2.0577e-02,  2.3268e-01,\n          5.5086e-02, -2.3049e-01,  1.8646e-01, -1.0656e-01, -1.8077e-01,\n          2.5466e-01,  1.1368e-01, -2.3433e-01,  2.1979e-01,  1.0063e-01],\n        [ 2.0644e-01, -1.2736e-01,  1.5716e-01,  1.9777e-01,  1.8077e-01,\n          1.9415e-01, -4.8394e-02,  1.1417e-01, -5.7973e-03,  1.9530e-01,\n         -1.8988e-01, -2.0956e-01, -1.4406e-01,  9.9905e-02,  1.5525e-01,\n          1.6283e-01, -5.2453e-02, -1.1800e-01,  2.9180e-02, -1.9328e-01,\n          1.7488e-01, -1.2905e-02, -2.3650e-01,  1.4255e-01,  2.4787e-01,\n          1.1059e-01, -2.3023e-01, -1.9742e-01,  2.0614e-02,  2.0672e-01],\n        [ 2.5802e-01, -1.8278e-01, -2.1656e-01,  1.9237e-01, -6.7491e-02,\n          2.2606e-01,  1.1089e-02,  1.8914e-01,  8.4299e-02, -9.4516e-02,\n         -7.7557e-02, -8.5620e-02,  9.2812e-02, -1.1047e-01,  1.9662e-01,\n         -1.2526e-01, -7.1587e-02, -1.8643e-01,  8.9256e-02, -2.1674e-01,\n          3.8572e-02,  2.4620e-01, -1.2975e-01,  4.6135e-02,  8.5465e-02,\n         -1.0472e-01,  2.3979e-01,  2.3996e-01, -1.9430e-01, -9.1956e-02]],\n       requires_grad=True)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_ih_l1  # 参数全部都requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}