{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hanlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SIGHAN2005_PKU_CONVSEG': 'https://file.hankcs.com/hanlp/tok/sighan2005-pku-convseg_20200110_153722.zip',\n",
       " 'SIGHAN2005_MSR_CONVSEG': 'https://file.hankcs.com/hanlp/tok/convseg-msr-nocrf-noembed_20200110_153524.zip',\n",
       " 'CTB6_CONVSEG': 'https://file.hankcs.com/hanlp/tok/ctb6_convseg_nowe_nocrf_20200110_004046.zip',\n",
       " 'PKU_NAME_MERGED_SIX_MONTHS_CONVSEG': 'https://file.hankcs.com/hanlp/tok/pku98_6m_conv_ngram_20200110_134736.zip',\n",
       " 'LARGE_ALBERT_BASE': 'https://file.hankcs.com/hanlp/tok/large_corpus_cws_albert_base_20211228_160926.zip',\n",
       " 'SIGHAN2005_PKU_BERT_BASE_ZH': 'https://file.hankcs.com/hanlp/tok/sighan2005_pku_bert_base_zh_20201231_141130.zip',\n",
       " 'COARSE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/coarse_electra_small_20220616_012050.zip',\n",
       " 'FINE_ELECTRA_SMALL_ZH': 'https://file.hankcs.com/hanlp/tok/fine_electra_small_20220615_231803.zip',\n",
       " 'CTB9_TOK_ELECTRA_SMALL': 'https://file.hankcs.com/hanlp/tok/ctb9_electra_small_20220215_205427.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_20220426_111949.zip',\n",
       " 'CTB9_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/ctb9_tok_electra_base_crf_20220426_161255.zip',\n",
       " 'MSR_TOK_ELECTRA_BASE_CRF': 'http://download.hanlp.com/tok/extra/msra_crf_electra_base_20220507_113936.zip',\n",
       " 'UD_TOK_MMINILMV2L6': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L6_no_space_mul_20220619_091824.zip',\n",
       " 'UD_TOK_MMINILMV2L12': 'https://file.hankcs.com/hanlp/tok/ud_tok_mMiniLMv2L12_no_space_mul_20220619_091159.zip'}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有pre-trained tokenizers\n",
    "hanlp.pretrained.tok.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duanm\\anaconda3\\envs\\nlp_hanlp\\lib\\site-packages\\hanlp\\common\\torch_component.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model_.load_state_dict(torch.load(filename, map_location='cpu'), strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hanlp.components.tokenizers.transformer.TransformerTaggingTokenizer at 0x22b9b8db130>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "tok = hanlp.load(\"https://file.hankcs.com/hanlp/tok/coarse_electra_small_20220220_013548.zip\")\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['商品', '和', '服务', '。'], ['晓美焰', '来到', '北京立方庭', '参观', '自然语义科技公司']]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 执行分词\n",
    "tok(['商品和服务。', '晓美焰来到北京立方庭参观自然语义科技公司'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.dict_combine, tok.dict_force  # 默认tok.dict_combine和tok.dict_force均为None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['首相', '和', '川', '普通', '电话']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok(\"首相和川普通电话\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['首相', '和', '川普', '通', '电话'],\n",
       " ['银', '川普', '通人', '与', '川普', '通', '电话', '讲', '四', '川普', '通话']]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 强制模式\n",
    "tok.dict_force = {'川普'}\n",
    "tok(\n",
    "    [\"首相和川普通电话\",  # 川普正常被分词\n",
    "     \"银川普通人与川普通电话讲四川普通话\"  # 匹配不该分出来的自定义词语(导致歧义)\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['首相', '和', '川普', '通', '电话'],\n",
       " ['银川', '普通人', '与', '川普', '通', '电话', '讲', '四川', '普通话']]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 强制校正模式(对每种可能产生歧义的语境,截取一个片段执行校正)\n",
    "tok.dict_force = {'川普通电话': ['川普', '通', '电话']}  \n",
    "tok([\"首相和川普通电话\", \"银川普通人与川普通电话讲四川普通话\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['首相', '和', '川普', '通', '电话', '，', '川普', '是', '美国', '总统', '。'], ['银川', '普通人', '与', '川普', '通', '电话', '讲', '四川', '普通话', '，', '川普', '是', '美国', '总统', '。']]\n"
     ]
    }
   ],
   "source": [
    "tok.dict_force = tok.dict_combine = None\n",
    "# 提供给神经网络足够的上下文线索,告诉神经网络\"川普是美国总统\"\n",
    "print(tok([\n",
    "    # 虽然词典对\"川普\"没有施加任何影响,但是更丰富的上下文促进了神经网络对语境的理解,使其得出了正确的结果\n",
    "    \"首相和川普通电话，川普是美国总统。\",\n",
    "    \"银川普通人与川普通电话讲四川普通话，川普是美国总统。\"\n",
    "]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['首相', '和', '川普', '通', '电话', '，', '川普', '是', '美国总统', '。'],\n",
       " ['美国', '总统筹部', '部长', '是', '谁', '？']]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.dict_force = None\n",
    "tok.dict_combine = None\n",
    "# 合并模式(dict_combine会在统计模型的分词结果上执行最长匹配并合并匹配到的词条)\n",
    "tok.dict_combine = {'美国总统'}\n",
    "tok([\n",
    "    # 初始分词结果为[..., \"美国\", \"总统\", ...] ---合并后为---> [..., \"美国总统\", ...]\n",
    "    \"首相和川普通电话，川普是美国总统。\",\n",
    "    # 初始分词结果为[\"美国\", \"总统筹部\", ...] ---不会被合共---> [\"美国\", \"总统筹部\", ...] \n",
    "    \"美国总统筹部部长是谁？\"\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['如何', '评价', 'iPad Pro', '？', 'iPad  Pro', '有', '2个空格']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.dict_combine = {\n",
    "    # 有空格、制表符等(Transformer tokenizer去掉的字符)的词语需要用tuple的形式提供\n",
    "    ('iPad', 'Pro'),\n",
    "    '2个空格'\n",
    "}\n",
    "\n",
    "# 初始分词结果为[..., 'iPad', 'Pro', ..., 'iPad', 'Pro',...] ---合并后为---> [..., 'iPad  Pro', ..., 'iPad  Pro',...] \n",
    "tok(\"如何评价iPad Pro ？iPad  Pro有2个空格\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2021', 0, 4], ['年', 5, 6], ['HanLPv2.1', 7, 16], ['为', 17, 18], ['生产', 18, 20], ['环境', 20, 22], ['带来', 22, 24], ['次', 24, 25], ['世代', 25, 27], ['最', 27, 28], ['先进', 28, 30], ['的', 30, 31], ['多', 31, 32], ['语种', 32, 34], ['NLP', 34, 37], ['技术', 37, 39], ['。', 39, 40]]\n"
     ]
    }
   ],
   "source": [
    "tok.config.output_spans = True  # 输出单词位置\n",
    "sent = '2021 年\\nHanLPv2.1 为生产环境带来次世代最先进的多语种NLP技术。'\n",
    "word_offsets = tok(sent)\n",
    "print(word_offsets)\n",
    "tok.config.output_spans = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hanlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
