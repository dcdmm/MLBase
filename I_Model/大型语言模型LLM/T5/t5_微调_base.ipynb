{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8bc64c-fa83-47f1-8612-f5e14532dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7adfa9-b833-499b-a8dc-5eed854e4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    model_name = '../all_models/t5-base/'\n",
    "    text_max_len = 768\n",
    "    summary_max_len = 256\n",
    "    batch_size = 8\n",
    "    epochs = 5\n",
    "    verbose = 100\n",
    "    lr = 2e-5  # 学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c71eb3-4d5a-485c-b288-89ffe477057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"PyTorch随机数种子设置大全\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)  # CPU上设置随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 当前GPU上设置随机种子\n",
    "        # A bool that, if True, causes cuDNN to only use deterministic convolution algorithms.\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        # torch.cuda.manual_seed_all(seed) # 所有GPU上设置随机种子\n",
    "\n",
    "\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50262af5-9b5f-47f1-a479-ae49be996486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1712e194-e0b5-4d9e-a4a9-3df0b14e31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14732 818\n",
      "94 56\n",
      "Amanda: I baked  cookies. Do you want some?\n",
      "Jerry: Sure!\n",
      "Amanda: I'll bring you tomorrow :-)\n",
      "\n",
      "Amanda baked cookies and will bring Jerry some tomorrow.\n"
     ]
    }
   ],
   "source": [
    "class Dataset(Data.Dataset):\n",
    "    \"\"\"定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path):\n",
    "        with open(dataset_path) as f:\n",
    "            self.dataset = json.loads(f.read())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"定义索引方式\"\"\"\n",
    "        text = self.dataset[i]['dialogue']\n",
    "        summary = self.dataset[i]['summary']\n",
    "        return text, summary\n",
    "\n",
    "\n",
    "dataset_train = Dataset(\"../huggingface_dataset_samsum/train.json\")\n",
    "dataset_valid = Dataset(\"../huggingface_dataset_samsum/val.json\")\n",
    "\n",
    "print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "for text_, summary_ in dataset_train:\n",
    "    # 调用__getitem__方法\n",
    "    print(len(str(text_)), len(str(summary_)))\n",
    "    print(text_, end='\\n\\n')\n",
    "    print(summary_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff42c570-93c9-48a8-a62d-126a5d53a773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n",
      "T5TokenizerFast(name_or_path='../all_models/t5-base/', vocab_size=32100, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n",
      "222903552\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "print(tokenizer.model_input_names)\n",
    "print(tokenizer)\n",
    "\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(CFG.model_name)\n",
    "model_t5 = model_t5.to(device)\n",
    "print(model_t5.num_parameters())\n",
    "\n",
    "# 优化器\n",
    "optimizer_adamw = optim.AdamW(model_t5.parameters(), lr=CFG.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e8e205-e843-4edd-a181-d3369adeda14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842\n",
      "torch.Size([8, 374])\n",
      "torch.Size([8, 374])\n",
      "torch.Size([8, 74])\n"
     ]
    }
   ],
   "source": [
    "def get_collate_fn(tokenizer, text_max_len=512, summary_max_len=256):\n",
    "    \"\"\"返回collate_fun函数(通过闭包函数引入形参)\"\"\"\n",
    "\n",
    "    def collate_fn(data):\n",
    "        prefix = \"summarize: \"\n",
    "\n",
    "        texts = [prefix + i[0] for i in data]\n",
    "        summarys = [i[1] for i in data]\n",
    "\n",
    "        texts_encode = tokenizer(texts,\n",
    "                                 max_length=text_max_len,\n",
    "                                 padding=True,\n",
    "                                 truncation=True,\n",
    "                                 return_tensors='pt')\n",
    "\n",
    "        summarys_encode = tokenizer(text_target=summarys,\n",
    "                                    max_length=summary_max_len,\n",
    "                                    padding=True,\n",
    "                                    truncation=True,\n",
    "                                    return_tensors='pt')\n",
    "\n",
    "        return {\"texts_input_ids\": texts_encode['input_ids'],\n",
    "                \"texts_attention_mask\": texts_encode['attention_mask'],\n",
    "                \"summarys_input_ids\": summarys_encode['input_ids']}\n",
    "\n",
    "    return collate_fn\n",
    "\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(dataset=dataset_valid,\n",
    "                                               batch_size=CFG.batch_size,\n",
    "                                               collate_fn=get_collate_fn(tokenizer, CFG.text_max_len,\n",
    "                                                                         CFG.summary_max_len),\n",
    "                                               shuffle=False,\n",
    "                                               drop_last=False)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                               batch_size=CFG.batch_size,\n",
    "                                               collate_fn=get_collate_fn(tokenizer, CFG.text_max_len,\n",
    "                                                                         CFG.summary_max_len),\n",
    "                                               shuffle=True,\n",
    "                                               drop_last=False)\n",
    "\n",
    "print(len(dataloader_train))\n",
    "\n",
    "for i in dataloader_train:\n",
    "    print(i['texts_input_ids'].shape)  # [batch_size, text_max_len]\n",
    "    print(i['texts_attention_mask'].shape)\n",
    "    print(i['summarys_input_ids'].shape)  # [batch_size, summary_max_len]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029475ee-5cbf-45a0-bd7d-d834ff8a41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    for idx, encode_data in enumerate(dataloader):\n",
    "        # 数据设备切换\n",
    "        input_ids = encode_data['texts_input_ids'].to(device)\n",
    "        attention_mask = encode_data['texts_attention_mask'].to(device)\n",
    "        labels = encode_data['summarys_input_ids'].to(device)\n",
    "        # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "        labels[labels == tokenizer.pad_token_id] = - 100\n",
    "\n",
    "        '''\n",
    "        huggingfae源码:\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)  ### Teacher Forcing \n",
    "        '''\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]  # T5ForConditionalGeneration源码内封装损失函数:CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % CFG.verbose == 0 and idx > 0:\n",
    "            print('| step {:5d} | loss {:8.5f} |'.format(idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3971905-40ec-4b29-9084-76e05e3a5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_blue_score = []\n",
    "    for idx, encode_data in enumerate(dataloader):\n",
    "        # 数据设备切换\n",
    "        input_ids = encode_data['texts_input_ids'].to(device)\n",
    "        attention_mask = encode_data['texts_attention_mask'].to(device)\n",
    "        labels = encode_data['summarys_input_ids'].to(device)\n",
    "\n",
    "        predictions = model.generate(input_ids=input_ids,\n",
    "                                     attention_mask=attention_mask,\n",
    "                                     max_length=256,\n",
    "                                     num_beams=2,\n",
    "                                     repetition_penalty=2.5,\n",
    "                                     length_penalty=1,\n",
    "                                     early_stopping=True)\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        all_blue_score.extend([sentence_bleu(references=[decoded_labels[i].split(' ')],\n",
    "                                             hypothesis=decoded_preds[i].split(' '),\n",
    "                                             weights=[0.25, 0.25, 0.25, 0.25],\n",
    "                                             smoothing_function=SmoothingFunction().method1)\n",
    "                               for i in range(predictions.shape[0])])\n",
    "\n",
    "    return np.array(all_blue_score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a152991-c5e6-4663-91c3-0d838e0a4374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| step   100 | loss  2.06461 |\n",
      "| step   200 | loss  2.08177 |\n",
      "| step   300 | loss  2.08045 |\n",
      "| step   400 | loss  2.00902 |\n",
      "| step   500 | loss  1.66362 |\n",
      "| step   600 | loss  1.75473 |\n",
      "| step   700 | loss  1.74266 |\n",
      "| step   800 | loss  1.44380 |\n",
      "| step   900 | loss  2.16509 |\n",
      "| step  1000 | loss  1.96669 |\n",
      "| step  1100 | loss  2.21257 |\n",
      "| step  1200 | loss  2.31056 |\n",
      "| step  1300 | loss  2.12070 |\n",
      "| step  1400 | loss  2.15469 |\n",
      "| step  1500 | loss  1.67766 |\n",
      "| step  1600 | loss  1.69820 |\n",
      "| step  1700 | loss  1.79850 |\n",
      "| step  1800 | loss  1.75700 |\n",
      "------------------------------------------------------------\n",
      "| end of epoch     1 | time: 204.84s | valid blue  0.09223 |\n",
      "------------------------------------------------------------\n",
      "| step   100 | loss  1.55292 |\n",
      "| step   200 | loss  1.67972 |\n",
      "| step   300 | loss  1.46360 |\n",
      "| step   400 | loss  1.78757 |\n",
      "| step   500 | loss  1.69956 |\n",
      "| step   600 | loss  1.87487 |\n",
      "| step   700 | loss  1.39110 |\n",
      "| step   800 | loss  1.19038 |\n",
      "| step   900 | loss  1.38775 |\n",
      "| step  1000 | loss  1.53157 |\n",
      "| step  1100 | loss  1.59207 |\n",
      "| step  1200 | loss  1.69214 |\n",
      "| step  1300 | loss  2.11269 |\n",
      "| step  1400 | loss  1.90462 |\n",
      "| step  1500 | loss  1.61116 |\n",
      "| step  1600 | loss  1.45734 |\n",
      "| step  1700 | loss  2.05824 |\n",
      "| step  1800 | loss  1.51487 |\n",
      "------------------------------------------------------------\n",
      "| end of epoch     2 | time: 210.42s | valid blue  0.11519 |\n",
      "------------------------------------------------------------\n",
      "| step   100 | loss  1.05054 |\n",
      "| step   200 | loss  1.56317 |\n",
      "| step   300 | loss  1.39728 |\n",
      "| step   400 | loss  1.46058 |\n",
      "| step   500 | loss  1.66262 |\n",
      "| step   600 | loss  1.28771 |\n",
      "| step   700 | loss  1.47605 |\n",
      "| step   800 | loss  1.34167 |\n",
      "| step   900 | loss  1.27106 |\n",
      "| step  1000 | loss  1.46837 |\n",
      "| step  1100 | loss  1.31132 |\n",
      "| step  1200 | loss  1.24334 |\n",
      "| step  1300 | loss  1.40421 |\n",
      "| step  1400 | loss  1.44134 |\n",
      "| step  1500 | loss  1.38950 |\n",
      "| step  1600 | loss  1.41746 |\n",
      "| step  1700 | loss  1.37135 |\n",
      "| step  1800 | loss  1.33482 |\n",
      "------------------------------------------------------------\n",
      "| end of epoch     3 | time: 205.47s | valid blue  0.11223 |\n",
      "------------------------------------------------------------\n",
      "| step   100 | loss  1.33237 |\n",
      "| step   200 | loss  1.24717 |\n",
      "| step   300 | loss  1.37748 |\n",
      "| step   400 | loss  1.06162 |\n",
      "| step   500 | loss  1.30350 |\n",
      "| step   600 | loss  1.49749 |\n",
      "| step   700 | loss  1.24832 |\n",
      "| step   800 | loss  1.11476 |\n",
      "| step   900 | loss  1.54799 |\n",
      "| step  1000 | loss  1.46981 |\n",
      "| step  1100 | loss  1.19632 |\n",
      "| step  1200 | loss  1.25032 |\n",
      "| step  1300 | loss  1.20931 |\n",
      "| step  1400 | loss  1.38733 |\n",
      "| step  1500 | loss  0.98297 |\n",
      "| step  1600 | loss  1.44860 |\n",
      "| step  1700 | loss  1.45094 |\n",
      "| step  1800 | loss  1.21608 |\n",
      "------------------------------------------------------------\n",
      "| end of epoch     4 | time: 207.02s | valid blue  0.10480 |\n",
      "------------------------------------------------------------\n",
      "| step   100 | loss  0.84115 |\n",
      "| step   200 | loss  1.45836 |\n",
      "| step   300 | loss  1.13822 |\n",
      "| step   400 | loss  1.07832 |\n",
      "| step   500 | loss  1.24230 |\n",
      "| step   600 | loss  1.19267 |\n",
      "| step   700 | loss  1.40689 |\n",
      "| step   800 | loss  0.90967 |\n",
      "| step   900 | loss  1.13773 |\n",
      "| step  1000 | loss  1.23839 |\n",
      "| step  1100 | loss  1.13468 |\n",
      "| step  1200 | loss  1.03813 |\n",
      "| step  1300 | loss  1.41557 |\n",
      "| step  1400 | loss  1.16570 |\n",
      "| step  1500 | loss  1.10580 |\n",
      "| step  1600 | loss  1.33842 |\n",
      "| step  1700 | loss  1.32119 |\n",
      "| step  1800 | loss  1.04711 |\n",
      "------------------------------------------------------------\n",
      "| end of epoch     5 | time: 210.22s | valid blue  0.10923 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, CFG.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train(model_t5, dataloader_train, optimizer_adamw, device)\n",
    "    blue_val = evaluate(model_t5, dataloader_valid, device)\n",
    "\n",
    "    print('-' * 60)\n",
    "    print('| end of epoch {:5d} | time: {:5.2f}s | valid blue {:8.5f} |'.format(epoch,\n",
    "                                                                                time.time() - epoch_start_time,\n",
    "                                                                                blue_val))\n",
    "    print('-' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "torch13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}