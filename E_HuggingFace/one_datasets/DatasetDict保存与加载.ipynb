{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0c2b38",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since dair-ai/emotion couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'split' at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\dair-ai___emotion\\split\\0.0.0\\cab853a1dbdf4c42c2b3ef2173804746df8825fe (last modified on Thu Dec 19 15:18:36 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Load a dataset\n",
    "\n",
    "- if ``path`` is a canonical dataset on the HF Hub (ex: `glue`, `squad`)\n",
    "              -> load the dataset builder from the dataset script in the github repository at huggingface/datasets\n",
    "              e.g. ``'squad'`` or ``'glue'``.\n",
    "\n",
    "- if ``path`` is a local directory (but doesn't contain a dataset script)\n",
    "              -> load a generic dataset builder (csv, json, text etc.) based on the content of the directory\n",
    "              e.g. ``'./path/to/directory/with/my/csv/data'``.\n",
    "'''\n",
    "datasets_emotion = load_dataset(path='dair-ai/emotion')  # 从Hugging Face加载dair-ai/emotion数据集\n",
    "datasets_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f6afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since glue couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'mrpc' at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\glue\\mrpc\\0.0.0\\bcdcba79d07bc864c1c254ccfcedcce55bcc9a8c (last modified on Tue Oct 29 15:55:44 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(path='glue', name='mrpc')  # 从Hugging Face加载glue下的mrpc数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf4340a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60bba6786eb4c76929362e81bbab02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e845fd260fa4440b8544f67ae08c765d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6ec3c93aa149a791b77f0458710459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saves a dataset dict to a filesystem using either :class:`~filesystems.S3FileSystem` or ``fsspec.spec.AbstractFileSystem``.\n",
    "datasets_emotion.save_to_disk(\"../extra_dataset/save_datasets_DatasetDict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c6cff2",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loads a dataset that was previously saved using :meth:`Dataset.save_to_disk` from a dataset directory,\n",
    "# or from a filesystem using either :class:`datasets.filesystems.S3FileSystem` or any implementation of ``fsspec.spec.AbstractFileSystem``.\n",
    "dataset_load = load_from_disk(\"../extra_dataset/save_datasets_DatasetDict\")\n",
    "print(dataset_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7f4800",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取单个csv文件\n",
    "load_dataset('csv', data_files='../extra_dataset/to_xxx/data.csv')  # DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ad26dc",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 32000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取多个csv文件\n",
    "load_dataset('csv', data_files=['../extra_dataset/to_xxx/data.csv', \n",
    "                                '../extra_dataset/to_xxx/data.csv'])  # DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0472b030",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 32000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过字典映射生成训练、测试、验证数据集\n",
    "load_dataset('csv', data_files={'train': ['../extra_dataset/to_xxx/data.csv', \n",
    "                                          '../extra_dataset/to_xxx/data.csv'],\n",
    "                                'test': '../extra_dataset/to_xxx/data.csv',\n",
    "                                'valid': '../extra_dataset/to_xxx/data.csv'})  # DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab30767",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取单个json文件\n",
    "load_dataset('json', data_files='../extra_dataset/to_xxx/data.json')  # DatasetDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e8cdfe",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 32000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取多个json文件\n",
    "load_dataset('json', data_files=['../extra_dataset/to_xxx/data.json',\n",
    "                                 '../extra_dataset/to_xxx/data.json'])  # DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e918ff",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 32000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过字典映射生成训练、测试、验证数据集\n",
    "load_dataset('json', data_files={'train': ['../extra_dataset/to_xxx/data.json', \n",
    "                                           '../extra_dataset/to_xxx/data.json'],\n",
    "                                 'test': '../extra_dataset/to_xxx/data.json',\n",
    "                                 'valid': '../extra_dataset/to_xxx/data.json'})  # DatasetDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
