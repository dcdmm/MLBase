{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input:$(N, C, H_{in}, W_{in})$\n",
    "* output:$(N, C, H_{out}, W_{out})$\n",
    "\n",
    "\\begin{array}{l}\n",
    "H_{out} &= \\lfloor \\frac{H_{in} + 2\\times padding[0] - kernel\\_size[0] }{stride[0]} +1  \\rfloor \\\\\n",
    "W_{out} &= \\lfloor \\frac{W_{in} + 2\\times padding[1] - kernel\\_size[1] }{stride[1]} +1  \\rfloor \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[  676.,   678.,   680.,  ...,   856.,   858.,   858.],\n          [ 1056.,  1058.,  1060.,  ...,  1236.,  1238.,  1238.],\n          [ 1436.,  1438.,  1440.,  ...,  1616.,  1618.,  1618.],\n          ...,\n          [12456., 12458., 12460.,  ..., 12636., 12638., 12638.],\n          [12836., 12838., 12840.,  ..., 13016., 13018., 13018.],\n          [13216., 13218., 13220.,  ..., 13396., 13398., 13398.]]]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kernel_size – the size of the window to take a max over\n",
    "stride – the stride of the window. Default value is kernel_size\n",
    "padding – implicit zero padding to be added on both sides\n",
    "dilation – a parameter that controls the stride of elements in the window\n",
    "'''\n",
    "input_tensor = torch.arange(100, 13400).reshape((1, 1, 70, 190)).to(torch.float32)\n",
    "max_f = F.max_pool2d(input=input_tensor,\n",
    "                     kernel_size=(3, 5),  # 池化窗口的大小\n",
    "                     stride=2,  # 池化窗口移动的步幅\n",
    "                     padding=(1, 2),  # 输入张量在边缘位置的填充(注意★★★★★:必须为int类型的元组)\n",
    "                     dilation=2,  # 与卷积运算中dilation的定义相同\n",
    "                     ceil_mode=False)  # 最后输出大小是否进行向上取整,默认进行向下取整\n",
    "max_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[  577,   579,   581,  ...,   755,   757,   759],\n          [  957,   959,   961,  ...,  1135,  1137,  1139],\n          [ 1337,  1339,  1341,  ...,  1515,  1517,  1519],\n          ...,\n          [12357, 12359, 12361,  ..., 12535, 12537, 12539],\n          [12737, 12739, 12741,  ..., 12915, 12917, 12919],\n          [13117, 13119, 13121,  ..., 13295, 13297, 13299]]]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "return_indices –\n",
    "    if True, will return the max indices along with the outputs.\n",
    "    Useful for torch.nn.MaxUnpool2d later\n",
    "'''\n",
    "max_f1, max_f1_indices = F.max_pool2d(input=input_tensor, kernel_size=(3, 5), stride=2, dilation=2,\n",
    "                                      padding=1, ceil_mode=False, return_indices=True)\n",
    "max_f1_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[  677.,   679.,   681.,  ...,   855.,   857.,   859.],\n          [ 1057.,  1059.,  1061.,  ...,  1235.,  1237.,  1239.],\n          [ 1437.,  1439.,  1441.,  ...,  1615.,  1617.,  1619.],\n          ...,\n          [12457., 12459., 12461.,  ..., 12635., 12637., 12639.],\n          [12837., 12839., 12841.,  ..., 13015., 13017., 13019.],\n          [13217., 13219., 13221.,  ..., 13395., 13397., 13399.]]]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_c = nn.MaxPool2d(kernel_size=(3, 5), stride=2, dilation=2,\n",
    "                     padding=1, ceil_mode=False, return_indices=True)\n",
    "max_c0, max_c0_indices = max_c(input_tensor)\n",
    "max_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 34, 92])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_c0_indices.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}