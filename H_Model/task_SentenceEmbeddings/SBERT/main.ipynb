{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f81a5cb3-df9e-4363-92fd-aef243ada967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models, losses\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a2fb87-0819-408f-9ce1-546806910208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>genre</th>\n",
       "      <th>dataset</th>\n",
       "      <th>year</th>\n",
       "      <th>sid</th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>4</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>5</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split          genre dataset      year  sid  score  \\\n",
       "0  train  main-captions  MSRvid  2012test    1   5.00   \n",
       "1  train  main-captions  MSRvid  2012test    4   3.80   \n",
       "2  train  main-captions  MSRvid  2012test    5   3.80   \n",
       "3  train  main-captions  MSRvid  2012test    6   2.60   \n",
       "4  train  main-captions  MSRvid  2012test    9   4.25   \n",
       "\n",
       "                                       sentence1  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        An air plane is taking off.  \n",
       "1                          A man is playing a flute.  \n",
       "2  A man is spreading shredded cheese on an uncoo...  \n",
       "3                         Two men are playing chess.  \n",
       "4                 A man seated is playing the cello.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/stsbenchmark.tsv', delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "dataset_train = dataset[dataset['split'] == 'train']\n",
    "dataset_dev = dataset[dataset['split'] == 'dev']\n",
    "dataset_test = dataset[dataset['split'] == 'test']\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1636b42a-c7c9-48cb-98a4-17c21ed71135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InputExample(row):\n",
    "    score = float(row['score']) / 5.0\n",
    "    # Creates one InputExample with the given texts, guid and label\n",
    "    row['ie'] = InputExample(\n",
    "        # the texts for the example.\n",
    "        texts=[row['sentence1'], row['sentence2']],\n",
    "        # the label for the example\n",
    "        label=score)  # 连续的分数(浮点类型), 不同类别对应标签(整型)\n",
    "    return row['ie']\n",
    "\n",
    "\n",
    "train_samples = dataset_train.apply(create_InputExample, axis=1).tolist()\n",
    "test_samples = dataset_test.apply(create_InputExample, axis=1).tolist()\n",
    "dev_samples = dataset_dev.apply(create_InputExample, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bdb8e06-2f53-4996-aebd-bfc0696cf245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "word_embedding_model = models.Transformer('distilbert-base-uncased')\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616ec0bf-56f7-4ae6-a50b-245e411a2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "# Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels.\n",
    "# The metrics are the cosine similarity as well as euclidean and Manhattan distance The returned score is the Spearman correlation with a specified metric.\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4976c10e-9264-4562-a0ed-5ea178757b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.029528141021728516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6bd5844ca9496b8cbf9666867544b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.22160625457763672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 360,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8045a3f0974eeea74becd884b40f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030063152313232422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 360,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d7f18a9fa64533b48fd97574132dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03289675712585449,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 360,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe88da9456f4c258ad10ab6cbea41d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03368520736694336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 360,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1be0a60e58f4c38b0b4e718e277e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.040895938873291016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 360,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4296f99734fe4803b1763a2f4a35dfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    # Tuples of (DataLoader, LossFunction). Pass more than one for multi-task learning\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    # An evaluator (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data.\n",
    "    # It is used to determine the best model that is saved to disc.\n",
    "    evaluator=evaluator,\n",
    "    epochs=5,  # 默认epochs=1\n",
    "    # If > 0, evaluate the model using evaluator after each number of training steps\n",
    "    evaluation_steps=1000,  # 默认evaluation_steps=0\n",
    "    # 其他可选择参数:\n",
    "    # 优化器(optimizer_class,optimizer_params)\n",
    "    # 学习率调整(cheduler,warmup_steps)\n",
    "    # 梯度裁剪(max_grad_norm)\n",
    "    # 混合精度加速(use_amp )\n",
    "    output_path='save_sbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9ce2468-48d4-4ae3-b6a2-47448011b34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('save_sbert')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be401be-0263-453d-952c-bb095a4936a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415362480129329\n",
      "0.7985742750445673\n"
     ]
    }
   ],
   "source": [
    "# This is called during training to evaluate the model.\n",
    "# It returns a score for the evaluation with a higher score indicating a better result.\n",
    "print(evaluator(model, output_path='save_sbert'))  # 达到0.84\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "print(test_evaluator(model, output_path='save_sbert'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92515e90-f212-4d3f-bc04-2f394e7cbe84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/distilbert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /root/.cache/torch/sentence_transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929568939710936\n",
      "0.5888452571674063\n"
     ]
    }
   ],
   "source": [
    "model_init = SentenceTransformer(model_name_or_path='distilbert-base-uncased')  # 默认,不进行微调\n",
    "print(evaluator(model_init))  # 只有0.69\n",
    "print(test_evaluator(model_init))  # 只有0.58\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3812",
   "language": "python",
   "name": "env_3812"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}