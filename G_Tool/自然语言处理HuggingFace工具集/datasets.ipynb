{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ac4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "764c214b6ccc4951894412f6fcbae2e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 9600\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1200\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1200\n    })\n})"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataset from the Hugging Face Hub, or a local dataset.\n",
    "dataset_all = load_dataset(path='seamew/ChnSentiCorp')\n",
    "dataset_all  # 类型:DatasetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1449e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = dataset_all['train']\n",
    "dataset_train  # 类型:Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1}\n",
      "{'text': ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', '房间太小。其他的都一般。。。。。。。。。'], 'label': [1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 索引\n",
    "print(dataset_train[0])\n",
    "# 切片\n",
    "print(dataset_train[0: 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6f179e2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-14246461b49d6134.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 未排序的label是乱序的\n",
    "print(dataset_train['label'][:10])\n",
    "\n",
    "# Create a new dataset sorted according to a column.\n",
    "sorted_dataset = dataset_train.sort(column='label')\n",
    "print(sorted_dataset)  # 类型:Dataset\n",
    "print(sorted_dataset['label'][:10])\n",
    "print(sorted_dataset['label'][-10:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0580b95d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-468feea96a2c2225.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Create a new Dataset where the rows are shuffled.\n",
    "shuffled_dataset = sorted_dataset.shuffle(seed=42)\n",
    "print(shuffled_dataset)  # 类型:Dataset\n",
    "print(shuffled_dataset['label'][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4b645946",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 6\n})"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataset with rows selected following the list/array of indices.\n",
    "dataset_select = dataset_train.select([0, 10, 20, 30, 40, 50])\n",
    "dataset_select  # 类型:DataSet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "2a1fd2a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-736176c5ef1ce4f5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2\n",
      "})\n",
      "2 ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '选择的事例太离奇了，夸大了心理咨询的现实意义，让人失去了信任感！如果说这样写的效果能在一开始抓住读者的眼球，但是看到案例主人公心理问题的原因解释时就逐渐失去了兴趣，反正有点拣了芝麻丢了西瓜的感觉。']\n"
     ]
    }
   ],
   "source": [
    "def filter_func(data):\n",
    "    return data['text'].startswith('选择')\n",
    "\n",
    "\n",
    "# Apply a filter function to all the elements in the table in batches and update the table so that the dataset only includes examples according to the filter function.\n",
    "start_with_ar = dataset_train.filter(filter_func)\n",
    "print(start_with_ar)  # 类型:Dataset\n",
    "print(len(start_with_ar), start_with_ar['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "90d50fce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### train_test_split(切分训练集和测试集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n})"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_size (:obj:`numpy.random.Generator`, optional): Size of the test split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
    "    If int, represents the absolute number of test samples.\n",
    "    If None, the value is set to the complement of the train size.\n",
    "    If train_size is also None, it will be set to 0.25.\n",
    "train_size (:obj:`numpy.random.Generator`, optional): Size of the train split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
    "    If int, represents the absolute number of train samples.\n",
    "    If None, the value is automatically set to the complement of the test size.\n",
    "\"\"\"\n",
    "dataset_train.train_test_split(test_size=0.5)  #  类型:DataSetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "b7563dea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 2400\n})"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the `index`-nth shard from dataset split into `num_shards` pieces.\n",
    "dataset_train.shard(\n",
    "    # How many shards to split the dataset into.\n",
    "    num_shards=4,\n",
    "    index=1,\n",
    ")  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "71352b68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### rename_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['textA', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename a column in the dataset, and move the features associated to the original column under the new column name.\n",
    "dataset_train.rename_column('text', 'textA')  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "408abc59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### remove_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove one or several column(s) in the dataset and the features associated to them.\n",
    "dataset_train.remove_columns(['text'])  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "252d3de3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-f3e1e232b2fa3670.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "['My sentence: 选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'My sentence: 15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'My sentence: 房间太小。其他的都一般。。。。。。。。。', 'My sentence: 1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'My sentence: 今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。']\n"
     ]
    }
   ],
   "source": [
    "def map_func(data):\n",
    "    data['text'] = 'My sentence: ' + data['text']\n",
    "    return data\n",
    "\n",
    "\n",
    "# Apply a function to all the elements in the table (individually or in batches) and update the table (if function does update examples).\n",
    "datatset_map = dataset_train.map(map_func)\n",
    "print(datatset_map) # 类型:Dataset\n",
    "print(datatset_map['text'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0f02e0f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_init = load_dataset(path='seamew/ChnSentiCorp', split='train')\n",
    "print(dataset_init)\n",
    "\n",
    "# Saves a dataset dict to a filesystem using either :class:`~filesystems.S3FileSystem` or ``fsspec.spec.AbstractFileSystem``.\n",
    "dataset_init.save_to_disk(\"dataset\")\n",
    "\n",
    "# Loads a dataset that was previously saved using :meth:`Dataset.save_to_disk` from a dataset directory,\n",
    "# or from a filesystem using either :class:`datasets.filesystems.S3FileSystem` or any implementation of ``fsspec.spec.AbstractFileSystem``.\n",
    "dataset_load = load_from_disk(\"dataset\")\n",
    "print(dataset_load)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "de71789e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 导出为其他格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9b79162c5414c79b8e881ea569bd6e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99a26728a4904f0cadc5021ff91b3846"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "3202787"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_csv_kwargs: Parameters to pass to pandas's :func:`pandas.DataFrame.to_csv`\n",
    "dataset_train.to_csv('data/data.csv')\n",
    "\n",
    "# to_json_kwargs: Parameters to pass to pandas's `pandas.DataFrame.to_json\n",
    "dataset_train.to_json('data/data.json',\n",
    "                      force_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}