{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "multihead_attn = nn.MultiheadAttention(embed_dim=200,  # E_q(E_q必须能整除num_heads)\n",
    "                                       num_heads=5,  # 注意力的数目\n",
    "                                       # 默认kdim=None(即kdim=embed_dim)\n",
    "                                       kdim=100,  # E_k\n",
    "                                       # 默认vdim=None(即vdim=embed_dim)\n",
    "                                       vdim=50,  # E_v\n",
    "                                       dropout=0.1  # Dropout probability on `attn_output_weights`\n",
    "                                       )\n",
    "\n",
    "# mask.shape=(14, 4)\n",
    "mask = torch.arange(4)[None, :] < torch.tensor([2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4])[:, None]\n",
    "# mask.shape=(1, 14, 4)\n",
    "mask = torch.unsqueeze(mask, 0)\n",
    "# mask.shape=(40, 14, 4)=(N * num_heads, L, S)\n",
    "mask = torch.repeat_interleave(mask, 40, dim=0)\n",
    "mask = ~mask\n",
    "\n",
    "query = torch.randn(14, 8, 200)  # query.shape=(L, N, E_q);L is the target sequence length\n",
    "key = torch.randn(4, 8, 100)  # key.shape=(S, N, E_k);S is the source sequence length\n",
    "value = torch.randn(4, 8, 50)  # value.shape=(S, N, E_v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = multihead_attn(query=query,\n",
    "                                                  key=key,\n",
    "                                                  value=value,\n",
    "                                                  # attn_mask.shape=(N * num_heads, L, S) or (L, S)\n",
    "                                                  # a True value indicates that the corresponding position is not allowed to attend\n",
    "                                                  attn_mask=mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14, 8, 200])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ★★★★★注意: pytorch输出的是头的平均注意力分数(tensorflow输出的是所有头的注意力分数)\n",
    "\"\"\"\n",
    "内部机制:\n",
    "if need_weights:\n",
    "    # average attention weights over heads\n",
    "    attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
    "    return attn_output, attn_output_weights.sum(dim=1) / num_heads\n",
    "else:\n",
    "    return attn_output, None\n",
    "\"\"\"\n",
    "# attn_output.shape=(L, N, E_q)\n",
    "attn_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 14, 4])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attn_output_weights.shape=(N, L, S)\n",
    "attn_output_weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "tensor([[0.5695, 0.3725, 0.0000, 0.0000],\n",
      "        [0.4529, 0.4285, 0.0000, 0.0000],\n",
      "        [0.6418, 0.4693, 0.0000, 0.0000],\n",
      "        [0.3648, 0.7463, 0.0000, 0.0000],\n",
      "        [0.3560, 0.3851, 0.3700, 0.0000],\n",
      "        [0.2858, 0.1156, 0.5682, 0.0000],\n",
      "        [0.3019, 0.4454, 0.3176, 0.0000],\n",
      "        [0.3328, 0.4049, 0.3734, 0.0000],\n",
      "        [0.4084, 0.2755, 0.4273, 0.0000],\n",
      "        [0.3450, 0.1566, 0.1948, 0.1429],\n",
      "        [0.4138, 0.1709, 0.3063, 0.1878],\n",
      "        [0.2192, 0.2985, 0.1580, 0.3818],\n",
      "        [0.1869, 0.3008, 0.2824, 0.2737],\n",
      "        [0.2157, 0.2981, 0.3033, 0.2177]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mask[0, :, :])\n",
    "print(attn_output_weights[0, :, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_proj_weight.shape= torch.Size([200, 200])\n",
      "k_proj_weight.shape= torch.Size([200, 100])\n",
      "v_proj_weight.shape= torch.Size([200, 50])\n",
      "in_proj_bias.shape= torch.Size([600])\n",
      "out_proj.weight.shape= torch.Size([200, 200])\n",
      "out_proj.bias.shape= torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "for i, j in multihead_attn.named_parameters():\n",
    "    print(str(i) + \".shape=\", j.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}