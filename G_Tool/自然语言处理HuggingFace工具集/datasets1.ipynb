{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "609489a1e3c34ed983c50c35fe859e5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all = load_dataset(path='seamew/ChnSentiCorp')\n",
    "dataset_train = dataset_all['train']\n",
    "dataset_train  # 类型:datasets.arrow_dataset.Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1}\n",
      "{'text': ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', '房间太小。其他的都一般。。。。。。。。。'], 'label': [1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 索引\n",
    "print(dataset_train[0])\n",
    "\n",
    "# 切片\n",
    "print(dataset_train[0: 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sort"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-14246461b49d6134.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 未排序的label是乱序的\n",
    "print(dataset_train['label'][:10])\n",
    "\n",
    "# Create a new dataset sorted according to a column.\n",
    "sorted_dataset = dataset_train.sort(column='label')  # 根据`label`进行排序\n",
    "print(sorted_dataset)  # 类型:datasets.arrow_dataset.Dataset\n",
    "print(sorted_dataset['label'][:10])\n",
    "print(sorted_dataset['label'][-10:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### shuffle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-14246461b49d6134.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-468feea96a2c2225.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "sorted_dataset = dataset_train.sort(column='label')\n",
    "\n",
    "# Create a new Dataset where the rows are shuffled.\n",
    "shuffled_dataset = sorted_dataset.shuffle(seed=42)\n",
    "print(shuffled_dataset)  # 类型:datasets.arrow_dataset.Dataset\n",
    "print(shuffled_dataset['label'][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### select"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 6\n})"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataset with rows selected following the list/array of indices.\n",
    "dataset_select = dataset_train.select([0, 10, 20, 30, 40, 50])\n",
    "dataset_select  # 类型:datasets.arrow_dataset.Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n})"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_size (:obj:`numpy.random.Generator`, optional): Size of the test split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
    "    If int, represents the absolute number of test samples.\n",
    "    If None, the value is set to the complement of the train size.\n",
    "    If train_size is also None, it will be set to 0.25.\n",
    "train_size (:obj:`numpy.random.Generator`, optional): Size of the train split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
    "    If int, represents the absolute number of train samples.\n",
    "    If None, the value is automatically set to the complement of the test size.\n",
    "\"\"\"\n",
    "# Return a dictionary (:obj:`datasets.DatsetDict`) with two random train and test subsets (`train` and `test` ``Dataset`` splits).\n",
    "dataset_train.train_test_split(test_size=0.5)  #  类型:datasets.dataset_dict.DatasetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### shard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 2400\n})"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the `index`-nth shard from dataset split into `num_shards` pieces.\n",
    "dataset_train.shard(\n",
    "    # How many shards to split the dataset into.\n",
    "    num_shards=4,\n",
    "    index=1,\n",
    ")  # 类型:datasets.arrow_dataset.Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rename_column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['textA', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename a column in the dataset, and move the features associated to the original column under the new column name.\n",
    "dataset_train.rename_column('text', 'textA')  # 类型:datasets.arrow_dataset.Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### remove_columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove one or several column(s) in the dataset and the features associated to them.\n",
    "dataset_train.remove_columns(['text'])  # 类型:datasets.arrow_dataset.Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-736176c5ef1ce4f5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2\n",
      "})\n",
      "2 ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '选择的事例太离奇了，夸大了心理咨询的现实意义，让人失去了信任感！如果说这样写的效果能在一开始抓住读者的眼球，但是看到案例主人公心理问题的原因解释时就逐渐失去了兴趣，反正有点拣了芝麻丢了西瓜的感觉。']\n"
     ]
    }
   ],
   "source": [
    "def filter_func(data):\n",
    "    return data['text'].startswith('选择')\n",
    "\n",
    "\n",
    "# Apply a filter function to all the elements in the table in batches and update the table so that the dataset only includes examples according to the filter function.\n",
    "start_with_ar = dataset_train.filter(filter_func)\n",
    "print(start_with_ar)  # 类型:datasets.arrow_dataset.Dataset\n",
    "print(len(start_with_ar), start_with_ar['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-f3e1e232b2fa3670.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "['My sentence: 选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'My sentence: 15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'My sentence: 房间太小。其他的都一般。。。。。。。。。', 'My sentence: 1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'My sentence: 今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。']\n"
     ]
    }
   ],
   "source": [
    "def map_func(data):\n",
    "    data['text'] = 'My sentence: ' + data['text']\n",
    "    return data\n",
    "\n",
    "\n",
    "# Apply a function to all the elements in the table (individually or in batches) and update the table (if function does update examples).\n",
    "datatset_map = dataset_train.map(map_func)\n",
    "print(datatset_map)  # 类型:datasets.arrow_dataset.Dataset\n",
    "print(datatset_map['text'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}