{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "predictions:a cat is on the table\n",
    "\n",
    "references:there is a cat on the table\n",
    "\n",
    "* 分子是predictions与references共有的`N-gram`个数\n",
    "* 分母是references所有`N-gram`个数\n",
    "\n",
    "$$ precision_1 = \\frac{len(['a', 'cat', 'is', 'on' 'the', 'table')]}{len(['there', 'is', 'a', 'cat', 'on', 'the', 'table'])} = \\frac{6}{7} $$\n",
    "\n",
    "$$ precision_2 = \\frac{len([('a', 'cat'), ('on', 'the'), ('the', 'table')]}{len([('there', 'is'), ('is', 'a'), ('a', 'cat'), ('cat', 'on'), ('on', 'the'), ('the', 'table')])} = \\frac{1}{2} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "{'rouge1': Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923),\n 'rouge2': Score(precision=0.5, recall=0.6, fmeasure=0.5454545454545454),\n 'rougeL': Score(precision=0.7142857142857143, recall=0.8333333333333334, fmeasure=0.7692307692307692),\n 'rougeLsum': Score(precision=0.7142857142857143, recall=0.8333333333333334, fmeasure=0.7692307692307692)}"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "scores = scorer.score('a cat is on the table',\n",
    "                      'there is a cat on the table')\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\nCalculates average rouge scores for a list of hypotheses and references\nArgs:\n    predictions: list of predictions to score. Each prediction\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\n    rouge_types: A list of rouge types to calculate.\n        Valid names:\n        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n        `\"rougeL\"`: Longest common subsequence based scoring.\n        `\"rougeLsum\"`: rougeLsum splits text using `\"\n\"`.\n        See details in https://github.com/huggingface/datasets/issues/617\n    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n    use_aggregator: Return aggregates if this is set to True\nReturns:\n    rouge1: rouge_1 (f1),\n    rouge2: rouge_2 (f1),\n    rougeL: rouge_l (f1),\n    rougeLsum: rouge_lsum (f1)\nExamples:\n\n    >>> rouge = evaluate.load('rouge')\n    >>> predictions = [\"hello there\", \"general kenobi\"]\n    >>> references = [\"hello there\", \"general kenobi\"]\n    >>> results = rouge.compute(predictions=predictions, references=references)\n    >>> print(results)\n    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n\"\"\", stored examples: 0)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "rouge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.923076923076923, 'rouge2': 0.5454545454545454, 'rougeL': 0.7692307692307692, 'rougeLsum': 0.7692307692307692}\n"
     ]
    }
   ],
   "source": [
    "predictions = [\"a cat is on the table\"]\n",
    "references = [\"there is a cat on the table\"]\n",
    "\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': [1.0, 1.0], 'rouge2': [1.0, 1.0], 'rougeL': [1.0, 1.0], 'rougeLsum': [1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references,\n",
    "                        # use_aggregator (boolean): If True, returns aggregates. Defaults to True.\n",
    "                        use_aggregator=False)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.8333333333333333, 'rouge2': 0.5, 'rougeL': 0.8333333333333333, 'rougeLsum': 0.8333333333333333}\n"
     ]
    }
   ],
   "source": [
    "# It can also deal with lists of references for each predictions:\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [[\"hello\", \"there\"], [\"general kenobi\", \"general yoda\"]]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}