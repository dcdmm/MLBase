{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcdmm\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\huggingface_hub\\file_download.py:588: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n  (2): Normalize()\n)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all-MiniLM-L6-v2\n",
    "    This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "'''\n",
    "model = SentenceTransformer(model_name_or_path='all-MiniLM-L6-v2', device='cuda')  # 从Huggingface加载预训练模型\n",
    "model  # 默认网络架构"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 256\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 512\n"
     ]
    }
   ],
   "source": [
    "# Change the length to 512\n",
    "# Note: You cannot increase the length higher than what is maximally supported by the respective transformer model.\n",
    "# Also note that if a model was trained on short texts, the representations for long texts might not be that good.\n",
    "model.max_seq_length = 512\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01371737 -0.04285157 -0.01562862 ...  0.10017828  0.12365725\n",
      "  -0.04229671]\n",
      " [ 0.05645247  0.05500242  0.03137957 ...  0.06650876  0.08491524\n",
      "  -0.03328492]\n",
      " [ 0.04393352  0.05893437  0.04817842 ...  0.05216279  0.05610652\n",
      "   0.10206395]]\n",
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "# Computes sentence embeddings\n",
    "embeddings_numpy = model.encode(sentences, convert_to_numpy=True)\n",
    "print(embeddings_numpy)  # numpy array\n",
    "print(embeddings_numpy.shape)  # (3, 384)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0137, -0.0429, -0.0156,  ...,  0.1002,  0.1237, -0.0423],\n",
      "        [ 0.0565,  0.0550,  0.0314,  ...,  0.0665,  0.0849, -0.0333],\n",
      "        [ 0.0439,  0.0589,  0.0482,  ...,  0.0522,  0.0561,  0.1021]],\n",
      "       device='cuda:0')\n",
      "torch.Size([3, 384])\n"
     ]
    }
   ],
   "source": [
    "# Computes sentence embeddings\n",
    "embeddings_tensor = model.encode(sentences, convert_to_tensor=True)\n",
    "print(embeddings_tensor)  # torch tensor\n",
    "print(embeddings_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}