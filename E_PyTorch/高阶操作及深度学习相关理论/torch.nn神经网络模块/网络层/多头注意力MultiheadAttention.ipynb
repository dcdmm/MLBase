{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 14, 4])\n"
     ]
    }
   ],
   "source": [
    "multihead_attn = nn.MultiheadAttention(embed_dim=200,  # E_q(E_q必须能整除num_heads)\n",
    "                                       num_heads=5,  # 注意力的数目\n",
    "                                       # 默认kdim=None(即kdim=embed_dim)\n",
    "                                       kdim=100,  # E_k\n",
    "                                       # 默认vdim=None(即vdim=embed_dim)\n",
    "                                       vdim=50,  # E_v\n",
    "                                       dropout=0.1  # Dropout probability on `attn_output_weights`\n",
    "                                       )\n",
    "\n",
    "mask = torch.arange(4)[None, :] < torch.tensor([2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4])[:, None]\n",
    "mask = torch.unsqueeze(mask, 0)\n",
    "mask = torch.repeat_interleave(mask, 40, dim=0)\n",
    "mask = ~mask\n",
    "print(mask.shape)\n",
    "query = torch.randn(14, 8, 200)  # query.shape=(L, N, E_q);L is the target sequence length\n",
    "key = torch.randn(4, 8, 100)  # key.shape=(S, N, E_k);S is the source sequence length\n",
    "value = torch.randn(4, 8, 50)  # value.shape=(S, N, E_v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = multihead_attn(query=query,\n",
    "                                                  key=key,\n",
    "                                                  value=value,\n",
    "                                                  # attn_mask.shape=(N * num_heads, L, S)\n",
    "                                                  # a True value indicates that the corresponding position is not allowed to attend\n",
    "                                                  attn_mask=mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([14, 8, 200])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ★★★★★注意: pytorch输出的是头的平均注意力分数(tensorflow输出的是所有头的注意力分数)\n",
    "\"\"\"\n",
    "内部机制:\n",
    "if need_weights:\n",
    "    # average attention weights over heads\n",
    "    attn_output_weights = attn_output_weights.view(bsz, num_heads, tgt_len, src_len)\n",
    "    return attn_output, attn_output_weights.sum(dim=1) / num_heads\n",
    "else:\n",
    "    return attn_output, None\n",
    "\"\"\"\n",
    "# attn_output.shape=(L, N, E_q)\n",
    "attn_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 14, 4])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attn_output_weights.shape=(N, L, S)\n",
    "attn_output_weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "tensor([[0.2539, 0.5431, 0.0000, 0.0000],\n",
      "        [0.4016, 0.5902, 0.0000, 0.0000],\n",
      "        [0.3744, 0.5451, 0.0000, 0.0000],\n",
      "        [0.2438, 0.6758, 0.0000, 0.0000],\n",
      "        [0.2059, 0.2278, 0.6774, 0.0000],\n",
      "        [0.5304, 0.3810, 0.1997, 0.0000],\n",
      "        [0.1313, 0.2999, 0.3711, 0.0000],\n",
      "        [0.2544, 0.2238, 0.4319, 0.0000],\n",
      "        [0.4367, 0.3485, 0.2122, 0.0000],\n",
      "        [0.4233, 0.2540, 0.2086, 0.1455],\n",
      "        [0.4418, 0.1090, 0.2379, 0.2652],\n",
      "        [0.2226, 0.3217, 0.2389, 0.2822],\n",
      "        [0.1565, 0.4765, 0.3173, 0.1323],\n",
      "        [0.2674, 0.2754, 0.3786, 0.1897]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mask[0, :, :])\n",
    "print(attn_output_weights[0, :, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_proj_weight.shape= torch.Size([200, 200])\n",
      "k_proj_weight.shape= torch.Size([200, 100])\n",
      "v_proj_weight.shape= torch.Size([200, 50])\n",
      "in_proj_bias.shape= torch.Size([600])\n",
      "out_proj.weight.shape= torch.Size([200, 200])\n",
      "out_proj.bias.shape= torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "for i, j in multihead_attn.named_parameters():\n",
    "    print(str(i) + \".shape=\", j.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}