{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<font color='red' size=4>定义:</font>     \n",
    "&emsp;&emsp;二项逻辑斯蒂回归模型是如下的条件概率分布(假设数据服从伯努利分布):    \n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=1|\\mathbf{x}) &= \\frac{\\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x} + b) }{1 + \\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x} +b)}&\\\\   \n",
    "         &=  \\frac{1}{1 + \\mathrm{exp}(-(\\mathbf{w} \\cdot \\mathbf{x} + b))} \\qquad 将 \\mathbf{w} \\cdot \\mathbf{x} + b代入\\mathrm{Sigmoid}函数得,其中\\mathrm{Sigmoid}函数是逻辑斯蒂分布的特例,故可视为概率   \\\\\n",
    "P(Y=0|\\mathbf{x}) &= \\frac{1}{1 + \\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x} + b)} &\\\\\n",
    "\\end{aligned}\n",
    "$$    \n",
    "这里,$ \\mathbf{x} \\in \\mathbf{R}^{n}$是输入,$ Y \\in \\{ 0, 1\\}$是输出,$\\mathbf{w} \\in \\mathbf{R}^n$和$b \\in \\mathbf{R}$是参数,$\\mathbf{w}$称为\n",
    "权值向量,$b$称为偏置,$\\mathbf{w} \\cdot \\mathbf{x}$为向量$\\mathbf{w}$和向量$\\mathbf{x}$向量的内积.\n",
    "\n",
    "&emsp;&emsp;有时为了方便,将权值向量和输入向量加以扩充,仍记为$ \\mathbf{w},\\mathbf{x} $,即$\\mathbf{w} = (w^{(1)}, w^{(2)}, \\dots, w^{(n)}, b)^T, \\mathbf{x} = (x^{(1)}, x^{(2)}, \\dots, x^{(n)}, 1)^T,$,这时,逻辑\n",
    "斯蒂回归模型如下:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=1|\\mathbf{x}) = \\frac{\\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x})}{1 + \\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x} )} &\\\\\n",
    "P(Y=0|\\mathbf{x}) = \\frac{1}{1 + \\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x})} &\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;现在考察逻辑斯蒂模型的特点.一个事件的几率(odds)是指该事件发生的概率与该事件不发生的\n",
    "概率的比值.如果事件发生的概率是$ p $,那么该事件的几率是$ \\frac{p}{1-p} $,该事件的对数几率(log odds)或logit函数是:    \n",
    "$$ \\mathrm{logit}(p) = \\log \\frac{p}{1 - p}  $$      \n",
    "&emsp;&emsp;对逻辑斯蒂回归而言,则有:    \n",
    "$$ \\log \\frac{P(Y=1|\\mathbf{x})}{1 - P(Y=1|\\mathbf{x})}  = \\mathbf{w} \\cdot \\mathbf{x} $$     \n",
    "这就是说,在逻辑斯蒂回归模型中,输出$Y=1$的对数几率是输入$\\mathbf{x}$的线性函数.或者说,输出$Y=1$的对数几率是由\n",
    "输入$\\mathbf{x}$的线性函数表示的模型,即逻辑斯蒂回归模型.    \n",
    "&emsp;&emsp;换一个角度看,考虑对输入$\\mathbf{x}$进行分类的线性函数$\\mathbf{w} \\cdot \\mathbf{x}$,其值域为实数域.注意,这里$ \\mathbf{x} \\in \\mathbf{R}^{n+1}, \\mathbf{w}\\in \\mathbf{R}^{n=1} $.通过对逻辑斯蒂\n",
    "回归模型的定义式可以将线性函数$\\mathbf{w} \\cdot \\mathbf{x}$转换为概率:    \n",
    "$$ P(Y=1|\\mathbf{x}) = \\frac{\\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x})}{1 + \\mathrm{exp}(\\mathbf{w} \\cdot \\mathbf{x} )} $$     \n",
    "这时,线性函数的值越接近正无穷,概率值就越接近1;线性函数的值越接近负无穷,概率值就越接近0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0886a02735466d80c36da7d0d184a8055779d3e497a063b4720b0317b8699033"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
