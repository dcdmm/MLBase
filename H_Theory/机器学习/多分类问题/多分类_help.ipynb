{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;现实中常遇到多分类学习的任务.有些二分类学习方法可以直接推广到多分类,但在更多情况下,我们是基于一些基本策略,利用二分类学习\n",
    "来解决多分类问题.                    \n",
    "&emsp;&emsp;不失一般性,考虑$N$个类别$C_1, C_2, \\dots,C_N$,多分类学习的基本思想是\"拆解法\",即将多分类任务拆为若干个二分类任务求解.具\n",
    "体来说,先对问题进行拆分,然后为拆出的每个二分类任务训练一个分类器;在测试时,对这些分类器的预测结果进行集成以获得最终的多分类结果.这里的关\n",
    "键是如何对多分类任务进行拆分,以及如何对多个分类器进行集成.                         \n",
    "&emsp;&emsp;最经典的拆分策略有三种:\"一对一\"(one vs one,简称OvO),\"一对其余\"(one vs Rest,简称OvR)和\"多对多\"(Many vs many,简称MvM).               \n",
    "&emsp;&emsp;给定数据集$D=\\{(\\mathbf{x}_1,y_1), (\\mathbf{x}_2, y_2),\\dots,(\\mathbf{x}_m, y_m)\\},y_i \\in \\{ C_1, C_2,\\dots ,C_N \\}$.OvO将这$N$个类别两两配对,从而产\n",
    "生$N(N-2)/2$个二分类任务,例如OvO将区分类别$C_i$和$C_j$训练一个分类器,该分类器将$D$中的$C_i$类样例作为正例,$C_j$类样例作为反例.在测试阶段,新样本\n",
    "将同时提交所有分类器,于是我们将得到$N(N-1)/2$个分类结果,最终的结果可通过投票产生:即把被预测得最高的类别作为最终分类结果.              \n",
    "&emsp;&emsp;OvR则是每次将一个类的样例作为正例,所有其他类的样例作为反例来训练$N$个分类器.在测试时若仅有一个分类器预测为正类,则对应\n",
    "的类别标记作为最终分类结果.若有多个分类器预测为正类,则通常考虑各分类器的预测置信度,选择置信度最大的类别标记作为分类结果.      \n",
    "\n",
    "\n",
    "<img src=\"../../../Other/img/OvO_OvR.png\" style=\"width:800px;height:400px;float:bottom\">\n",
    "       \n",
    "&emsp;&emsp;容易看出,OvR只需训练$N$个分类器,而OvO需训练$N(N-1)/2$个分类器,因此,OvO的存储开销和测试时间通常比OvR更大.但在训\n",
    "练时,OvR的每个分类器均使用全部训练样例,而OvO的每个分类器仅用到两个类的样例,因此,在类别很多时,OvO的训练时间开销通常比OvR更小.至于预\n",
    "测性能,取决于具体的数据分布,在多数情况下两者差不多.           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}