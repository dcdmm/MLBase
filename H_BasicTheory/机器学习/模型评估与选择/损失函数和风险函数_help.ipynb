{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 损失函数和风险函数\n",
    "&emsp;&emsp;监督学习问题是在假设空间$ F $中选取模型$ f $作为决策函数,对于给定的输入$ X $,由$ f(X)$给出\n",
    "相应的输出$ f(X) $,这个输出的预测值$ f(X)$与真实值$Y$可能一致也可能不一致,用一个损失函数( loss function)或\n",
    "代价函数(cost function)来度量预测错误的程度.损失函数是$ f(X) $和$ Y $的非负实值函数,记作$ L(Y, f(X)) $.   \n",
    "&emsp;&emsp;统计学习常用的损失函数由以下几种:    \n",
    "1. 0-1损失函数(0-1 loss function)   \n",
    "   \n",
    "$$\n",
    "L(Y, f(X))=\\begin{cases}\n",
    "\t\t1, & \\text{if} \\quad  Y \\neq f(X) \\\\\n",
    "        0, & \\text{if} \\quad  Y \\in = f(X) \n",
    "     \\end{cases}\n",
    "$$\n",
    "\n",
    "2. 平方损失函数(quadratic loss function)  \n",
    "$$ L(Y, f(X)) = (Y - f(X))^2 $$  \n",
    "\n",
    "3. 绝对损失函数(absolute loss function)\n",
    "$$ L(Y, f(X)) = | Y - f(X) |   $$\n",
    "\n",
    "4. 对数损失函数(logarithmic loss function)\n",
    "\n",
    "$$ L(Y, P(Y \\mid X))=-\\log P(Y \\mid X) $$\n",
    "\n",
    "&emsp;&emsp;损失函数越小,模型就越好.由于模型的输入,输出$ (X, Y)  $是随机变量,遵循联合分布$P(X, Y)$,所以损失函数的期望是     \n",
    "$$\n",
    "\\begin{aligned}\n",
    "R_{\\mathrm{exp}}(f) &= E_p[L(Y, f(X))] \\\\\n",
    "           &= \\int_{\\mathcal{X} \\times \\mathcal{Y}} L(y, f(\\mathbf{x}))P(\\mathbf{x}, y) d \\mathbf{x}dy     \n",
    "\\end{aligned}\n",
    "$$    \n",
    "这是理论上模型$f(X) $关于联合分布$ P(X, Y ) $的平均意义下的损失,称为风险损失(risk function)或期望损失(expected loss).    \n",
    "&emsp;&emsp;学习的目标就是选择期望风险最小的模型.由于联合分布$ P(X, Y) $是未知的,$R_{\\mathrm{exp}}(f) $不能直接计算.实际上,如果\n",
    "知道联合分布$ P(X, Y) $,可以从联合分布直接求出条件概率$  P(Y|X) $,也就不需要学习了.正因为不知道联合概率分布,所有才需要进行\n",
    "学习.这样一来,一方面根据期望风险最小学习模型要用到联合分布,另一方面联合分布又是未知的,所有监督问题就成为一个病态问题(ill-formed problem).     \n",
    "&emsp;&emsp;给定一个训练数据集    \n",
    "$$ T=\\{  (\\mathbf{x}_1, y_1),(\\mathbf{x}_2, y_2), \\dots, (\\mathbf{x}_N, y_N)  \\}  $$   \n",
    "模型$ f(X)  $关于训练数据集的平均损失称为经验风险(empirical risk)或经验损失(empirical loss),记作$ R_{\\mathrm{emp}} $:   \n",
    "$$ R_{\\mathrm{emp}} (f) = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f(\\mathbf{x}_i)) $$   \n",
    "&emsp;&emsp;期望风险$ R_{\\mathrm{exp}}(f) $是模型关于联合分布的期望损失,经验风险$ R_{\\mathrm{emp}} (f) $是模型关于训练样本集的平均损失.根据\n",
    "大数定律,当样本容量$N$趋于无穷时,经验风险$R_{\\mathrm{emp}} (f)  $趋于期望风险$ R_{\\mathrm{exp}}(f) $.所以一个很自然的想法是用经验风险估计\n",
    "期望风险.但是,由于现实中训练样本数目有限,甚至很小,所有用经验风险估计期望风险常常并不理想,要对风险进行一定的矫正.这就关系到监督学习的两个基本策略:经验风险\n",
    "最小化和结构风险最小化.    \n",
    "\n",
    "\n",
    "## 经验风险最小化与结构风险最小化  \n",
    "&emsp;&emsp;在假设空间,损失函数及训练数据集确定的情况下,经验风险函数式就可以确定.经验风险最小化(empirical risk minimization,ERM)的策略认为,经验\n",
    "风险最小的模型是最优的模型.根据这一策略,根据经验风险最小化求最优模型就是求解最优化问题:    \n",
    "$$ \\min_{f \\in F} \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f(\\mathbf{x}_i)) $$     \n",
    "其中,$ F $是假设空间.   \n",
    "&emsp;&emsp;当样本容量足够大时,经验风险最小化能保证有很好的学习效果,在现实中被广泛采用.比如,极大似然估计( maximum likelihood estimation)就是经验\n",
    "风险最小化的一个例子.当模型是条件概率分布,损失函数是对数损失函数时,经验风险最小化就等价于极大似然估计.  \n",
    "&emsp;&emsp;但是,当样本容量很小时,经验风险最小化学习的效果就未必最好,会产生\"过拟合\"(over-fitting)现象.    \n",
    "&emsp;&emsp;经验风险最小化(structural risk minimization, SRM)是为了防止过拟合而提出来的策略.结构\n",
    "风险最小化等价于正则化(regularization).结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或\n",
    "罚项(penalty term).在假设空间,损失函数以及训练数据集确定的情况下,结构风险的定义是:   \n",
    "$$ R_{srm}(f) = \\frac{1}{N} \\sum_{i=1}^{N}  L(y_i, f(\\mathbf{x}_i))  + \\lambda J(f)$$   \n",
    "其中$J(f)$为模型的复杂度,是定义在假设空间$F$上的泛函.模型$f$越复杂,复杂度$  J(f)$就越大;反之,模型$ f$越\n",
    "简单,复杂度$ J(f)$就越小.也就是说,复杂度表示了对复杂模型的惩罚.$ \\lambda \\geq 0$是系数,用以权衡经验风险和\n",
    "模型复杂度.结构风险小需要经验风险和模型复杂度同事小.结构风险小的模型往往对训练数据及未知的测试数据都有较好的预测.   \n",
    "&emsp;&emsp;比如,贝叶斯估计中的最大后验概率估计(maximum posterior probability estimation, MAP)就是\n",
    "结构风险最小化的一个例子.当模型是条件概率,损失函数是对数损失函数,模型复杂度由模型的先验概率表示时,结构风险最小化就等价于\n",
    "最大后验概率估计.      \n",
    "&emsp;&emsp;结构风险最小化的策略认为结构风险最小的模型是最优的模型.所以求最优化模型,就是求解最优化问题:    \n",
    "$$ \\min_{f \\in F} \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f(\\mathbf{x}_i)) +\\lambda J(f) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}