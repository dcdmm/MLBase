{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 30])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 100)\n",
    "\n",
    "rnn = nn.RNN(input_size=100, hidden_size=30)\n",
    "\n",
    "out, h = rnn(x)  # 单层,序列长度为1\n",
    "\n",
    "print(out.shape)\n",
    "print(out - h)  # 此时out=h;即相当于RNNCell(只输出h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 10]) torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=100,  # The number of expected features in the input x\n",
    "             hidden_size=10,  # 隐含变量的维度大小\n",
    "             num_layers=2,  # 循环神经网络层的多少.若num_layers=2,则第2层的输入是第1层的输出(层与层之间的参数相互独立)\n",
    "             nonlinearity='tanh',  # 非线性激活函数类型,也可以设置为'relu'.默认nonlinearity='tanh'\n",
    "             bias=True,  # 是否添加偏置.默认bias=True\n",
    "             batch_first=False,  # 如果batch_first=True,则输入张量大小为(N,T,C),而不是(T,N,C).默认batch_first=False\n",
    "             dropout=0.5)  # 如果这个值非零,则在循环神经网络最后输出的基础上加上丢弃层,丢弃的概率由输入的dropout确定.默认dropout=0\n",
    "\n",
    "x = torch.randn(20, 3, 100)  # 输入的默认形状为(T,N,C),其中T为序列的长度,N为min-batch的大小,C为输入的特征数目\n",
    "h_0 = torch.ones((2, 3, 10))  # (L*D, N, hidden_size),其中L为循环神经网络层数,D为1(单向)或2(双向)\n",
    "out, h = rnn(x, hx=h_0)  # 自定h_0,默认h_0为全0张量\n",
    "print(out.shape, h.shape)  # out.shape=(T, N, hidden_size);h.shape=(L*D, N, hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([10, 100])\n",
      "weight_hh_l0   shape= torch.Size([10, 10])\n",
      "bias_ih_l0   shape= torch.Size([10])\n",
      "bias_hh_l0   shape= torch.Size([10])\n",
      "weight_ih_l1   shape= torch.Size([10, 10])\n",
      "weight_hh_l1   shape= torch.Size([10, 10])\n",
      "bias_ih_l1   shape= torch.Size([10])\n",
      "bias_hh_l1   shape= torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in rnn.named_parameters():\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 30]) torch.Size([4, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "b_run = nn.RNN(input_size=100, hidden_size=15, num_layers=2,\n",
    "               bidirectional=True)  # 是否为设置为双向循环神经网络,默认为False\n",
    "\n",
    "# 此时b_h_0为正向hx(shape=(2, 3, 15))和反向hx(shape=(2, 3, 15))在第0个维度的拼接\n",
    "b_h_0 = torch.ones((4, 3, 15))\n",
    "\n",
    "# ★★★★★b_out中T(训练的长度)信息仍然保留\n",
    "b_out, b_h = b_run(x, hx=b_h_0)\n",
    "# b_out为每个序列最后一层的输出(双向则第二维度*2);b_h为最后一个序列每层的输出(双向则第0维度*2)\n",
    "print(b_out.shape, b_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([15, 100])\n",
      "weight_hh_l0   shape= torch.Size([15, 15])\n",
      "bias_ih_l0   shape= torch.Size([15])\n",
      "bias_hh_l0   shape= torch.Size([15])\n",
      "weight_ih_l0_reverse   shape= torch.Size([15, 100])\n",
      "weight_hh_l0_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l0_reverse   shape= torch.Size([15])\n",
      "bias_hh_l0_reverse   shape= torch.Size([15])\n",
      "weight_ih_l1   shape= torch.Size([15, 30])\n",
      "weight_hh_l1   shape= torch.Size([15, 15])\n",
      "bias_ih_l1   shape= torch.Size([15])\n",
      "bias_hh_l1   shape= torch.Size([15])\n",
      "weight_ih_l1_reverse   shape= torch.Size([15, 30])\n",
      "weight_hh_l1_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l1_reverse   shape= torch.Size([15])\n",
      "bias_hh_l1_reverse   shape= torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for name, param in b_run.named_parameters():\n",
    "    '''正向和反向两个方向的循环神经网络有各自的相互独立的参数'''\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-1.8555e-01,  1.1329e-01,  2.4918e-01, -3.6007e-02, -1.7716e-03,\n          4.3607e-02, -2.8975e-02, -4.4970e-02,  1.6755e-01, -2.3783e-01,\n          2.4658e-01,  5.7709e-02, -5.5757e-02,  3.8081e-02, -2.0598e-01],\n        [ 1.2940e-01,  3.8460e-02, -1.3125e-01, -2.5347e-01,  5.4901e-02,\n          1.9817e-01,  2.5753e-01, -2.0727e-01,  9.3943e-04,  3.2192e-03,\n          8.3854e-02, -1.1049e-01,  1.9628e-01,  1.5656e-01,  1.3021e-01],\n        [ 2.3819e-01, -1.4488e-02,  8.3998e-02, -4.0635e-02, -1.1969e-01,\n          8.7819e-02,  1.8752e-01, -1.1748e-02, -3.6478e-03, -1.1085e-02,\n         -2.3807e-02,  8.3186e-02, -8.4126e-03,  1.4259e-01,  1.0121e-01],\n        [ 2.0698e-01, -1.2697e-01, -1.2296e-01,  3.8799e-02, -8.4972e-02,\n         -1.8428e-01, -1.2324e-01,  1.2904e-01, -1.8404e-01, -2.4366e-01,\n          2.3639e-01, -2.2278e-01, -1.1823e-01,  1.3325e-01,  6.7143e-02],\n        [-1.9387e-01, -8.9016e-03, -8.9846e-03, -1.9714e-01,  2.3283e-01,\n          2.3382e-02,  2.1076e-01,  1.9014e-01, -2.4454e-01,  1.6960e-01,\n          5.0150e-02,  1.3804e-01,  7.6127e-02, -3.7989e-02, -2.2138e-01],\n        [-1.0995e-01, -2.3832e-01, -1.2982e-01,  4.2271e-02,  6.7297e-02,\n         -1.4398e-01, -1.3807e-01, -1.5941e-01, -1.3780e-01, -1.8559e-01,\n          1.2571e-01,  5.8124e-02, -2.2043e-01,  1.2957e-01,  1.6717e-01],\n        [ 3.8089e-02,  8.8906e-02,  9.6893e-02, -2.1279e-01, -9.8676e-03,\n         -3.2915e-02, -5.6299e-02,  1.5091e-03,  2.3448e-01,  2.5577e-01,\n          2.0428e-01,  8.6853e-02,  8.9077e-02, -1.2217e-01, -1.5263e-01],\n        [ 2.0989e-01, -2.1374e-01,  1.7840e-01, -9.7234e-02, -8.0991e-03,\n         -1.5085e-01, -2.4948e-01,  1.8853e-01,  1.8019e-01,  1.9317e-01,\n          7.9130e-02, -3.6316e-03, -2.0796e-01, -1.4831e-02, -1.5677e-01],\n        [-1.7137e-01, -7.8413e-03, -1.8150e-01, -1.5032e-01,  1.4520e-01,\n         -6.2384e-02, -2.1250e-01,  2.2450e-01, -1.1970e-01,  1.7225e-01,\n         -2.2681e-01, -1.1933e-01,  7.7913e-03, -2.1535e-04, -9.6525e-02],\n        [-8.1946e-02, -1.2697e-01, -1.2792e-01,  2.4332e-02, -2.1336e-01,\n         -7.3313e-03, -5.5874e-03, -8.6433e-02,  1.3414e-01, -3.1828e-02,\n          1.7129e-01, -1.7118e-02, -7.6216e-02,  2.0385e-01,  2.3363e-01],\n        [-3.1761e-02,  2.0997e-01,  9.1309e-02, -8.9485e-02, -3.7998e-02,\n          1.6987e-01,  1.6706e-01,  2.1414e-01, -7.8152e-03, -2.4764e-01,\n         -2.3117e-01,  1.8531e-01, -2.7098e-02,  2.0167e-01,  1.5348e-01],\n        [-1.5270e-01, -1.9518e-01, -1.9961e-01,  2.3984e-01,  1.0032e-01,\n          5.2914e-02, -2.4009e-01,  2.4501e-01, -2.5798e-01, -2.3285e-01,\n          1.7097e-01,  2.5107e-01, -1.8003e-01, -1.2149e-01, -2.4984e-01],\n        [ 2.1828e-01,  1.4266e-01, -5.1709e-02, -1.5759e-01, -1.1012e-01,\n         -1.0115e-01, -2.1987e-02, -1.1684e-01,  1.0739e-01,  1.7240e-02,\n         -8.9961e-02, -1.0218e-01, -1.6855e-01, -6.2975e-02,  1.0711e-01],\n        [ 1.8465e-01,  8.9481e-02, -2.3145e-01, -2.0423e-01, -2.1819e-01,\n          1.5576e-01, -2.1035e-01, -8.7449e-02,  1.0585e-01,  5.7654e-02,\n          1.6664e-01,  2.2004e-01, -2.2295e-01,  8.8570e-03, -3.6139e-02],\n        [-1.9544e-01,  9.7947e-02, -1.6856e-01,  1.0651e-01, -3.5532e-03,\n          2.1987e-01, -2.3542e-01, -2.5816e-01,  4.3882e-02,  2.4300e-02,\n         -1.8620e-01,  2.1164e-01, -1.3785e-01, -9.3757e-02,  1.0469e-01]],\n       requires_grad=True)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_hh_l0  # all the weights and biases are initialized from U(-\\sqrt{k}, \\sqrt{k}), where k=1/hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.2248,  0.1640, -0.2155,  0.1693, -0.0283, -0.1041, -0.2188,  0.2108,\n         -0.0094, -0.0677, -0.0338,  0.1651, -0.2539,  0.2007,  0.0583, -0.1160,\n         -0.2139, -0.0890,  0.1946,  0.1556,  0.1572,  0.0360, -0.1896, -0.0069,\n          0.2461,  0.2242, -0.0193,  0.0751,  0.2293, -0.0865],\n        [ 0.0840, -0.1849,  0.0100, -0.0776, -0.1552, -0.0373, -0.2206, -0.0044,\n          0.0008, -0.2063,  0.1485, -0.1798,  0.1573, -0.0444,  0.0748, -0.1194,\n          0.1256, -0.0092,  0.1403, -0.2454, -0.0273, -0.0206, -0.1796,  0.0938,\n          0.1657, -0.1908, -0.0671,  0.0981, -0.2397,  0.1281],\n        [ 0.0070, -0.1161, -0.1385, -0.0030,  0.2107, -0.0189, -0.0617,  0.1363,\n          0.0254,  0.2118,  0.2511,  0.1142, -0.2319,  0.1187, -0.1703,  0.1397,\n         -0.2175, -0.0484,  0.1403,  0.1530,  0.1407,  0.1849,  0.2422,  0.1005,\n         -0.0882,  0.1747, -0.2290,  0.1769, -0.0022,  0.2204],\n        [ 0.2242,  0.2085, -0.1308, -0.0033,  0.1474, -0.1554,  0.1433,  0.0802,\n          0.1841, -0.2064, -0.0406, -0.1758, -0.1276,  0.2345, -0.0298, -0.1342,\n          0.1633,  0.0665, -0.1583,  0.0098,  0.2119, -0.0066,  0.1966, -0.0546,\n          0.2309,  0.1891, -0.2293, -0.1809, -0.1337,  0.0599],\n        [-0.1692, -0.1399,  0.1883,  0.1152, -0.0701, -0.0141, -0.2557,  0.2329,\n          0.1313,  0.2578,  0.1965, -0.0856,  0.2527,  0.2339,  0.1266,  0.1373,\n         -0.1949, -0.2547, -0.2074,  0.1290,  0.2449,  0.0215, -0.2568, -0.1921,\n         -0.1907,  0.0119, -0.2530,  0.0307,  0.2552, -0.1997],\n        [ 0.1793, -0.1098,  0.2297, -0.2143,  0.1152,  0.0845,  0.1068,  0.1852,\n         -0.0333,  0.0813, -0.2289,  0.1859,  0.0885,  0.0259, -0.2000,  0.0107,\n          0.1263, -0.0644,  0.1968,  0.0517, -0.0661, -0.0124, -0.2271, -0.1049,\n          0.2139,  0.0860,  0.2134,  0.0737,  0.0250,  0.1256],\n        [ 0.0469,  0.0844, -0.0003, -0.1446,  0.1128,  0.2178, -0.1995,  0.0855,\n          0.0375, -0.0761, -0.2319,  0.1845, -0.2391,  0.0457,  0.0526,  0.2047,\n          0.2446, -0.0133,  0.2331, -0.0817,  0.0342,  0.2060, -0.1551, -0.2547,\n         -0.0168,  0.0412,  0.0940,  0.1171,  0.1871, -0.2204],\n        [-0.2052, -0.2267, -0.1780, -0.2253, -0.1268,  0.1820,  0.0678,  0.2138,\n         -0.2413,  0.1330,  0.1521, -0.1566,  0.0772, -0.1145,  0.2379,  0.0818,\n          0.0772,  0.0097,  0.1463, -0.2198, -0.0868, -0.2471, -0.1390,  0.1371,\n          0.1250, -0.1227, -0.1389, -0.1505, -0.1212,  0.2394],\n        [ 0.1674, -0.0707,  0.1912,  0.2046,  0.0473, -0.2581, -0.2294, -0.2333,\n         -0.1358,  0.0035,  0.0019, -0.0276, -0.1070, -0.0109,  0.2282, -0.0968,\n          0.1039,  0.0219, -0.0902, -0.1712, -0.0425,  0.1679, -0.2039, -0.1922,\n         -0.0101,  0.0265,  0.2535, -0.1604, -0.1933,  0.0453],\n        [ 0.1471, -0.1516,  0.1338,  0.1458, -0.1580,  0.0800, -0.2188, -0.0859,\n          0.1409,  0.2383, -0.0236,  0.1752, -0.0176, -0.0523,  0.1431, -0.1529,\n          0.1145,  0.0812,  0.2197, -0.1555, -0.0329, -0.1253, -0.1999, -0.0628,\n          0.1010,  0.2244, -0.0386, -0.1263,  0.1008, -0.2315],\n        [ 0.0738,  0.1899,  0.1304, -0.1116, -0.0716, -0.0460,  0.1307,  0.0132,\n         -0.1566,  0.2536, -0.2290, -0.0632, -0.0263,  0.1412, -0.2125,  0.0133,\n          0.0289, -0.0992,  0.0563, -0.1688, -0.0502, -0.2437,  0.2530, -0.1252,\n         -0.0537, -0.0297, -0.2441, -0.0121, -0.0598,  0.0832],\n        [-0.2382,  0.0468, -0.1385,  0.0778,  0.1854, -0.1721, -0.1427,  0.2557,\n          0.0556, -0.0883, -0.0829,  0.2471,  0.1982, -0.1093,  0.0064, -0.1403,\n          0.0559,  0.0241,  0.1351, -0.0038, -0.0163, -0.0917, -0.2372,  0.2312,\n         -0.1252, -0.0735, -0.2124,  0.2370,  0.0751, -0.2357],\n        [-0.0628, -0.0860,  0.0618,  0.1470, -0.0664, -0.0367,  0.1874,  0.2316,\n          0.1152,  0.0310, -0.2258, -0.1058,  0.2406,  0.0267,  0.1481,  0.1654,\n         -0.0296,  0.1011, -0.1970,  0.0085, -0.2305, -0.1549,  0.1903, -0.0417,\n         -0.2447, -0.1879,  0.0722,  0.2570, -0.0559,  0.2330],\n        [-0.1678, -0.1990,  0.0436,  0.1599,  0.0538, -0.0762, -0.2295,  0.2397,\n          0.0636,  0.2437,  0.0255, -0.1858,  0.0196,  0.0935, -0.0763,  0.0748,\n          0.2430, -0.0578,  0.1751, -0.1620, -0.0788,  0.0539,  0.0245, -0.0071,\n          0.2261,  0.0271,  0.0278,  0.2579, -0.1351, -0.2122],\n        [ 0.1338, -0.1678,  0.0108, -0.1189, -0.1537,  0.0962,  0.1040,  0.1966,\n          0.0137, -0.1306, -0.2098, -0.1043,  0.0775,  0.1818, -0.0067, -0.2340,\n          0.2222, -0.0291,  0.1600, -0.2031, -0.0273, -0.0953, -0.0511, -0.0065,\n          0.1794, -0.1599,  0.1849, -0.1076, -0.2437, -0.2034]],\n       requires_grad=True)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_ih_l1  # 参数全部都requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}