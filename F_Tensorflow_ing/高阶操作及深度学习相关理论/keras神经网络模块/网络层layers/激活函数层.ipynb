{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### sigmoid激活函数\n",
    "### 参考torch.sigmoid/torch.nn.Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-5, 5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00669285 0.00942264 0.01325097 0.0186055  0.02606656 0.03640861\n",
      " 0.05064057 0.07003141 0.09609567 0.13049925 0.17483739 0.23025063\n",
      " 0.29690726 0.37349752 0.45700301 0.54299699 0.62650248 0.70309274\n",
      " 0.76974937 0.82516261 0.86950075 0.90390433 0.92996859 0.94935943\n",
      " 0.96359139 0.97393344 0.9813945  0.98674903 0.99057736 0.99330715], shape=(30,), dtype=float64)\n",
      "\n",
      "tf.Tensor(\n",
      "[0.00669285 0.00942264 0.01325097 0.0186055  0.02606656 0.03640861\n",
      " 0.05064057 0.07003141 0.09609567 0.13049925 0.17483739 0.23025063\n",
      " 0.29690726 0.37349752 0.45700301 0.54299699 0.62650248 0.70309274\n",
      " 0.76974937 0.82516261 0.86950075 0.90390433 0.92996859 0.94935943\n",
      " 0.96359139 0.97393344 0.9813945  0.98674903 0.99057736 0.99330715], shape=(30,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# 函数\n",
    "print(tf.nn.sigmoid(x), end='\\n\\n')\n",
    "\n",
    "# 函数\n",
    "print(tf.math.sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "tf.Tensor(\n",
      "[0.00669285 0.00942264 0.01325097 0.0186055  0.02606656 0.03640861\n",
      " 0.05064056 0.07003141 0.09609567 0.13049924 0.17483738 0.23025063\n",
      " 0.29690725 0.37349752 0.457003   0.54299694 0.62650245 0.70309275\n",
      " 0.7697494  0.8251626  0.8695008  0.9039043  0.9299686  0.9493594\n",
      " 0.96359134 0.9739335  0.9813945  0.986749   0.99057734 0.9933072 ], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 类\n",
    "layer = tf.keras.layers.Activation(tf.nn.sigmoid, name='sigmoid')  # 可在网络层中简写为:'sigmoid'\n",
    "output = layer(x)\n",
    "\n",
    "print(layer.name)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### softmax激活函数\n",
    "### 参考tofch.nn.functional.softmax/torch.nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-5, 5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(30,), dtype=float64, numpy=\narray([1.32416572e-05, 1.86938631e-05, 2.63909957e-05, 3.72573956e-05,\n       5.25979976e-05, 7.42550388e-05, 1.04829291e-04, 1.47992384e-04,\n       2.08927729e-04, 2.94952988e-04, 4.16398847e-04, 5.87849613e-04,\n       8.29894630e-04, 1.17160083e-03, 1.65400337e-03, 2.33503346e-03,\n       3.29647530e-03, 4.65378745e-03, 6.56996811e-03, 9.27512945e-03,\n       1.30941315e-02, 1.84855942e-02, 2.60969728e-02, 3.68423099e-02,\n       5.20120018e-02, 7.34277612e-02, 1.03661384e-01, 1.46343596e-01,\n       2.06600059e-01, 2.91666909e-01])>"
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数\n",
    "tf.nn.softmax(x)  # 等价与tf.math.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n",
      "tf.Tensor(\n",
      "[1.32416581e-05 1.86938669e-05 2.63910006e-05 3.72574068e-05\n",
      " 5.25980140e-05 7.42550692e-05 1.04829291e-04 1.47992381e-04\n",
      " 2.08927755e-04 2.94953032e-04 4.16398747e-04 5.87849587e-04\n",
      " 8.29894561e-04 1.17160077e-03 1.65400351e-03 2.33503385e-03\n",
      " 3.29647609e-03 4.65378864e-03 6.56996854e-03 9.27513093e-03\n",
      " 1.30941318e-02 1.84855945e-02 2.60969736e-02 3.68423164e-02\n",
      " 5.20120002e-02 7.34277666e-02 1.03661396e-01 1.46343589e-01\n",
      " 2.06600055e-01 2.91666925e-01], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layer = tf.keras.layers.Activation(tf.nn.softmax, name='softmax')  # 可在网络层中简写为:'softmax'\n",
    "output = layer(x)\n",
    "\n",
    "print(layer.name)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 激活函数tanh\n",
    "### 参考torch.tanh/torch.nn.Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-20, 20, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(50,), dtype=float64, numpy=\narray([-1.        , -1.        , -1.        , -1.        , -1.        ,\n       -1.        , -1.        , -1.        , -1.        , -1.        ,\n       -1.        , -1.        , -1.        , -0.99999999, -0.99999993,\n       -0.99999963, -0.99999812, -0.99999038, -0.99995078, -0.99974812,\n       -0.99871171, -0.99342468, -0.96680063, -0.8409736 , -0.38691202,\n        0.38691202,  0.8409736 ,  0.96680063,  0.99342468,  0.99871171,\n        0.99974812,  0.99995078,  0.99999038,  0.99999812,  0.99999963,\n        0.99999993,  0.99999999,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ])>"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.tanh(x)  # 等价与tf.math.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(50,), dtype=float32, numpy=\narray([-1.        , -1.        , -1.        , -1.        , -1.        ,\n       -1.        , -1.        , -1.        , -1.        , -1.        ,\n       -1.        , -1.        , -1.        , -1.        , -1.        ,\n       -0.99999964, -0.9999983 , -0.9999904 , -0.99995077, -0.9997481 ,\n       -0.99871165, -0.99342465, -0.9668005 , -0.84097356, -0.38691205,\n        0.38691205,  0.84097356,  0.9668005 ,  0.99342465,  0.99871165,\n        0.9997481 ,  0.99995077,  0.9999904 ,  0.9999983 ,  0.99999964,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n        1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n      dtype=float32)>"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Activation(tf.nn.tanh)  # 可在网络层中简写为:'tanh'\n",
    "output = layer(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 激活函数Swish \n",
    "\n",
    "Swish activation function which returns $ x * sigmoid(x)$.\n",
    "It is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks, it is unbounded above and bounded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.constant([-20, -1.0, 0.0, 1.0, 20], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=float32, numpy=\narray([-4.1223068e-08, -2.6894143e-01,  0.0000000e+00,  7.3105854e-01,\n        2.0000000e+01], dtype=float32)>"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数\n",
    "tf.nn.swish(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=float32, numpy=\narray([-4.1223068e-08, -2.6894143e-01,  0.0000000e+00,  7.3105854e-01,\n        2.0000000e+01], dtype=float32)>"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Activation(tf.nn.swish)\n",
    "output = layer(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 激活函数relu\n",
    "### 参考torch.functional.relu/torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-5, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(100,), dtype=float64, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.05050505, 0.15151515, 0.25252525, 0.35353535, 0.45454545,\n       0.55555556, 0.65656566, 0.75757576, 0.85858586, 0.95959596,\n       1.06060606, 1.16161616, 1.26262626, 1.36363636, 1.46464646,\n       1.56565657, 1.66666667, 1.76767677, 1.86868687, 1.96969697,\n       2.07070707, 2.17171717, 2.27272727, 2.37373737, 2.47474747,\n       2.57575758, 2.67676768, 2.77777778, 2.87878788, 2.97979798,\n       3.08080808, 3.18181818, 3.28282828, 3.38383838, 3.48484848,\n       3.58585859, 3.68686869, 3.78787879, 3.88888889, 3.98989899,\n       4.09090909, 4.19191919, 4.29292929, 4.39393939, 4.49494949,\n       4.5959596 , 4.6969697 , 4.7979798 , 4.8989899 , 5.        ])>"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数\n",
    "tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(100,), dtype=float32, numpy=\narray([0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.05050505, 0.15151516, 0.25252524, 0.35353535, 0.45454547,\n       0.5555556 , 0.65656567, 0.75757575, 0.85858583, 0.959596  ,\n       1.060606  , 1.1616162 , 1.2626263 , 1.3636364 , 1.4646465 ,\n       1.5656565 , 1.6666666 , 1.7676767 , 1.8686869 , 1.969697  ,\n       2.070707  , 2.1717172 , 2.2727273 , 2.3737373 , 2.4747474 ,\n       2.5757575 , 2.6767676 , 2.7777777 , 2.878788  , 2.979798  ,\n       3.0808082 , 3.1818182 , 3.2828283 , 3.3838384 , 3.4848485 ,\n       3.5858586 , 3.6868687 , 3.7878788 , 3.8888888 , 3.989899  ,\n       4.090909  , 4.1919193 , 4.292929  , 4.3939395 , 4.4949493 ,\n       4.5959597 , 4.6969695 , 4.79798   , 4.8989897 , 5.        ],\n      dtype=float32)>"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Activation(tf.nn.relu)  # 可在网络层中简写为:'relu'\n",
    "output = layer(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 激活函数leaky_relu\n",
    "### 参考torch.nn.LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.linspace(-5, 5, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(200,), dtype=float64, numpy=\narray([-5.00000007e-01, -4.94974882e-01, -4.89949756e-01, -4.84924630e-01,\n       -4.79899505e-01, -4.74874379e-01, -4.69849253e-01, -4.64824128e-01,\n       -4.59799002e-01, -4.54773876e-01, -4.49748750e-01, -4.44723625e-01,\n       -4.39698499e-01, -4.34673373e-01, -4.29648248e-01, -4.24623122e-01,\n       -4.19597996e-01, -4.14572870e-01, -4.09547745e-01, -4.04522619e-01,\n       -3.99497493e-01, -3.94472368e-01, -3.89447242e-01, -3.84422116e-01,\n       -3.79396991e-01, -3.74371865e-01, -3.69346739e-01, -3.64321613e-01,\n       -3.59296488e-01, -3.54271362e-01, -3.49246236e-01, -3.44221111e-01,\n       -3.39195985e-01, -3.34170859e-01, -3.29145734e-01, -3.24120608e-01,\n       -3.19095482e-01, -3.14070356e-01, -3.09045231e-01, -3.04020105e-01,\n       -2.98994979e-01, -2.93969854e-01, -2.88944728e-01, -2.83919602e-01,\n       -2.78894477e-01, -2.73869351e-01, -2.68844225e-01, -2.63819099e-01,\n       -2.58793974e-01, -2.53768848e-01, -2.48743722e-01, -2.43718597e-01,\n       -2.38693471e-01, -2.33668345e-01, -2.28643219e-01, -2.23618094e-01,\n       -2.18592968e-01, -2.13567842e-01, -2.08542717e-01, -2.03517591e-01,\n       -1.98492465e-01, -1.93467340e-01, -1.88442214e-01, -1.83417088e-01,\n       -1.78391962e-01, -1.73366837e-01, -1.68341711e-01, -1.63316585e-01,\n       -1.58291460e-01, -1.53266334e-01, -1.48241208e-01, -1.43216083e-01,\n       -1.38190957e-01, -1.33165831e-01, -1.28140705e-01, -1.23115580e-01,\n       -1.18090454e-01, -1.13065328e-01, -1.08040203e-01, -1.03015077e-01,\n       -9.79899512e-02, -9.29648255e-02, -8.79396998e-02, -8.29145741e-02,\n       -7.78894484e-02, -7.28643227e-02, -6.78391970e-02, -6.28140713e-02,\n       -5.77889456e-02, -5.27638199e-02, -4.77386942e-02, -4.27135685e-02,\n       -3.76884428e-02, -3.26633171e-02, -2.76381914e-02, -2.26130657e-02,\n       -1.75879400e-02, -1.25628143e-02, -7.53768855e-03, -2.51256285e-03,\n        2.51256281e-02,  7.53768844e-02,  1.25628141e-01,  1.75879397e-01,\n        2.26130653e-01,  2.76381910e-01,  3.26633166e-01,  3.76884422e-01,\n        4.27135678e-01,  4.77386935e-01,  5.27638191e-01,  5.77889447e-01,\n        6.28140704e-01,  6.78391960e-01,  7.28643216e-01,  7.78894472e-01,\n        8.29145729e-01,  8.79396985e-01,  9.29648241e-01,  9.79899497e-01,\n        1.03015075e+00,  1.08040201e+00,  1.13065327e+00,  1.18090452e+00,\n        1.23115578e+00,  1.28140704e+00,  1.33165829e+00,  1.38190955e+00,\n        1.43216080e+00,  1.48241206e+00,  1.53266332e+00,  1.58291457e+00,\n        1.63316583e+00,  1.68341709e+00,  1.73366834e+00,  1.78391960e+00,\n        1.83417085e+00,  1.88442211e+00,  1.93467337e+00,  1.98492462e+00,\n        2.03517588e+00,  2.08542714e+00,  2.13567839e+00,  2.18592965e+00,\n        2.23618090e+00,  2.28643216e+00,  2.33668342e+00,  2.38693467e+00,\n        2.43718593e+00,  2.48743719e+00,  2.53768844e+00,  2.58793970e+00,\n        2.63819095e+00,  2.68844221e+00,  2.73869347e+00,  2.78894472e+00,\n        2.83919598e+00,  2.88944724e+00,  2.93969849e+00,  2.98994975e+00,\n        3.04020101e+00,  3.09045226e+00,  3.14070352e+00,  3.19095477e+00,\n        3.24120603e+00,  3.29145729e+00,  3.34170854e+00,  3.39195980e+00,\n        3.44221106e+00,  3.49246231e+00,  3.54271357e+00,  3.59296482e+00,\n        3.64321608e+00,  3.69346734e+00,  3.74371859e+00,  3.79396985e+00,\n        3.84422111e+00,  3.89447236e+00,  3.94472362e+00,  3.99497487e+00,\n        4.04522613e+00,  4.09547739e+00,  4.14572864e+00,  4.19597990e+00,\n        4.24623116e+00,  4.29648241e+00,  4.34673367e+00,  4.39698492e+00,\n        4.44723618e+00,  4.49748744e+00,  4.54773869e+00,  4.59798995e+00,\n        4.64824121e+00,  4.69849246e+00,  4.74874372e+00,  4.79899497e+00,\n        4.84924623e+00,  4.89949749e+00,  4.94974874e+00,  5.00000000e+00])>"
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 函数\n",
    "tf.nn.leaky_relu(x,\n",
    "                 alpha=0.1)  # alpha: Slope of the activation function at x < 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "# 自定义leaky_relu激活函数层\n",
    "class MyLeakyRelu(tf.keras.layers.Layer):  # This is the class from which all layers inherit.\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}