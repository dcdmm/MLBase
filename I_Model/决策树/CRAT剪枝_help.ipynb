{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;CART剪枝算法从\"完全生长\"的决策树的底端减去一些子树,使决策树变小(规模变简单),从而能够对未知的\n",
    "数据有更准确的预测.CART剪枝算法由两步组成:首先从生成算法产生的决策树$T_0$底部开始不断剪枝,直到$T_0$的跟结点,形成\n",
    "一个子树序列$ \\{ T_0, T_1, \\dots, T_n \\} $;然后通过交叉验证法在独立的数据集上对子树序列进行测试,从中选择最优子树.     \n",
    "1. 剪枝,形成一个子树序列    \n",
    "\n",
    "\n",
    "&emsp;&emsp;在剪枝过程中,计算子树的损失函数:  \n",
    "$$ C_{\\alpha}(T) = C(T) + \\alpha |T| $$    \n",
    "其中,$T$为任意子树,$ C(T) $为对训练数据的测试误差(如基尼指数),$|T|$为子树的叶结点个数,$ \\alpha \\geq 0$为参数,$ C_{\\alpha}(T) $为参\n",
    "数是$\\alpha$时的子树$T$的整体损失.参数$\\alpha$权衡训练数据的拟合程度与模型的复杂度.       \n",
    "&emsp;&emsp;对固定的$\\alpha$,一定存在使损失函数$C_{\\alpha}(C)$最小的子树,将其表示为$T_{\\alpha}$.$T_{\\alpha}$在损失函数$C_{\\alpha}(T)$最小\n",
    "的意义下是最优的.容易验证这样的最优子树是唯一的.当$\\alpha$大的时候,最优子树$T_{\\alpha}$偏小;当$\\alpha$小的时候,最优子树$T_{\\alpha}$偏大.极\n",
    "端情况,当$\\alpha=0$时,整体树是最优的.当$\\alpha \\rightarrow \\infty$时,根节点组成的单节点树是最优的.      \n",
    "&emsp;&emsp;Breiman等人证明:可以用递归的方法对树进行剪枝.将$\\alpha$,$ 0 = \\alpha_0 < \\alpha_1 < \\dots < \\alpha_n < \\infty $,产生一系列的\n",
    "区间$ [ \\alpha_i, \\alpha_{i+1} ), i =0,1,\\dots, n$;剪枝得到的子树序列对应着区间$ \\alpha \\in [ \\alpha_i, \\alpha_{i+1} ), i =0,1,\\dots, n$的最优子树\n",
    "序列$ \\{ T_0, T_1, \\dots, T_n \\} $,序列中的子树都是嵌套的.   \n",
    "&emsp;&emsp;具体地,从整体书$T_0$开始剪枝.对$T_0$的任意内部结点$t$,以$t$为单结点的损失函数是    \n",
    "$$ C_{\\alpha} (t) = C(t) + \\alpha  $$    \n",
    "\n",
    "<img src=\"../../Other/img/决策树单结点.jpg\" style=\"width:400px;height:300px;float:bottom\">\n",
    "\n",
    "以$t$为根节点的子树$T_{t}$的损失函数是        \n",
    "$$ C_{\\alpha} (T_t) = C(T_t) + \\alpha  |T_t| $$      \n",
    "\n",
    "<img src=\"../../Other/img/决策树根结点.jpg\" style=\"width:400px;height:300px;float:bottom\">\n",
    "   \n",
    "&emsp;&emsp;当$\\alpha=0$及$\\alpha$充分小时,有不等式   \n",
    "$$ C_{\\alpha} (T_t) < C_{\\alpha} (t) $$     \n",
    "当$\\alpha 增大时$,在某一$ \\alpha $有   \n",
    "$$ C_{\\alpha} (T_t) = C_{\\alpha} (t) $$   \n",
    "&emsp;&emsp;当$\\alpha$再增大时,不等式反向.只要$\\alpha= \\frac{C(t) - C(T_t)}{ |T_t| - 1}$,$T_t$与$t$有相同的损失函\n",
    "数值,而$t$的结点少,因此$t$比$T_t$更可取,对$T_t$进行剪枝.      \n",
    "&emsp;&emsp;为此,对$T_0$中<font color='red'>每一内部结点</font>$t$,计算    \n",
    "$$ g(t)= \\frac{C(t) - C(T_t)}{ |T_t| - 1} $$     \n",
    "它表示剪枝后整体损失函数的减少的程度.在$T_0$中剪去$g(t)$最小的$T_t$,将得到的子树作为$T_1$,同时将最小的$g(t)$设为$ \\alpha_1 $.$T_1$为区间$[\\alpha_1, \\alpha_1)$的最优子树.     \n",
    "&emsp;&emsp;如此剪枝下去,直到得到根节点.在这一过程中,不断地增加$\\alpha$的值,产生新的区间.    \n",
    "\n",
    "2. 在剪枝得到的子树序列$T_0, T_1, \\dots, T_n$中通过交叉验证选取最优的子树$T_{\\alpha}$   \n",
    "\n",
    "&emsp;&emsp;具体地,利用独立的验证数据集,测试子树序列$ T_0, T_1, \\dots, T_n $中各棵子树的平方误差或基尼指数.平方误差或基尼指数最小的决策树\n",
    "被认为是最优的决策树.在子树序列中,每棵子树$T_1, T_2, \\dots,T_n$对应于一个参数$\\alpha_1, \\alpha_2, \\dots, \\alpha_n$.所以,当最优子树$T_k$确定时,对应的$\\alpha_k$也确定了,即得到最\n",
    "优决策树$T_{\\alpha}$.    \n",
    "\n",
    "\n",
    "\n",
    "<font color='red' size=4>CART 剪枝算法:</font>   \n",
    "\n",
    "输入:CART算法生成的决策树$T_0$ ;    \n",
    "输出:最优决策树$T_{\\alpha}$       \n",
    "\n",
    "1. 设$k=0, T=T_0$\n",
    "2. 设$\\alpha=+\\infty$\n",
    "3. 自下而上地对各内部结点$t$计算$C(T_{t}),|T_t|$  以及    \n",
    "$$g(t)= \\frac{C(t) - C(T_t)}{ |T_t| - 1} $$     \n",
    "$$ \\alpha = \\min(\\alpha, g(t)) \\qquad  (保证序列中的子树是嵌套的)$$    \n",
    "这里,$T_t$表示以$t$为跟结点的子树,$C(T_t)$是训练数据集的测试误差,$|T_t|$是$T_t$的叶节点个数.    \n",
    "4. 对$g(t) =\\alpha$的内部结点$t$进行剪枝,并对叶节点$t$以多数表决法决定其类,得到树$T$.\n",
    "5. 设$k=k+1,\\alpha_k=\\alpha,T_{\\alpha}=T$\n",
    "6. 如果$T_k$不是由根结点及两个叶结点(也是最简单的树)构造的树,则回到步骤2;否则$T_k = T_n$.\n",
    "7. 采用交叉验证法在子树序列$T_0, T_1, \\dots,T_n$中选取最优子树$T_{\\alpha}$ \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
