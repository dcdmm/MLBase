{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../../../Other/img/注意力机制.png\"  style=\"width:750px;height:400px;float:bottom\">\n",
    "\n",
    "其中$a$表示注意力评分函数\n",
    "\n",
    "假设有一个查询$ \\mathrm{q} \\in \\mathbb{R}^{q} $ 和$m$个\"键-值\"对$ \\left(\\mathrm{k}_{1}, \\mathrm{v}_{1}\\right), \\ldots,\\left(\\mathrm{k}_{m}, \\mathrm{v}_{m}\\right) $,其中$ \\mathrm{k}_{i} \\in \\mathbb{R}^{k}, \\mathrm{v}_{i} \\in \\mathbb{R}^{v}$.注意力汇聚函数$f$就被表示成值的加权和:\n",
    "\n",
    "$$ f\\left(\\mathrm{q},\\left(\\mathrm{k}_{1}, \\mathrm{v}_{1}\\right), \\ldots,\\left(\\mathrm{k}_{m}, \\mathrm{v}_{m}\\right)\\right)=\\sum^{m} \\alpha\\left(\\mathrm{q}, \\mathrm{k}_{i}\\right) \\mathrm{v}_{i} \\in \\mathbb{R}^{v} $$\n",
    "\n",
    "其中查询$\\mathrm{q}$和键$\\mathrm{k}_i$的注意力权重是通过注意力评分函数$a$将两个向量映射为标量,再经过softmax运算得到:\n",
    "\n",
    "$$ \\alpha\\left(\\mathrm{q}, \\mathrm{k}_{i}\\right)=\\operatorname{softmax}\\left(a\\left(\\mathrm{q}, \\mathrm{k}_{i}\\right)\\right)=\\frac{\\exp \\left(a\\left(\\mathrm{q}, \\mathrm{k}_{i}\\right)\\right)}{\\sum_{j=1}^{m} \\exp \\left(a\\left(\\mathrm{q}, \\mathbf{k}_{j}\\right)\\right)} \\in \\mathbb{R} $$\n",
    "\n",
    "选择不同的注意力评分函数$ a $会导致不同的注意力汇聚操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens=None):\n",
    "    \"\"\"通过在最后⼀个轴上遮蔽元素来执⾏softmax操作\"\"\"\n",
    "\n",
    "    def sequence_mask(X, valid_len, value=0):\n",
    "        \"\"\"Mask irrelevant entries in sequences\"\"\"\n",
    "        maxlen = X.size(1)\n",
    "        # 广播机制\n",
    "        mask = torch.arange(maxlen, device=X.device)[None, :] < valid_len[:, None]\n",
    "        X[~mask] = value\n",
    "        return X\n",
    "\n",
    "    if valid_lens is None:\n",
    "        return F.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 被遮蔽的元素使用⼀个非常大的负值替换,使其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                          value=-1e6)\n",
    "        return F.softmax(X.reshape(shape), dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2713, 0.2097, 0.2698, 0.2491],\n",
      "         [0.1335, 0.3093, 0.2492, 0.3079]],\n",
      "\n",
      "        [[0.2026, 0.3176, 0.2452, 0.2346],\n",
      "         [0.2491, 0.3762, 0.1739, 0.2008]]])\n",
      "\n",
      "tensor([[[0.5013, 0.4987, 0.0000, 0.0000],\n",
      "         [0.3533, 0.6467, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2667, 0.3649, 0.3684, 0.0000],\n",
      "         [0.3093, 0.3334, 0.3573, 0.0000]]])\n",
      "\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2844, 0.3777, 0.3380, 0.0000]],\n",
      "\n",
      "        [[0.6578, 0.3422, 0.0000, 0.0000],\n",
      "         [0.2550, 0.2790, 0.1991, 0.2669]]])\n"
     ]
    }
   ],
   "source": [
    "print(masked_softmax(torch.rand(2, 2, 4)), end='\\n\\n')\n",
    "print(masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3])), end='\\n\\n')\n",
    "print(masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加性注意力\n",
    "\n",
    "当查询和键是不同长度的矢量时,可以使⽤加性注意力作为评分函数.给定查询$ \\mathrm{q} \\in \\mathbb{R}^{1 \\times q} $和键$\\mathrm{k} \\in \\mathbb{R}^{1 \\times k} $,加性注意力(additive attention)的评分函数为:\n",
    "\n",
    "$$ a(\\mathrm{q}, \\mathrm{k})=\\tanh \\left(\\mathrm{q} W_q^T + \\mathrm{k} W_k^T\\right) \\mathrm{w}_{v} \\in \\mathbb{R} $$\n",
    "\n",
    "其中可学习的参数是$ W_q \\in \\mathbb{R}^{h \\times q}, W_k \\in \\mathbb{R}^{h \\times k} $和$\\mathrm{w}_v \\in \\mathbb{R}^{h \\times 1}$.\n",
    "然后将查询和键连接起来后输⼊到⼀个多层感知机(MLP)中,感知机包含⼀个隐藏层,其隐藏单元数是⼀个超参数$h$.通过使用tanh作为激活函数,并且禁用偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 # 键特征数目\n",
    "                 key_size,\n",
    "                 # 查询特征数据\n",
    "                 query_size,\n",
    "                 # 矩阵W_q、W_k,向量w_v输出特征维度\n",
    "                 num_hiddens,\n",
    "                 dropout):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        # self.W_k.weight.shape = (num_hiddens, key_size)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        # self.W_q.weight.shape = (num_hiddens, query_size)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        # self.W_v.weight.shape = (1, num_hiddens)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        \"\"\"\n",
    "        queries: 查询\n",
    "        keys: 键\n",
    "        values: 值\n",
    "        valid_lens: 计算attention_weights的有效长度\n",
    "        \"\"\"\n",
    "        # queries:(b, ?q, query_size) x (query_size, num_hiddens) = (b, ?q, num_hiddens)\n",
    "        # keys:(b, ?k, key_size) x (key_size, num_hiddens) = (b, ?k, num_hiddens)\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # queries.unsqueeze(2).shape=(b, ?q, 1, num_hiddens)\n",
    "        # keys.unsqueeze(1).shape=(b, 1, ?k, num_hiddens)\n",
    "        # features.shape=(b, ?q, ?k, num_hiddens)\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # scores:(b, ?q, ?k, num_hiddens) x (num_hiddens, 1) = (b, ?q, ?k, 1)\n",
    "        # scores.squeeze(-1).shape=(b, ?q, ?k)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values.shape=(b, ?k, ?v)\n",
    "        # 返回值:(b, ?q, ?k) x (b, ?k, ?v) = (b, ?q, ?v)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n\n        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward0>)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# queries.shape(2, 1, 20)\n",
    "# keys.shape=(2, 10, 2)\n",
    "# values.shape=(2, 10, 4)\n",
    "queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "# 最终结果.shape=(2, 1, 4)\n",
    "attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8,\n",
    "                              dropout=0.1)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000]],\n\n        [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000,\n          0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.attention_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(33.0, 0.5, 'Queries')"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 注意力权重\n",
    "_, axes = plt.subplots(1, 1)\n",
    "sns.heatmap(torch.squeeze(attention.attention_weights.detach(), 1), cmap='Reds', ax=axes)\n",
    "axes.set_xlabel('Keys')\n",
    "axes.set_ylabel('Queries')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 缩放点积注意力\n",
    "\n",
    "使用点积可以得到计算效率更⾼的评分函数.但是点积操作要求查询和键具有相同的⻓度$ d $.\n",
    "\n",
    "缩放点注意力(scaled dot-product attention)评分函数:\n",
    "\n",
    "$$ a(\\mathrm{q}, \\mathrm{k})=\\mathrm{q} \\mathrm{k}^T / \\sqrt{d} $$\n",
    "\n",
    "向量化版本:\n",
    "\n",
    "1. $$ Q \\in \\mathbb{R}^{n \\times d}, \\quad K \\in \\mathbb{R}^{m \\times d}, V \\in \\mathbb{R}^{m \\times v} $$\n",
    "\n",
    "2. 注意力分数: $$ a(Q, K)=Q K^{T} / \\sqrt{d} \\in \\mathbb{R}^{n \\times m}$$\n",
    "\n",
    "3. 注意力汇聚:$$ f=\\operatorname{softmax}(a(Q,K)) V \\in \\mathbb{R}^{n \\times v} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力(论文`Attention ls All You Need`的注意力计算方式)\"\"\"\n",
    "\n",
    "    def __init__(self, dropout):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        \"\"\"\n",
    "        queries: 查询\n",
    "        keys: 键\n",
    "        values: 值\n",
    "        valid_lens: 计算attention_weights的有效长度\n",
    "        \"\"\"\n",
    "        # queries.shape = (b, ?q, d)\n",
    "        # keys.shape = (b, ?k, d)\n",
    "        # scores.shape = (b, ?q, d) x (b, d, ?k) = (b, ?q, ?k)\n",
    "        d = queries.shape[-1]\n",
    "        # 除以d的平方根\n",
    "        # 原因:当维度很大时,点积结果会很大,会导致softmax的梯度很小(见softmax-Softmax.ipynb).为了减轻这个影响,对点积进行缩放\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values.shape=(b, ?k, ?v)\n",
    "        # 返回值.shape=(b, ?q, ?k) x (b, ?k, ?v) = (b, ?q, ?v)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n\n        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "keys = torch.ones((2, 10, 2))\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "# 最终结果.shape=(2, 1, 4)\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(33.0, 0.5, 'Queries')"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 注意力权重\n",
    "_, axes = plt.subplots(1, 1)\n",
    "sns.heatmap(torch.squeeze(attention.attention_weights.detach(), 1), cmap='Reds', ax=axes)\n",
    "axes.set_xlabel('Keys')\n",
    "axes.set_ylabel('Queries')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "a = nn.Linear(3, 1, bias=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 # 查询特征数目(E_q)\n",
    "                 query_size,\n",
    "                 # 键特征数目(E_k)\n",
    "                 key_size,\n",
    "                 # 值特征数目(E_v)\n",
    "                 value_size,\n",
    "                 # 多头数\n",
    "                 num_heads, dropout, bias=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        assert query_size % num_heads == 0, \"query_size must be divisible by num_heads\"\n",
    "        # 可学习参数H^2 * 4\n",
    "        self.W_q = nn.Linear(query_size, query_size, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, query_size, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, query_size, bias=bias)\n",
    "        self.W_o = nn.Linear(query_size, query_size, bias=bias)\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose_qkv(X, num_heads):\n",
    "        # 输入:X.shape=(N, L or S, E_q)\n",
    "        # X.shape=(N, L or S, num_heads, E_q / num_heads)\n",
    "        X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "        # X.shape=(N, num_heads, L or S, E_q / num_heads)\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "        # 返回值.shape=(N * num_heads, L or S, E_q / num_heads)\n",
    "        return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        \"\"\"\n",
    "        queries: 查询\n",
    "        keys: 键\n",
    "        values: 值\n",
    "        valid_lens: 计算attention_weights的有效长度\n",
    "        \"\"\"\n",
    "        # queries.shape=(N, L, E_q);L is the target sequence length\n",
    "        # self.W_q(queries).shape=(N, L, E_q)\n",
    "        # queries.shape=(N * num_heads, L, E_q / num_heads)\n",
    "\n",
    "        # keys.shape=(N, S, E_k);S is the source sequence length\n",
    "        # self.W_k(queries).shape=(N, S, E_q)\n",
    "        # keys.shape=(N * num_heads, S, E_q / num_heads)\n",
    "\n",
    "        # values.shape=(N, S, E_v)\n",
    "        # self.W_v(values).shape=(N, S, E_q)\n",
    "        # values.shape=(N * num_heads, S, E_q / num_heads)\n",
    "        queries = self.transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = self.transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = self.transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # E_q维度信息增加到batch_size维度上\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # output.shape=(N * num_heads, L, E_q / num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        # output.shape=(N, num_heads, L, E_q / num_heads)\n",
    "        output = output.reshape(-1, self.num_heads, output.shape[1], output.shape[2])\n",
    "        # output.shape=(N, L, num_heads, E_q / num_heads)\n",
    "        output = output.permute(0, 2, 1, 3)\n",
    "        # output.shape=(N, L, E_q)\n",
    "        output_concat = output.reshape(output.shape[0], output.shape[1], -1)\n",
    "        # 返回值.shape=(N, L, E_q)\n",
    "        return self.W_o(output_concat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "MultiHeadAttention(\n  (W_q): Linear(in_features=100, out_features=100, bias=False)\n  (W_k): Linear(in_features=200, out_features=100, bias=False)\n  (W_v): Linear(in_features=200, out_features=100, bias=False)\n  (W_o): Linear(in_features=100, out_features=100, bias=False)\n  (attention): DotProductAttention(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_size, key_size, value_size, num_heads = 100, 200, 200, 5\n",
    "multi_head_atten = MultiHeadAttention(query_size=query_size,\n",
    "                                      key_size=key_size,\n",
    "                                      value_size=value_size,\n",
    "                                      num_heads=num_heads,\n",
    "                                      dropout=0.1)\n",
    "multi_head_atten.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4, 100])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_queries, num_kvpairs, valid_lens = 2, 4, 6, torch.tensor([3, 2])\n",
    "X = torch.randn((batch_size, num_queries, query_size))\n",
    "Y = torch.randn((batch_size, num_kvpairs, key_size))\n",
    "multi_head_atten(X, Y, Y, valid_lens).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 5, 4, 6])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意力输出权重.shape=(N * num_heads, L, S)\n",
    "# mul_head_att_weight.reshape=(N, num_heads, L, S)\n",
    "mul_head_att_weight = multi_head_atten.attention.attention_weights.reshape(batch_size, num_heads, num_queries,\n",
    "                                                                           num_kvpairs)\n",
    "mul_head_att_weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}