{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': ['For a car, what scams can be plotted with 0% financing vs rebate?',\n",
       "  'Why does it matter if a Central Bank has a negative rather than 0% interest rate?',\n",
       "  'Where should I be investing my money?',\n",
       "  'Specifically when do options expire?',\n",
       "  'Negative Balance from Automatic Options Exercise. What to do?',\n",
       "  'Approximation of equity value for company in default',\n",
       "  'Is it true that 90% of investors lose their money?',\n",
       "  'Can a company charge you for services never requested or received?',\n",
       "  'Working out if I should be registered as self-employed in the UK',\n",
       "  'About eToro investments'],\n",
       " 'input': ['', '', '', '', '', '', '', '', '', ''],\n",
       " 'output': [\"The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.\",\n",
       "  'That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.',\n",
       "  'Pay off your debt.  As you witnessed, no \"investment\" % is guaranteed.  But your debt payments are... so if you have cash, the best way to \"invest\" it is to pay off your debt.  Since your car is depreciating while your house may be appreciating (don\\'t know but it\\'s possible) you should pay off your car loan first.  You\\'re losing money in more than one way on that investment.',\n",
       "  'Equity options, at least those traded in the American exchanges, actually expire the Saturday after the 3rd Friday of the month.  However, the choice to trade or exercise the options must be specified by the 3rd Friday. This is outlined by the CBOE, who oversees the exchange of equity options.  Their FAQ regarding option expiration can be found at http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.',\n",
       "  \"Automatic exercisions can be extremely risky, and the closer to the money the options are, the riskier their exercisions are. It is unlikely that the entire account has negative equity since a responsible broker would forcibly close all positions and pursue the holder for the balance of the debt to reduce solvency risk.  Since the broker has automatically exercised a near the money option, it's solvency policy is already risky. Regardless of whether there is negative equity or simply a liability, the least risky course of action is to sell enough of the underlying to satisfy the loan by closing all other positions if necessary as soon as possible. If there is a negative equity after trying to satisfy the loan, the account will need to be funded for the balance of the loan to pay for purchases of the underlying to fully satisfy the loan. Since the underlying can move in such a way to cause this loan to increase, the account should also be funded as soon as possible if necessary. Accounts after exercise For deep in the money exercised options, a call turns into a long underlying on margin while a put turns into a short underlying. The next decision should be based upon risk and position selection.  First, if the position is no longer attractive, it should be closed.  Since it's deep in the money, simply closing out the exposure to the underlying should extinguish the liability as cash is not marginable, so the cash received from the closing out of the position will repay any margin debt. If the position in the underlying is still attractive then the liability should be managed according to one's liability policy and of course to margin limits. In a margin account, closing the underlying positions on the same day as the exercise will only be considered a day trade.  If the positions are closed on any business day after the exercision, there will be no penalty or restriction. Cash option accounts While this is possible, many brokers force an upgrade to a margin account, and the ShareBuilder Options Account Agreement seems ambiguous, but their options trading page implies the upgrade. In a cash account, equities are not marginable, so any margin will trigger a margin call.  If the margin debt did not trigger a margin call then it is unlikely that it is a cash account as margin for any security in a cash account except for certain options trades is 100%. Equities are convertible to cash presumably at the bid, so during a call exercise, the exercisor or exercisor's broker pays cash for the underlying at the exercise price, and any deficit is financed with debt, thus underlying can be sold to satisfy that debt or be sold for cash as one normally would. To preempt a forced exercise as a call holder, one could short the underlying, but this will be more expensive, and since probably no broker allows shorting against the box because of its intended use to circumvent capital gains taxes by fraud.  The least expensive way to trade out of options positions is to close them themselves rather than take delivery.\",\n",
       "  'Generally \"default\" means that the company cannot pay off their debts, and since debt holders get paid before equity holders, their equity would be effectively worthless. That said, companies can emerge from Chapter 11 bankruptcy (reorganization) and retain equity value, but it is rare. Most times, stocks are de-listed or frozen on stock exchanges, and company\\'s reorganization plan will cancel all existing equity shares, instead focusing all of their attention on paying back as much debt as possible. If the company issues new equity after reorganizing, it might provide a way for holders of the original equity to exchange their shares for the new equity, but it is rare, and the value is usually significantly less that the value of the original equity.',\n",
       "  'The game is not zero sum. When a friend and I chop down a tree, and build a house from it, the house has value, far greater than the value of a standing tree. Our labor has turned into something of value.  In theory, a company starts from an idea, and offers either a good or service to create value. There are scams that make it seem like a Vegas casino. There are times a stock will trade for well above what it should. When I buy the S&P index at a fair price for 1000 (through an etf or fund) and years later it\\'s 1400, the gain isn\\'t out of someone else\\'s pocket, else the amount of wealth in the world would be fixed and that\\'s not the case. Over time, investors lag the market return for multiple reasons, trading costs, bad timing, etc. Statements such as \"90% lose money\" are hyperbole meant to separate you from your money. A self fulfilling prophesy.   The question of lagging the market is another story - I have no data to support my observation, but I\\'d imagine that well over 90% lag the broad market. A detailed explanation is too long for this forum, but simply put, there are trading costs. If I invest in an S&P ETF that costs .1% per year, I\\'ll see a return of say 9.9% over decades if the market return is 10%. Over 40 years, this is 4364% compounded, vs the index 4526% compounded, a difference of less than 4% in final wealth. There are load funds that charge more than this just to buy in (5% anyone?).  Lagging by a small fraction is a far cry from \\'losing money.\\'  There is an annual report by a company named Dalbar that tracks investor performance. For the 20 year period ending 12/31/10 the S&P returned 9.14% and Dalbar calculates the average investor had an average return of 3.83%. Pretty bad, but not zero. Since you don\\'t cite a particular article or source, there may be more to the story. Day traders are likely to lose. As are a series of other types of traders in other markets, Forex for one.  While your question may be interesting, its premise of \"many experts say....\" without naming even one leaves room for doubt.  Note - I\\'ve updated the link for the 2015 report. And 4 years later, I see that when searching on that 90% statistic, the articles are about day traders. That actually makes sense to me.',\n",
       "  \"In general, you can only be charged for services if there is some kind of contract. The contract doesn't have to be written, but you have to have agreed to it somehow. However, it is possible that you entered into a contract due to some clause in the home purchase contract or the contract with the home owners' association. There are also sometimes services you are legally required to get, such as regular inspection of heating furnaces (though I don't think this translates to automatic contracts). But in any case you would not be liable for services rendered before you entered into the contract, which sounds like it's the case here.\",\n",
       "  'Being self employed just means you fill out some more forms in your annual self assessment for your \"profit\" from being self employed.  Profit = all the money you receive, minus any tax deductible cost that you spent for making that money (and all the cost must be documented, which means you have a folder with all the receipts and keep it safe). You pay normal income tax on all the profit, which means it is just added to your taxable income. What you do with the profit is up to you; you don\\'t pay yourself a salary, just take the money (make sure you leave enough to pay your taxes).',\n",
       "  'For eToro, just like any other brokerage firm, you can lose your entire capital. I suggest that you invest in one or more exchange-traded funds that track major indexes.  If not, just put your money in fixed deposit accounts; gain a bit of interest and establish an emergency fund first before investing money that you feel you are able to lose.'],\n",
       " 'text': ['', '', '', '', '', '', '', '', '', '']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(path='gbharti/finance-alpaca', split='train')\n",
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('E:\\huggingface_models\\Qwen2.5-0.5B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 68912\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_func(example):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a financial advisor.\"},\n",
    "        {\"role\": \"user\", \"content\": example['instruction'].strip()}\n",
    "    ]\n",
    "    instruction = tokenizer.apply_chat_template(conversation=messages,\n",
    "                                                add_generation_prompt=True,\n",
    "                                                tokenize=True,\n",
    "                                                return_dict=True)\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(process_func)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels', 'yy'],\n",
       "    num_rows: 68912\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.remove_columns(['instruction', 'input', 'output', 'text'])\n",
    "train_dataset = train_dataset.add_column('yy', list(range(0, len(train_dataset))))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': [151644, 8948, 198, 2610, 525, 264, 5896, 36613, 13, 151645, 198, 151644, 872, 198, 2461, 264, 1803, 11, 1128, 63055, 646, 387, 67583, 448, 220, 15, 4, 28542, 6165, 89946, 30, 151645, 198, 151644, 77091, 198, 785, 1803, 3484, 3643, 3220, 220, 18, 5510, 13, 1416, 498, 2291, 304, 825, 48529, 8160, 13, 1416, 279, 8160, 374, 7046, 1091, 1128, 807, 7171, 369, 279, 1803, 11, 5519, 862, 18024, 11, 807, 1281, 264, 11372, 13, 2379, 11679, 498, 279, 3220, 13, 1446, 1281, 14173, 916, 3951, 476, 1635, 11, 421, 279, 2790, 3311, 498, 2291, 374, 7046, 1091, 1128, 807, 7171, 369, 279, 1803, 11, 5519, 862, 18024, 11, 5519, 862, 17017, 18024, 807, 1281, 3220, 13, 4940, 3308, 279, 3220, 4990, 1635, 311, 2525, 304, 11, 476, 807, 4559, 697, 11679, 311, 2441, 2562, 311, 633, 279, 3220, 10596, 714, 304, 264, 9155, 3311, 13, 1446, 6559, 304, 264, 1803, 323, 807, 4559, 432, 518, 264, 11372, 13, 4940, 3308, 429, 501, 7745, 1410, 387, 264, 48529, 2629, 476, 264, 11679, 389, 279, 1483, 1803, 1112, 2379, 476, 3308, 1281, 3220, 421, 498, 4446, 279, 1803, 1182, 369, 13404, 11, 476, 498, 3695, 10077, 315, 11392, 23321, 2606, 13, 4329, 26199, 12060, 1378, 12506, 304, 4065, 315, 498, 25, 633, 264, 220, 15, 4, 2734, 11679, 13, 4220, 8376, 311, 387, 23327, 220, 16, 17, 3951, 6165, 220, 18, 21, 11, 19, 23, 11, 21, 15, 476, 1496, 220, 22, 17, 3951, 13, 576, 23327, 3084, 3643, 432, 15750, 369, 1657, 311, 9946, 13, 1416, 498, 646, 944, 18806, 279, 220, 16, 17, 3460, 14173, 807, 3010, 498, 518, 856, 4, 11679, 369, 379, 1635, 429, 13598, 279, 14173, 304, 697, 8039, 13, 2291, 8350, 323, 633, 264, 89946, 13, 1416, 498, 1896, 279, 89946, 498, 646, 944, 633, 279, 220, 15, 4, 11679, 13, 1416, 498, 1896, 279, 220, 15, 4, 11679, 498, 646, 944, 633, 279, 89946, 13, 576, 3349, 498, 36567, 27283, 279, 89946, 374, 3322, 311, 1281, 264, 11372, 13, 576, 1376, 374, 537, 20194, 1105, 1414, 892, 3010, 498, 525, 8014, 304, 13, 4320, 944, 1496, 6286, 264, 6559, 304, 3080, 279, 3349, 315, 279, 501, 1803, 702, 1012, 60387, 13, 18214, 807, 686, 7500, 279, 3349, 11, 89946, 11, 2734, 4379, 11, 3084, 315, 11679, 11, 220, 323, 6559, 3419, 897, 311, 34508, 862, 11372, 13, 576, 23776, 315, 4303, 279, 5109, 1526, 264, 45886, 374, 264, 1661, 825, 13, 1416, 498, 633, 264, 11679, 369, 220, 17, 4, 504, 697, 6073, 14, 23311, 11300, 369, 220, 18, 1635, 323, 279, 89946, 504, 279, 23321, 11, 432, 686, 2783, 2686, 304, 2790, 1091, 279, 220, 15, 4, 11679, 504, 279, 23321, 13, 576, 1376, 374, 311, 633, 279, 11679, 11792, 553, 279, 6073, 14, 23311, 11300, 1573, 6438, 448, 279, 23321, 13, 576, 3220, 504, 279, 6073, 5868, 1075, 8350, 311, 279, 23321, 13, 151645], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'yy': 0}, {'input_ids': [151644, 8948, 198, 2610, 525, 264, 5896, 36613, 13, 151645, 198, 151644, 872, 198, 10234, 1558, 432, 4925, 421, 264, 10684, 8547, 702, 264, 8225, 4751, 1091, 220, 15, 4, 2734, 4379, 30, 151645, 198, 151644, 77091, 198, 4792, 374, 3093, 315, 279, 1459, 11, 825, 315, 279, 16005, 374, 429, 432, 82984, 4756, 13959, 311, 2936, 27572, 3220, 323, 1191, 87285, 432, 1119, 279, 8584, 5577, 13, 58713, 311, 279, 7513, 10684, 8547, 24965, 5961, 1119, 279, 8584, 279, 1616, 279, 2274, 8622, 6073, 702, 1012, 3730, 13, 320, 785, 12137, 24785, 11833, 20846, 21411, 33819, 8, 1913, 264, 3146, 2188, 11, 3842, 7513, 5837, 614, 6679, 419, 1573, 304, 3213, 3039, 448, 902, 42326, 2456, 13, 151645], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'yy': 1}]\n",
      "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,   5896,  36613,     13,\n",
      "         151645,    198, 151644,    872,    198,   2461,    264,   1803,     11,\n",
      "           1128,  63055,    646,    387,  67583,    448,    220,     15,      4,\n",
      "          28542,   6165,  89946,     30, 151645,    198, 151644,  77091,    198,\n",
      "            785,   1803,   3484,   3643,   3220,    220,     18,   5510,     13,\n",
      "           1416,    498,   2291,    304,    825,  48529,   8160,     13,   1416,\n",
      "            279,   8160,    374,   7046,   1091,   1128,    807,   7171,    369,\n",
      "            279,   1803,     11,   5519,    862,  18024,     11,    807,   1281,\n",
      "            264,  11372,     13,   2379,  11679,    498,    279,   3220,     13,\n",
      "           1446,   1281,  14173,    916,   3951,    476,   1635,     11,    421,\n",
      "            279,   2790,   3311,    498,   2291,    374,   7046,   1091,   1128,\n",
      "            807,   7171,    369,    279,   1803,     11,   5519,    862,  18024,\n",
      "             11,   5519,    862,  17017,  18024,    807,   1281,   3220,     13,\n",
      "           4940,   3308,    279,   3220,   4990,   1635,    311,   2525,    304,\n",
      "             11,    476,    807,   4559,    697,  11679,    311,   2441,   2562,\n",
      "            311,    633,    279,   3220,  10596,    714,    304,    264,   9155,\n",
      "           3311,     13,   1446,   6559,    304,    264,   1803,    323,    807,\n",
      "           4559,    432,    518,    264,  11372,     13,   4940,   3308,    429,\n",
      "            501,   7745,   1410,    387,    264,  48529,   2629,    476,    264,\n",
      "          11679,    389,    279,   1483,   1803,   1112,   2379,    476,   3308,\n",
      "           1281,   3220,    421,    498,   4446,    279,   1803,   1182,    369,\n",
      "          13404,     11,    476,    498,   3695,  10077,    315,  11392,  23321,\n",
      "           2606,     13,   4329,  26199,  12060,   1378,  12506,    304,   4065,\n",
      "            315,    498,     25,    633,    264,    220,     15,      4,   2734,\n",
      "          11679,     13,   4220,   8376,    311,    387,  23327,    220,     16,\n",
      "             17,   3951,   6165,    220,     18,     21,     11,     19,     23,\n",
      "             11,     21,     15,    476,   1496,    220,     22,     17,   3951,\n",
      "             13,    576,  23327,   3084,   3643,    432,  15750,    369,   1657,\n",
      "            311,   9946,     13,   1416,    498,    646,    944,  18806,    279,\n",
      "            220,     16,     17,   3460,  14173,    807,   3010,    498,    518,\n",
      "            856,      4,  11679,    369,    379,   1635,    429,  13598,    279,\n",
      "          14173,    304,    697,   8039,     13,   2291,   8350,    323,    633,\n",
      "            264,  89946,     13,   1416,    498,   1896,    279,  89946,    498,\n",
      "            646,    944,    633,    279,    220,     15,      4,  11679,     13,\n",
      "           1416,    498,   1896,    279,    220,     15,      4,  11679,    498,\n",
      "            646,    944,    633,    279,  89946,     13,    576,   3349,    498,\n",
      "          36567,  27283,    279,  89946,    374,   3322,    311,   1281,    264,\n",
      "          11372,     13,    576,   1376,    374,    537,  20194,   1105,   1414,\n",
      "            892,   3010,    498,    525,   8014,    304,     13,   4320,    944,\n",
      "           1496,   6286,    264,   6559,    304,   3080,    279,   3349,    315,\n",
      "            279,    501,   1803,    702,   1012,  60387,     13,  18214,    807,\n",
      "            686,   7500,    279,   3349,     11,  89946,     11,   2734,   4379,\n",
      "             11,   3084,    315,  11679,     11,    220,    323,   6559,   3419,\n",
      "            897,    311,  34508,    862,  11372,     13,    576,  23776,    315,\n",
      "           4303,    279,   5109,   1526,    264,  45886,    374,    264,   1661,\n",
      "            825,     13,   1416,    498,    633,    264,  11679,    369,    220,\n",
      "             17,      4,    504,    697,   6073,     14,  23311,  11300,    369,\n",
      "            220,     18,   1635,    323,    279,  89946,    504,    279,  23321,\n",
      "             11,    432,    686,   2783,   2686,    304,   2790,   1091,    279,\n",
      "            220,     15,      4,  11679,    504,    279,  23321,     13,    576,\n",
      "           1376,    374,    311,    633,    279,  11679,  11792,    553,    279,\n",
      "           6073,     14,  23311,  11300,   1573,   6438,    448,    279,  23321,\n",
      "             13,    576,   3220,    504,    279,   6073,   5868,   1075,   8350,\n",
      "            311,    279,  23321,     13, 151645],\n",
      "        [151644,   8948,    198,   2610,    525,    264,   5896,  36613,     13,\n",
      "         151645,    198, 151644,    872,    198,  10234,   1558,    432,   4925,\n",
      "            421,    264,  10684,   8547,    702,    264,   8225,   4751,   1091,\n",
      "            220,     15,      4,   2734,   4379,     30, 151645,    198, 151644,\n",
      "          77091,    198,   4792,    374,   3093,    315,    279,   1459,     11,\n",
      "            825,    315,    279,  16005,    374,    429,    432,  82984,   4756,\n",
      "          13959,    311,   2936,  27572,   3220,    323,   1191,  87285,    432,\n",
      "           1119,    279,   8584,   5577,     13,  58713,    311,    279,   7513,\n",
      "          10684,   8547,  24965,   5961,   1119,    279,   8584,    279,   1616,\n",
      "            279,   2274,   8622,   6073,    702,   1012,   3730,     13,    320,\n",
      "            785,  12137,  24785,  11833,  20846,  21411,  33819,      8,   1913,\n",
      "            264,   3146,   2188,     11,   3842,   7513,   5837,    614,   6679,\n",
      "            419,   1573,    304,   3213,   3039,    448,    902,  42326,   2456,\n",
      "             13, 151645, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'yy': tensor([0, 1])}\n",
      "dict_keys(['input_ids', 'attention_mask', 'yy', 'labels'])\n",
      "tensor([[151644,   8948,    198,   2610,    525,    264,   5896,  36613,     13,\n",
      "         151645,    198, 151644,    872,    198,   2461,    264,   1803,     11,\n",
      "           1128,  63055,    646,    387,  67583,    448,    220,     15,      4,\n",
      "          28542,   6165,  89946,     30, 151645,    198, 151644,  77091,    198,\n",
      "            785,   1803,   3484,   3643,   3220,    220,     18,   5510,     13,\n",
      "           1416,    498,   2291,    304,    825,  48529,   8160,     13,   1416,\n",
      "            279,   8160,    374,   7046,   1091,   1128,    807,   7171,    369,\n",
      "            279,   1803,     11,   5519,    862,  18024,     11,    807,   1281,\n",
      "            264,  11372,     13,   2379,  11679,    498,    279,   3220,     13,\n",
      "           1446,   1281,  14173,    916,   3951,    476,   1635,     11,    421,\n",
      "            279,   2790,   3311,    498,   2291,    374,   7046,   1091,   1128,\n",
      "            807,   7171,    369,    279,   1803,     11,   5519,    862,  18024,\n",
      "             11,   5519,    862,  17017,  18024,    807,   1281,   3220,     13,\n",
      "           4940,   3308,    279,   3220,   4990,   1635,    311,   2525,    304,\n",
      "             11,    476,    807,   4559,    697,  11679,    311,   2441,   2562,\n",
      "            311,    633,    279,   3220,  10596,    714,    304,    264,   9155,\n",
      "           3311,     13,   1446,   6559,    304,    264,   1803,    323,    807,\n",
      "           4559,    432,    518,    264,  11372,     13,   4940,   3308,    429,\n",
      "            501,   7745,   1410,    387,    264,  48529,   2629,    476,    264,\n",
      "          11679,    389,    279,   1483,   1803,   1112,   2379,    476,   3308,\n",
      "           1281,   3220,    421,    498,   4446,    279,   1803,   1182,    369,\n",
      "          13404,     11,    476,    498,   3695,  10077,    315,  11392,  23321,\n",
      "           2606,     13,   4329,  26199,  12060,   1378,  12506,    304,   4065,\n",
      "            315,    498,     25,    633,    264,    220,     15,      4,   2734,\n",
      "          11679,     13,   4220,   8376,    311,    387,  23327,    220,     16,\n",
      "             17,   3951,   6165,    220,     18,     21,     11,     19,     23,\n",
      "             11,     21,     15,    476,   1496,    220,     22,     17,   3951,\n",
      "             13,    576,  23327,   3084,   3643,    432,  15750,    369,   1657,\n",
      "            311,   9946,     13,   1416,    498,    646,    944,  18806,    279,\n",
      "            220,     16,     17,   3460,  14173,    807,   3010,    498,    518,\n",
      "            856,      4,  11679,    369,    379,   1635,    429,  13598,    279,\n",
      "          14173,    304,    697,   8039,     13,   2291,   8350,    323,    633,\n",
      "            264,  89946,     13,   1416,    498,   1896,    279,  89946,    498,\n",
      "            646,    944,    633,    279,    220,     15,      4,  11679,     13,\n",
      "           1416,    498,   1896,    279,    220,     15,      4,  11679,    498,\n",
      "            646,    944,    633,    279,  89946,     13,    576,   3349,    498,\n",
      "          36567,  27283,    279,  89946,    374,   3322,    311,   1281,    264,\n",
      "          11372,     13,    576,   1376,    374,    537,  20194,   1105,   1414,\n",
      "            892,   3010,    498,    525,   8014,    304,     13,   4320,    944,\n",
      "           1496,   6286,    264,   6559,    304,   3080,    279,   3349,    315,\n",
      "            279,    501,   1803,    702,   1012,  60387,     13,  18214,    807,\n",
      "            686,   7500,    279,   3349,     11,  89946,     11,   2734,   4379,\n",
      "             11,   3084,    315,  11679,     11,    220,    323,   6559,   3419,\n",
      "            897,    311,  34508,    862,  11372,     13,    576,  23776,    315,\n",
      "           4303,    279,   5109,   1526,    264,  45886,    374,    264,   1661,\n",
      "            825,     13,   1416,    498,    633,    264,  11679,    369,    220,\n",
      "             17,      4,    504,    697,   6073,     14,  23311,  11300,    369,\n",
      "            220,     18,   1635,    323,    279,  89946,    504,    279,  23321,\n",
      "             11,    432,    686,   2783,   2686,    304,   2790,   1091,    279,\n",
      "            220,     15,      4,  11679,    504,    279,  23321,     13,    576,\n",
      "           1376,    374,    311,    633,    279,  11679,  11792,    553,    279,\n",
      "           6073,     14,  23311,  11300,   1573,   6438,    448,    279,  23321,\n",
      "             13,    576,   3220,    504,    279,   6073,   5868,   1075,   8350,\n",
      "            311,    279,  23321,     13, 151645],\n",
      "        [151644,   8948,    198,   2610,    525,    264,   5896,  36613,     13,\n",
      "         151645,    198, 151644,    872,    198,  10234,   1558,    432,   4925,\n",
      "            421,    264,  10684,   8547,    702,    264,   8225,   4751,   1091,\n",
      "            220,     15,      4,   2734,   4379,     30, 151645,    198, 151644,\n",
      "          77091,    198,   4792,    374,   3093,    315,    279,   1459,     11,\n",
      "            825,    315,    279,  16005,    374,    429,    432,  82984,   4756,\n",
      "          13959,    311,   2936,  27572,   3220,    323,   1191,  87285,    432,\n",
      "           1119,    279,   8584,   5577,     13,  58713,    311,    279,   7513,\n",
      "          10684,   8547,  24965,   5961,   1119,    279,   8584,    279,   1616,\n",
      "            279,   2274,   8622,   6073,    702,   1012,   3730,     13,    320,\n",
      "            785,  12137,  24785,  11833,  20846,  21411,  33819,      8,   1913,\n",
      "            264,   3146,   2188,     11,   3842,   7513,   5837,    614,   6679,\n",
      "            419,   1573,    304,   3213,   3039,    448,    902,  42326,   2456,\n",
      "             13, 151645, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])\n",
      "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "            785,   1803,   3484,   3643,   3220,    220,     18,   5510,     13,\n",
      "           1416,    498,   2291,    304,    825,  48529,   8160,     13,   1416,\n",
      "            279,   8160,    374,   7046,   1091,   1128,    807,   7171,    369,\n",
      "            279,   1803,     11,   5519,    862,  18024,     11,    807,   1281,\n",
      "            264,  11372,     13,   2379,  11679,    498,    279,   3220,     13,\n",
      "           1446,   1281,  14173,    916,   3951,    476,   1635,     11,    421,\n",
      "            279,   2790,   3311,    498,   2291,    374,   7046,   1091,   1128,\n",
      "            807,   7171,    369,    279,   1803,     11,   5519,    862,  18024,\n",
      "             11,   5519,    862,  17017,  18024,    807,   1281,   3220,     13,\n",
      "           4940,   3308,    279,   3220,   4990,   1635,    311,   2525,    304,\n",
      "             11,    476,    807,   4559,    697,  11679,    311,   2441,   2562,\n",
      "            311,    633,    279,   3220,  10596,    714,    304,    264,   9155,\n",
      "           3311,     13,   1446,   6559,    304,    264,   1803,    323,    807,\n",
      "           4559,    432,    518,    264,  11372,     13,   4940,   3308,    429,\n",
      "            501,   7745,   1410,    387,    264,  48529,   2629,    476,    264,\n",
      "          11679,    389,    279,   1483,   1803,   1112,   2379,    476,   3308,\n",
      "           1281,   3220,    421,    498,   4446,    279,   1803,   1182,    369,\n",
      "          13404,     11,    476,    498,   3695,  10077,    315,  11392,  23321,\n",
      "           2606,     13,   4329,  26199,  12060,   1378,  12506,    304,   4065,\n",
      "            315,    498,     25,    633,    264,    220,     15,      4,   2734,\n",
      "          11679,     13,   4220,   8376,    311,    387,  23327,    220,     16,\n",
      "             17,   3951,   6165,    220,     18,     21,     11,     19,     23,\n",
      "             11,     21,     15,    476,   1496,    220,     22,     17,   3951,\n",
      "             13,    576,  23327,   3084,   3643,    432,  15750,    369,   1657,\n",
      "            311,   9946,     13,   1416,    498,    646,    944,  18806,    279,\n",
      "            220,     16,     17,   3460,  14173,    807,   3010,    498,    518,\n",
      "            856,      4,  11679,    369,    379,   1635,    429,  13598,    279,\n",
      "          14173,    304,    697,   8039,     13,   2291,   8350,    323,    633,\n",
      "            264,  89946,     13,   1416,    498,   1896,    279,  89946,    498,\n",
      "            646,    944,    633,    279,    220,     15,      4,  11679,     13,\n",
      "           1416,    498,   1896,    279,    220,     15,      4,  11679,    498,\n",
      "            646,    944,    633,    279,  89946,     13,    576,   3349,    498,\n",
      "          36567,  27283,    279,  89946,    374,   3322,    311,   1281,    264,\n",
      "          11372,     13,    576,   1376,    374,    537,  20194,   1105,   1414,\n",
      "            892,   3010,    498,    525,   8014,    304,     13,   4320,    944,\n",
      "           1496,   6286,    264,   6559,    304,   3080,    279,   3349,    315,\n",
      "            279,    501,   1803,    702,   1012,  60387,     13,  18214,    807,\n",
      "            686,   7500,    279,   3349,     11,  89946,     11,   2734,   4379,\n",
      "             11,   3084,    315,  11679,     11,    220,    323,   6559,   3419,\n",
      "            897,    311,  34508,    862,  11372,     13,    576,  23776,    315,\n",
      "           4303,    279,   5109,   1526,    264,  45886,    374,    264,   1661,\n",
      "            825,     13,   1416,    498,    633,    264,  11679,    369,    220,\n",
      "             17,      4,    504,    697,   6073,     14,  23311,  11300,    369,\n",
      "            220,     18,   1635,    323,    279,  89946,    504,    279,  23321,\n",
      "             11,    432,    686,   2783,   2686,    304,   2790,   1091,    279,\n",
      "            220,     15,      4,  11679,    504,    279,  23321,     13,    576,\n",
      "           1376,    374,    311,    633,    279,  11679,  11792,    553,    279,\n",
      "           6073,     14,  23311,  11300,   1573,   6438,    448,    279,  23321,\n",
      "             13,    576,   3220,    504,    279,   6073,   5868,   1075,   8350,\n",
      "            311,    279,  23321,     13, 151645],\n",
      "        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   4792,    374,   3093,    315,    279,   1459,     11,\n",
      "            825,    315,    279,  16005,    374,    429,    432,  82984,   4756,\n",
      "          13959,    311,   2936,  27572,   3220,    323,   1191,  87285,    432,\n",
      "           1119,    279,   8584,   5577,     13,  58713,    311,    279,   7513,\n",
      "          10684,   8547,  24965,   5961,   1119,    279,   8584,    279,   1616,\n",
      "            279,   2274,   8622,   6073,    702,   1012,   3730,     13,    320,\n",
      "            785,  12137,  24785,  11833,  20846,  21411,  33819,      8,   1913,\n",
      "            264,   3146,   2188,     11,   3842,   7513,   5837,    614,   6679,\n",
      "            419,   1573,    304,   3213,   3039,    448,    902,  42326,   2456,\n",
      "             13, 151645,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
      "           -100,   -100,   -100,   -100,   -100]])\n"
     ]
    }
   ],
   "source": [
    "dac = Data.DataLoader(train_dataset, \n",
    "                      # Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "                      collate_fn=DataCollatorForSeq2Seq(tokenizer=tokenizer,\n",
    "                                                        padding=True  # padding=True\n",
    "                                                        ), \n",
    "                      batch_size=2)\n",
    "\n",
    "for i in dac:\n",
    "    print(i.keys())\n",
    "    print(i['input_ids'])\n",
    "    print(i['attention_mask'])\n",
    "    print(i['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
