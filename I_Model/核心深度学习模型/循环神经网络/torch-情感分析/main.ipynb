{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torchtext.legacy import data\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import datasets\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torchtext.legacy.datasets.imdb.IMDB at 0x2b0e1c9af10>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"定义分词操作\"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "TEXT = data.Field(tokenize=tokenizer, include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, unk_token=None, dtype=torch.float32)\n",
    "\n",
    "# 创造情感分析数据集\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)  # load the IMDb dataset(电影评论数据集)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n",
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# 数据集的长度\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "print(len(train_data.examples))\n",
    "print(len(test_data.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['Bromwell',\n 'High',\n 'is',\n 'a',\n 'cartoon',\n 'comedy',\n '.',\n 'It',\n 'ran',\n 'at',\n 'the',\n 'same',\n 'time',\n 'as',\n 'some',\n 'other',\n 'programs',\n 'about',\n 'school',\n 'life',\n ',',\n 'such',\n 'as',\n '\"',\n 'Teachers',\n '\"',\n '.',\n 'My',\n '35',\n 'years',\n 'in',\n 'the',\n 'teaching',\n 'profession',\n 'lead',\n 'me',\n 'to',\n 'believe',\n 'that',\n 'Bromwell',\n 'High',\n \"'s\",\n 'satire',\n 'is',\n 'much',\n 'closer',\n 'to',\n 'reality',\n 'than',\n 'is',\n '\"',\n 'Teachers',\n '\"',\n '.',\n 'The',\n 'scramble',\n 'to',\n 'survive',\n 'financially',\n ',',\n 'the',\n 'insightful',\n 'students',\n 'who',\n 'can',\n 'see',\n 'right',\n 'through',\n 'their',\n 'pathetic',\n 'teachers',\n \"'\",\n 'pomp',\n ',',\n 'the',\n 'pettiness',\n 'of',\n 'the',\n 'whole',\n 'situation',\n ',',\n 'all',\n 'remind',\n 'me',\n 'of',\n 'the',\n 'schools',\n 'I',\n 'knew',\n 'and',\n 'their',\n 'students',\n '.',\n 'When',\n 'I',\n 'saw',\n 'the',\n 'episode',\n 'in',\n 'which',\n 'a',\n 'student',\n 'repeatedly',\n 'tried',\n 'to',\n 'burn',\n 'down',\n 'the',\n 'school',\n ',',\n 'I',\n 'immediately',\n 'recalled',\n '.........',\n 'at',\n '..........',\n 'High',\n '.',\n 'A',\n 'classic',\n 'line',\n ':',\n 'INSPECTOR',\n ':',\n 'I',\n \"'m\",\n 'here',\n 'to',\n 'sack',\n 'one',\n 'of',\n 'your',\n 'teachers',\n '.',\n 'STUDENT',\n ':',\n 'Welcome',\n 'to',\n 'Bromwell',\n 'High',\n '.',\n 'I',\n 'expect',\n 'that',\n 'many',\n 'adults',\n 'of',\n 'my',\n 'age',\n 'think',\n 'that',\n 'Bromwell',\n 'High',\n 'is',\n 'far',\n 'fetched',\n '.',\n 'What',\n 'a',\n 'pity',\n 'that',\n 'it',\n 'is',\n \"n't\",\n '!']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.examples[0].text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'pos'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<torchtext.legacy.datasets.imdb.IMDB at 0x2b0e1c9af10>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '\"', 'Teachers', '\"', '.', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', 'High', \"'s\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"', 'Teachers', '\"', '.', 'The', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'pomp', ',', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students', '.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High', '.', 'A', 'classic', 'line', ':', 'INSPECTOR', ':', 'I', \"'m\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', '.', 'STUDENT', ':', 'Welcome', 'to', 'Bromwell', 'High', '.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched', '.', 'What', 'a', 'pity', 'that', 'it', 'is', \"n't\", '!']\n",
      "165\n",
      "490\n",
      "177\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print(train_data.examples[0].text)  # 每条数据的文本\n",
    "\n",
    "print(len(train_data.examples[0].text))\n",
    "print(len(train_data.examples[1].text))\n",
    "print(len(train_data.examples[2].text))\n",
    "print(len(train_data.examples[3].text))  # 每条数据的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'pos'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.examples[0].label  # 每条数据的标签,这里为积极的情感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = train_data.split(random_state=np.random.seed(1))  # 划分训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_dataset)}')\n",
    "print(f'Number of validation examples: {len(valid_dataset)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立词表\n",
    "TEXT.build_vocab(train_dataset, max_size=25000, vectors=\"glove.6B.100d\",\n",
    "                 unk_init=torch.Tensor.normal_,\n",
    "                 vectors_cache=r'C:\\Users\\duanm\\Music\\GitHubProjects\\MLNote\\E_PyTorch\\高阶操作及深度学习相关理论\\torchtext自然语言处理\\.vector_cache')\n",
    "LABEL.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x000002B0F3935DF0>>,\n            {'<unk>': 0,\n             '<pad>': 1,\n             'the': 2,\n             ',': 3,\n             '.': 4,\n             'and': 5,\n             'a': 6,\n             'of': 7,\n             'to': 8,\n             'is': 9,\n             'in': 10,\n             'I': 11,\n             'it': 12,\n             'that': 13,\n             '\"': 14,\n             \"'s\": 15,\n             'this': 16,\n             '-': 17,\n             '/><br': 18,\n             'was': 19,\n             'as': 20,\n             'movie': 21,\n             'with': 22,\n             'for': 23,\n             'film': 24,\n             'The': 25,\n             'but': 26,\n             '(': 27,\n             'on': 28,\n             \"n't\": 29,\n             ')': 30,\n             'you': 31,\n             'are': 32,\n             'not': 33,\n             'have': 34,\n             'his': 35,\n             'be': 36,\n             'he': 37,\n             'one': 38,\n             'at': 39,\n             'by': 40,\n             '!': 41,\n             'all': 42,\n             'who': 43,\n             'an': 44,\n             'they': 45,\n             'from': 46,\n             'like': 47,\n             'so': 48,\n             'her': 49,\n             \"'\": 50,\n             'or': 51,\n             'about': 52,\n             'has': 53,\n             'out': 54,\n             'It': 55,\n             'just': 56,\n             'do': 57,\n             '?': 58,\n             'some': 59,\n             'good': 60,\n             'more': 61,\n             'would': 62,\n             'very': 63,\n             'up': 64,\n             'what': 65,\n             'This': 66,\n             'there': 67,\n             'time': 68,\n             'can': 69,\n             'when': 70,\n             'which': 71,\n             'she': 72,\n             'had': 73,\n             'really': 74,\n             'if': 75,\n             'only': 76,\n             'story': 77,\n             'their': 78,\n             'were': 79,\n             'see': 80,\n             'even': 81,\n             'no': 82,\n             'my': 83,\n             'does': 84,\n             'did': 85,\n             'me': 86,\n             'than': 87,\n             '...': 88,\n             'much': 89,\n             ':': 90,\n             'could': 91,\n             'get': 92,\n             'been': 93,\n             'into': 94,\n             'well': 95,\n             'other': 96,\n             'we': 97,\n             'will': 98,\n             'bad': 99,\n             'because': 100,\n             'him': 101,\n             'people': 102,\n             'great': 103,\n             'made': 104,\n             'most': 105,\n             'first': 106,\n             'make': 107,\n             'them': 108,\n             'also': 109,\n             'way': 110,\n             'how': 111,\n             '<': 112,\n             'br': 113,\n             'its': 114,\n             'too': 115,\n             'any': 116,\n             'movies': 117,\n             '/>The': 118,\n             'think': 119,\n             'characters': 120,\n             'character': 121,\n             'then': 122,\n             'films': 123,\n             ';': 124,\n             'two': 125,\n             'But': 126,\n             'seen': 127,\n             'watch': 128,\n             'plot': 129,\n             'being': 130,\n             'life': 131,\n             'acting': 132,\n             'many': 133,\n             'never': 134,\n             'know': 135,\n             'little': 136,\n             'after': 137,\n             'And': 138,\n             'over': 139,\n             'where': 140,\n             'show': 141,\n             'love': 142,\n             'off': 143,\n             'best': 144,\n             '*': 145,\n             'ever': 146,\n             'better': 147,\n             'A': 148,\n             'your': 149,\n             'should': 150,\n             'say': 151,\n             'end': 152,\n             'i': 153,\n             'There': 154,\n             'He': 155,\n             'scene': 156,\n             'scenes': 157,\n             'still': 158,\n             'such': 159,\n             'In': 160,\n             'here': 161,\n             'man': 162,\n             '/': 163,\n             \"'ve\": 164,\n             'something': 165,\n             'go': 166,\n             'through': 167,\n             'back': 168,\n             'these': 169,\n             \"'m\": 170,\n             'real': 171,\n             'those': 172,\n             'actors': 173,\n             'If': 174,\n             'watching': 175,\n             'thing': 176,\n             'work': 177,\n             'years': 178,\n             'old': 179,\n             'find': 180,\n             'makes': 181,\n             '--': 182,\n             'funny': 183,\n             'going': 184,\n             'though': 185,\n             'actually': 186,\n             'few': 187,\n             'before': 188,\n             'same': 189,\n             'why': 190,\n             'lot': 191,\n             'look': 192,\n             'director': 193,\n             'while': 194,\n             'cast': 195,\n             'part': 196,\n             'nothing': 197,\n             'want': 198,\n             'another': 199,\n             '/>I': 200,\n             'got': 201,\n             'ca': 202,\n             'around': 203,\n             \"'re\": 204,\n             'again': 205,\n             'quite': 206,\n             'seems': 207,\n             'pretty': 208,\n             'down': 209,\n             'every': 210,\n             'things': 211,\n             'fact': 212,\n             'thought': 213,\n             '&': 214,\n             'enough': 215,\n             'between': 216,\n             'own': 217,\n             'take': 218,\n             'horror': 219,\n             'now': 220,\n             'young': 221,\n             'give': 222,\n             'must': 223,\n             'world': 224,\n             'may': 225,\n             'us': 226,\n             'series': 227,\n             'gets': 228,\n             'original': 229,\n             'long': 230,\n             'action': 231,\n             'point': 232,\n             'always': 233,\n             'right': 234,\n             'role': 235,\n             'They': 236,\n             'comedy': 237,\n             'least': 238,\n             'saw': 239,\n             'interesting': 240,\n             'times': 241,\n             'family': 242,\n             'whole': 243,\n             'new': 244,\n             'both': 245,\n             'done': 246,\n             'You': 247,\n             'without': 248,\n             'almost': 249,\n             'bit': 250,\n             'big': 251,\n             'come': 252,\n             'feel': 253,\n             'script': 254,\n             'far': 255,\n             'making': 256,\n             'might': 257,\n             'anything': 258,\n             'minutes': 259,\n             'What': 260,\n             'performance': 261,\n             'guy': 262,\n             'am': 263,\n             'music': 264,\n             'She': 265,\n             'kind': 266,\n             'TV': 267,\n             'probably': 268,\n             'As': 269,\n             'woman': 270,\n             'last': 271,\n             'rather': 272,\n             'away': 273,\n             \"'ll\": 274,\n             'since': 275,\n             'girl': 276,\n             'found': 277,\n             'fun': 278,\n             'played': 279,\n             'worst': 280,\n             'course': 281,\n             'That': 282,\n             'hard': 283,\n             'trying': 284,\n             'comes': 285,\n             'each': 286,\n             'looking': 287,\n             'screen': 288,\n             'goes': 289,\n             'anyone': 290,\n             'believe': 291,\n             'book': 292,\n             'put': 293,\n             'sure': 294,\n             'looks': 295,\n             'actor': 296,\n             'different': 297,\n             'set': 298,\n             'our': 299,\n             'reason': 300,\n             'especially': 301,\n             'day': 302,\n             'place': 303,\n             'shows': 304,\n             'money': 305,\n             'yet': 306,\n             'play': 307,\n             'sense': 308,\n             'year': 309,\n             'having': 310,\n             'ending': 311,\n             'job': 312,\n             '/>This': 313,\n             '10': 314,\n             'seem': 315,\n             'When': 316,\n             'main': 317,\n             'audience': 318,\n             'worth': 319,\n             'takes': 320,\n             'DVD': 321,\n             'plays': 322,\n             \"'d\": 323,\n             'said': 324,\n             'effects': 325,\n             'American': 326,\n             'together': 327,\n             '2': 328,\n             'watched': 329,\n             'someone': 330,\n             'So': 331,\n             'John': 332,\n             'true': 333,\n             'three': 334,\n             'wife': 335,\n             'version': 336,\n             'himself': 337,\n             'left': 338,\n             'half': 339,\n             'beautiful': 340,\n             'seeing': 341,\n             'shot': 342,\n             'idea': 343,\n             'everything': 344,\n             'father': 345,\n             'special': 346,\n             'during': 347,\n             'later': 348,\n             'read': 349,\n             'less': 350,\n             'else': 351,\n             'help': 352,\n             'high': 353,\n             'One': 354,\n             'once': 355,\n             'used': 356,\n             'excellent': 357,\n             'simply': 358,\n             'We': 359,\n             'nice': 360,\n             'mind': 361,\n             'everyone': 362,\n             'completely': 363,\n             'rest': 364,\n             'fan': 365,\n             'short': 366,\n             'Not': 367,\n             'need': 368,\n             'performances': 369,\n             'budget': 370,\n             'use': 371,\n             'try': 372,\n             'Hollywood': 373,\n             'However': 374,\n             'production': 375,\n             'line': 376,\n             'classic': 377,\n             'let': 378,\n             'low': 379,\n             'women': 380,\n             'poor': 381,\n             'given': 382,\n             'camera': 383,\n             'enjoy': 384,\n             'For': 385,\n             'All': 386,\n             'boring': 387,\n             'either': 388,\n             'home': 389,\n             'top': 390,\n             'wrong': 391,\n             'kids': 392,\n             'friends': 393,\n             'second': 394,\n             'came': 395,\n             'house': 396,\n             'until': 397,\n             '/>It': 398,\n             'recommend': 399,\n             'tell': 400,\n             'sex': 401,\n             'mean': 402,\n             'My': 403,\n             'start': 404,\n             'stupid': 405,\n             'getting': 406,\n             'night': 407,\n             'understand': 408,\n             'truly': 409,\n             'instead': 410,\n             'remember': 411,\n             'couple': 412,\n             'moments': 413,\n             'full': 414,\n             'men': 415,\n             'doing': 416,\n             'playing': 417,\n             'along': 418,\n             'name': 419,\n             'gives': 420,\n             'small': 421,\n             'episode': 422,\n             'keep': 423,\n             'maybe': 424,\n             'awful': 425,\n             'person': 426,\n             'death': 427,\n             'lines': 428,\n             'stars': 429,\n             'black': 430,\n             'felt': 431,\n             'style': 432,\n             'although': 433,\n             'supposed': 434,\n             'written': 435,\n             'video': 436,\n             'liked': 437,\n             'school': 438,\n             'however': 439,\n             'early': 440,\n             'often': 441,\n             'perfect': 442,\n             'No': 443,\n             'become': 444,\n             'dialogue': 445,\n             'next': 446,\n             'piece': 447,\n             'itself': 448,\n             'terrible': 449,\n             'wonderful': 450,\n             '..': 451,\n             'human': 452,\n             'star': 453,\n             'case': 454,\n             'face': 455,\n             'went': 456,\n             'head': 457,\n             'called': 458,\n             'against': 459,\n             'problem': 460,\n             'live': 461,\n             'entire': 462,\n             'sort': 463,\n             'waste': 464,\n             'others': 465,\n             'mother': 466,\n             'children': 467,\n             'Even': 468,\n             'absolutely': 469,\n             'After': 470,\n             'THE': 471,\n             'definitely': 472,\n             'At': 473,\n             'entertaining': 474,\n             'title': 475,\n             'laugh': 476,\n             'seemed': 477,\n             '3': 478,\n             'beginning': 479,\n             'friend': 480,\n             'war': 481,\n             'wanted': 482,\n             'Well': 483,\n             'several': 484,\n             'worse': 485,\n             'certainly': 486,\n             'becomes': 487,\n             'care': 488,\n             'To': 489,\n             'already': 490,\n             'His': 491,\n             'drama': 492,\n             'Do': 493,\n             'boy': 494,\n             'example': 495,\n             'lives': 496,\n             'loved': 497,\n             'based': 498,\n             'killer': 499,\n             'hope': 500,\n             'picture': 501,\n             'dead': 502,\n             'fans': 503,\n             'Michael': 504,\n             'son': 505,\n             '>': 506,\n             'cinema': 507,\n             'under': 508,\n             'guess': 509,\n             'lead': 510,\n             '<br': 511,\n             'sound': 512,\n             '\\x96': 513,\n             'fine': 514,\n             'wants': 515,\n             'lost': 516,\n             'able': 517,\n             'direction': 518,\n             'gave': 519,\n             'viewer': 520,\n             'humor': 521,\n             'turn': 522,\n             'totally': 523,\n             'hand': 524,\n             'tries': 525,\n             'works': 526,\n             '1': 527,\n             'guys': 528,\n             'quality': 529,\n             'writing': 530,\n             'amazing': 531,\n             'past': 532,\n             'turns': 533,\n             'wo': 534,\n             'heart': 535,\n             'child': 536,\n             'enjoyed': 537,\n             'Then': 538,\n             'finally': 539,\n             'white': 540,\n             'Why': 541,\n             'throughout': 542,\n             'game': 543,\n             'self': 544,\n             'Of': 545,\n             'evil': 546,\n             'final': 547,\n             'Also': 548,\n             'starts': 549,\n             'parts': 550,\n             'flick': 551,\n             '....': 552,\n             'stories': 553,\n             'How': 554,\n             'thinking': 555,\n             'behind': 556,\n             'themselves': 557,\n             'etc': 558,\n             'history': 559,\n             'car': 560,\n             'favorite': 561,\n             'genre': 562,\n             'New': 563,\n             'close': 564,\n             'perhaps': 565,\n             'feeling': 566,\n             'act': 567,\n             'side': 568,\n             'While': 569,\n             'town': 570,\n             'directed': 571,\n             'today': 572,\n             'decent': 573,\n             'stuff': 574,\n             'hour': 575,\n             'kill': 576,\n             'girls': 577,\n             'late': 578,\n             'type': 579,\n             'expect': 580,\n             'moment': 581,\n             'art': 582,\n             'brilliant': 583,\n             'actress': 584,\n             'daughter': 585,\n             'slow': 586,\n             'writer': 587,\n             'says': 588,\n             'horrible': 589,\n             'roles': 590,\n             'killed': 591,\n             'voice': 592,\n             'days': 593,\n             'fight': 594,\n             'myself': 595,\n             'heard': 596,\n             'kid': 597,\n             'hit': 598,\n             'known': 599,\n             'dark': 600,\n             'involved': 601,\n             'Mr.': 602,\n             'took': 603,\n             'particularly': 604,\n             'group': 605,\n             'run': 606,\n             'matter': 607,\n             'told': 608,\n             'including': 609,\n             'violence': 610,\n             'Some': 611,\n             'attempt': 612,\n             'happens': 613,\n             'husband': 614,\n             'obvious': 615,\n             'stop': 616,\n             'eyes': 617,\n             'lack': 618,\n             'sometimes': 619,\n             'James': 620,\n             'strong': 621,\n             'Just': 622,\n             'chance': 623,\n             'extremely': 624,\n             'With': 625,\n             'experience': 626,\n             'Now': 627,\n             'number': 628,\n             'brother': 629,\n             'coming': 630,\n             'ago': 631,\n             '/>In': 632,\n             'career': 633,\n             'wonder': 634,\n             'leave': 635,\n             'interest': 636,\n             'soon': 637,\n             'looked': 638,\n             'shown': 639,\n             'happened': 640,\n             '/>There': 641,\n             'obviously': 642,\n             'relationship': 643,\n             'David': 644,\n             'annoying': 645,\n             'complete': 646,\n             'finds': 647,\n             'cinematography': 648,\n             'crap': 649,\n             'despite': 650,\n             'jokes': 651,\n             'murder': 652,\n             'age': 653,\n             'happen': 654,\n             '4': 655,\n             'female': 656,\n             'score': 657,\n             'serious': 658,\n             'taken': 659,\n             'whose': 660,\n             'except': 661,\n             'highly': 662,\n             'police': 663,\n             'novel': 664,\n             'opening': 665,\n             'hero': 666,\n             'usual': 667,\n             'level': 668,\n             'Robert': 669,\n             'somewhat': 670,\n             'gore': 671,\n             'hours': 672,\n             'song': 673,\n             'started': 674,\n             'across': 675,\n             'hilarious': 676,\n             'musical': 677,\n             'simple': 678,\n             'talking': 679,\n             'exactly': 680,\n             'yourself': 681,\n             'body': 682,\n             'taking': 683,\n             'cut': 684,\n             'light': 685,\n             'ones': 686,\n             'opinion': 687,\n             '/>If': 688,\n             'living': 689,\n             'view': 690,\n             'shots': 691,\n             '5': 692,\n             'change': 693,\n             'documentary': 694,\n             'usually': 695,\n             'talent': 696,\n             'single': 697,\n             'word': 698,\n             'important': 699,\n             'ridiculous': 700,\n             'saying': 701,\n             'released': 702,\n             'sad': 703,\n             'running': 704,\n             'alone': 705,\n             'reality': 706,\n             'English': 707,\n             'ends': 708,\n             'turned': 709,\n             'Man': 710,\n             'episodes': 711,\n             'thriller': 712,\n             'wish': 713,\n             'middle': 714,\n             'tells': 715,\n             'possible': 716,\n             'British': 717,\n             'cool': 718,\n             'comic': 719,\n             'save': 720,\n             'appears': 721,\n             'modern': 722,\n             'mostly': 723,\n             'Paul': 724,\n             'call': 725,\n             'due': 726,\n             'order': 727,\n             'cheap': 728,\n             'local': 729,\n             'non': 730,\n             'knew': 731,\n             'attention': 732,\n             'room': 733,\n             'Oh': 734,\n             'falls': 735,\n             'problems': 736,\n             'giving': 737,\n             'scary': 738,\n             'future': 739,\n             'knows': 740,\n             'Jack': 741,\n             'songs': 742,\n             'events': 743,\n             'Although': 744,\n             'huge': 745,\n             'words': 746,\n             '/>But': 747,\n             'On': 748,\n             'romantic': 749,\n             'country': 750,\n             'major': 751,\n             'blood': 752,\n             'it.<br': 753,\n             'happy': 754,\n             'silly': 755,\n             'needs': 756,\n             'class': 757,\n             'entertainment': 758,\n             'OK': 759,\n             'clearly': 760,\n             'herself': 761,\n             'moving': 762,\n             'sequence': 763,\n             'seriously': 764,\n             'fast': 765,\n             'stand': 766,\n             'George': 767,\n             'strange': 768,\n             'Oscar': 769,\n             'four': 770,\n             'television': 771,\n             'Richard': 772,\n             'sets': 773,\n             'similar': 774,\n             'supporting': 775,\n             'easily': 776,\n             'disappointed': 777,\n             'named': 778,\n             'bring': 779,\n             'predictable': 780,\n             'near': 781,\n             'points': 782,\n             'enjoyable': 783,\n             'First': 784,\n             'mention': 785,\n             'surprised': 786,\n             'King': 787,\n             'talk': 788,\n             'Lee': 789,\n             'kept': 790,\n             'review': 791,\n             'hell': 792,\n             'effort': 793,\n             'leads': 794,\n             'beyond': 795,\n             'feels': 796,\n             'sequel': 797,\n             'bunch': 798,\n             'theme': 799,\n             'storyline': 800,\n             'within': 801,\n             'power': 802,\n             'ten': 803,\n             'tried': 804,\n             'ways': 805,\n             'dialog': 806,\n             'rating': 807,\n             'above': 808,\n             'brought': 809,\n             'message': 810,\n             'straight': 811,\n             'realistic': 812,\n             'dull': 813,\n             'five': 814,\n             'animation': 815,\n             'begins': 816,\n             'upon': 817,\n             'elements': 818,\n             'fall': 819,\n             'release': 820,\n             'sister': 821,\n             'York': 822,\n             'actual': 823,\n             'clear': 824,\n             'comments': 825,\n             'using': 826,\n             'working': 827,\n             'figure': 828,\n             'nearly': 829,\n             'minute': 830,\n             'none': 831,\n             'among': 832,\n             'famous': 833,\n             're': 834,\n             'weak': 835,\n             'Peter': 836,\n             'sexual': 837,\n             'tale': 838,\n             'typical': 839,\n             'easy': 840,\n             'hear': 841,\n             'overall': 842,\n             'certain': 843,\n             'editing': 844,\n             'means': 845,\n             'team': 846,\n             'viewers': 847,\n             'Unfortunately': 848,\n             'whether': 849,\n             'Is': 850,\n             'movie.<br': 851,\n             'soundtrack': 852,\n             'apparently': 853,\n             'fantastic': 854,\n             'eye': 855,\n             'hate': 856,\n             'particular': 857,\n             'stay': 858,\n             'Maybe': 859,\n             'difficult': 860,\n             'filmed': 861,\n             'form': 862,\n             'showing': 863,\n             'B': 864,\n             'Who': 865,\n             'learn': 866,\n             'feature': 867,\n             'theater': 868,\n             'viewing': 869,\n             'follow': 870,\n             'suspense': 871,\n             '/>A': 872,\n             'Yes': 873,\n             'decided': 874,\n             'leaves': 875,\n             'premise': 876,\n             'material': 877,\n             'buy': 878,\n             'basically': 879,\n             'possibly': 880,\n             'Her': 881,\n             'parents': 882,\n             '$': 883,\n             'God': 884,\n             'expected': 885,\n             'move': 886,\n             'atmosphere': 887,\n             'film.<br': 888,\n             'subject': 889,\n             'Disney': 890,\n             'Its': 891,\n             'doubt': 892,\n             'America': 893,\n             'city': 894,\n             'crime': 895,\n             'stage': 896,\n             'From': 897,\n             'lame': 898,\n             'deal': 899,\n             'killing': 900,\n             'became': 901,\n             'reviews': 902,\n             '/>And': 903,\n             'begin': 904,\n             'greatest': 905,\n             'add': 906,\n             'lots': 907,\n             'sit': 908,\n             'period': 909,\n             'sequences': 910,\n             '/>As': 911,\n             'weird': 912,\n             'Tom': 913,\n             'yes': 914,\n             'French': 915,\n             'NOT': 916,\n             'average': 917,\n             'free': 918,\n             'mystery': 919,\n             'needed': 920,\n             'acted': 921,\n             'screenplay': 922,\n             'An': 923,\n             'nature': 924,\n             'believable': 925,\n             'write': 926,\n             'nor': 927,\n             '20': 928,\n             'question': 929,\n             'poorly': 930,\n             'directors': 931,\n             'gone': 932,\n             'meets': 933,\n             'These': 934,\n             'emotional': 935,\n             'older': 936,\n             'somehow': 937,\n             '`': 938,\n             'memorable': 939,\n             'forward': 940,\n             'reading': 941,\n             'wait': 942,\n             'rent': 943,\n             'setting': 944,\n             'meant': 945,\n             'third': 946,\n             'admit': 947,\n             'male': 948,\n             'realize': 949,\n             'season': 950,\n             'dance': 951,\n             'effect': 952,\n             'features': 953,\n             'Joe': 954,\n             'creepy': 955,\n             'writers': 956,\n             'truth': 957,\n             'comment': 958,\n             'surprise': 959,\n             'worked': 960,\n             'Japanese': 961,\n             'laughs': 962,\n             'earlier': 963,\n             'fighting': 964,\n             'open': 965,\n             'quickly': 966,\n             's': 967,\n             'Most': 968,\n             'credits': 969,\n             'forced': 970,\n             'whom': 971,\n             'result': 972,\n             'society': 973,\n             'Jane': 974,\n             'War': 975,\n             'powerful': 976,\n             'dramatic': 977,\n             'keeps': 978,\n             'forget': 979,\n             'Like': 980,\n             'gay': 981,\n             'meet': 982,\n             'previous': 983,\n             'badly': 984,\n             'brings': 985,\n             'eventually': 986,\n             'front': 987,\n             'imagine': 988,\n             'towards': 989,\n             'romance': 990,\n             'situation': 991,\n             'check': 992,\n             'die': 993,\n             'footage': 994,\n             'nudity': 995,\n             'cheesy': 996,\n             'general': 997,\n             'interested': 998,\n             'leading': 999,\n             ...})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([25002, 100])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 202571), (',', 193209), ('.', 165915), ('and', 109443), ('a', 109043), ('of', 100243), ('to', 93794), ('is', 76547), ('in', 61246), ('I', 54168), ('it', 53524), ('that', 49024), ('\"', 44294), (\"'s\", 43138), ('this', 42199), ('-', 37350), ('/><br', 35732), ('was', 34985), ('as', 30292), ('movie', 29876)]\n",
      "Counter({'neg': 8767, 'pos': 8733})\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print(LABEL.vocab.freqs)  # 数量上基本上是1:1的比例,所以不需要对样本做重采样来保持正负样本比例均衡"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    shuffle=False,  # 这里可以不打乱顺序\n",
    "    sort_within_batch=True)  # IMDB内置了sort_key方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 64]) \n",
      " tensor([[   11,  6147,    11,  ...,  3800,    25, 11897],\n",
      "        [  213,     2,   239,  ...,   435,   120,    25],\n",
      "        [   16,  6902,    16,  ...,    23,    32,     0],\n",
      "        ...,\n",
      "        [19372,   626,     9,  ...,     1,     1,     1],\n",
      "        [   14,   693,   103,  ...,     1,     1,     1],\n",
      "        [    4,     4,    41,  ...,     1,     1,     1]], device='cuda:0')\n",
      "torch.Size([64]) \n",
      " tensor([49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47,\n",
      "        47, 47, 47, 47, 46, 46, 46, 46, 45, 45, 45, 45, 44, 44, 44, 43, 43, 43,\n",
      "        42, 42, 42, 42, 41, 40, 40, 40, 40, 40, 39, 39, 38, 38, 38, 38, 38, 36,\n",
      "        35, 34, 33, 33, 33, 31, 29, 24, 22, 13], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(valid_iterator))\n",
    "# print(batch)\n",
    "\n",
    "print(batch.text[0].shape, '\\n', batch.text[0])  # 长度为49,批次为64;1表示填充\n",
    "print(batch.text[1].shape, '\\n', batch.text[1])  # 每个批次的长度\n",
    "\n",
    "# print(batch.label.shape, '\\n', batch.label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 64])\n",
      "torch.Size([56, 64])\n",
      "torch.Size([61, 64])\n",
      "torch.Size([67, 64])\n",
      "torch.Size([72, 64])\n",
      "torch.Size([77, 64])\n",
      "torch.Size([82, 64])\n",
      "torch.Size([86, 64])\n",
      "torch.Size([91, 64])\n",
      "torch.Size([96, 64])\n",
      "torch.Size([102, 64])\n",
      "torch.Size([108, 64])\n",
      "torch.Size([113, 64])\n",
      "torch.Size([118, 64])\n",
      "torch.Size([120, 64])\n",
      "torch.Size([124, 64])\n",
      "torch.Size([127, 64])\n",
      "torch.Size([129, 64])\n",
      "torch.Size([131, 64])\n",
      "torch.Size([133, 64])\n",
      "torch.Size([135, 64])\n",
      "torch.Size([137, 64])\n",
      "torch.Size([138, 64])\n",
      "torch.Size([140, 64])\n",
      "torch.Size([141, 64])\n",
      "torch.Size([143, 64])\n",
      "torch.Size([144, 64])\n",
      "torch.Size([146, 64])\n",
      "torch.Size([147, 64])\n",
      "torch.Size([148, 64])\n",
      "torch.Size([150, 64])\n",
      "torch.Size([152, 64])\n",
      "torch.Size([153, 64])\n",
      "torch.Size([155, 64])\n",
      "torch.Size([156, 64])\n",
      "torch.Size([158, 64])\n",
      "torch.Size([160, 64])\n",
      "torch.Size([161, 64])\n",
      "torch.Size([163, 64])\n",
      "torch.Size([164, 64])\n",
      "torch.Size([166, 64])\n",
      "torch.Size([168, 64])\n",
      "torch.Size([170, 64])\n",
      "torch.Size([171, 64])\n",
      "torch.Size([173, 64])\n",
      "torch.Size([175, 64])\n",
      "torch.Size([177, 64])\n",
      "torch.Size([179, 64])\n",
      "torch.Size([181, 64])\n",
      "torch.Size([183, 64])\n",
      "torch.Size([185, 64])\n",
      "torch.Size([187, 64])\n",
      "torch.Size([190, 64])\n",
      "torch.Size([192, 64])\n",
      "torch.Size([195, 64])\n",
      "torch.Size([197, 64])\n",
      "torch.Size([200, 64])\n",
      "torch.Size([202, 64])\n",
      "torch.Size([205, 64])\n",
      "torch.Size([208, 64])\n",
      "torch.Size([211, 64])\n",
      "torch.Size([213, 64])\n",
      "torch.Size([217, 64])\n",
      "torch.Size([219, 64])\n",
      "torch.Size([222, 64])\n",
      "torch.Size([226, 64])\n",
      "torch.Size([229, 64])\n",
      "torch.Size([232, 64])\n",
      "torch.Size([236, 64])\n",
      "torch.Size([240, 64])\n",
      "torch.Size([243, 64])\n",
      "torch.Size([247, 64])\n",
      "torch.Size([251, 64])\n",
      "torch.Size([256, 64])\n",
      "torch.Size([260, 64])\n",
      "torch.Size([265, 64])\n",
      "torch.Size([269, 64])\n",
      "torch.Size([274, 64])\n",
      "torch.Size([279, 64])\n",
      "torch.Size([284, 64])\n",
      "torch.Size([289, 64])\n",
      "torch.Size([294, 64])\n",
      "torch.Size([299, 64])\n",
      "torch.Size([306, 64])\n",
      "torch.Size([312, 64])\n",
      "torch.Size([319, 64])\n",
      "torch.Size([326, 64])\n",
      "torch.Size([332, 64])\n",
      "torch.Size([341, 64])\n",
      "torch.Size([348, 64])\n",
      "torch.Size([357, 64])\n",
      "torch.Size([366, 64])\n",
      "torch.Size([374, 64])\n",
      "torch.Size([385, 64])\n",
      "torch.Size([391, 64])\n",
      "torch.Size([401, 64])\n",
      "torch.Size([410, 64])\n",
      "torch.Size([420, 64])\n",
      "torch.Size([433, 64])\n",
      "torch.Size([445, 64])\n",
      "torch.Size([459, 64])\n",
      "torch.Size([472, 64])\n",
      "torch.Size([485, 64])\n",
      "torch.Size([503, 64])\n",
      "torch.Size([521, 64])\n",
      "torch.Size([542, 64])\n",
      "torch.Size([564, 64])\n",
      "torch.Size([589, 64])\n",
      "torch.Size([620, 64])\n",
      "torch.Size([651, 64])\n",
      "torch.Size([688, 64])\n",
      "torch.Size([726, 64])\n",
      "torch.Size([785, 64])\n",
      "torch.Size([843, 64])\n",
      "torch.Size([940, 64])\n",
      "torch.Size([1055, 64])\n",
      "torch.Size([1223, 64])\n",
      "torch.Size([1996, 12])\n"
     ]
    }
   ],
   "source": [
    "for i in valid_iterator:\n",
    "    print(i.text[0].shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002 100\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors  # 预训练词向量\n",
    "vocal_size, embedding_size = pretrained_embeddings.shape\n",
    "hidden_size = 256\n",
    "dropout = 0.5\n",
    "bidirectional = True\n",
    "out_size = 1\n",
    "num_layers = 2\n",
    "lr = 0.001  # 学习率\n",
    "weight_decay = 1e-5\n",
    "print(vocal_size, embedding_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5730,    22,     7,    40,    40,   783,   309,    16,  2338,     7,\n",
      "          4777,     0,  3725,  1752, 12687, 22044,     0,     4,     4,    41,\n",
      "             4,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    0,    16,    16,     6,  1380,    21,   179,    21,   254,   314,\n",
      "             4,     4,     4,    41,     4,     4,    41,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [ 2490,    21,    21,   270,  3196,     4,  2006,    41,    41,    41,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    4,     4,     4,     4,     4,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1]], device='cuda:0')\n",
      "tensor([48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 46, 46, 46, 46, 46, 46, 46, 45,\n",
      "        45, 45, 45, 44, 44, 44, 44, 43, 43, 42, 42, 42, 42, 42, 42, 42, 41, 41,\n",
      "        41, 41, 40, 40, 40, 38, 37, 37, 37, 36, 35, 35, 35, 34, 33, 32, 30, 29,\n",
      "        28, 28, 28, 27, 27, 24, 21, 21, 14, 14], device='cuda:0')\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    (text, text_lengths), label = batch.text, batch.label\n",
    "    print(text[-4:, :])\n",
    "    print(text_lengths)\n",
    "    print(label)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from BRNNModel import BRNN\n",
    "%run BRNNModel.py\n",
    "\n",
    "net = BRNN(vocal_size=vocal_size,\n",
    "           embedding_size=embedding_size,\n",
    "           hidden_size=hidden_size,\n",
    "           num_layers=num_layers,\n",
    "           dropout=dropout,\n",
    "           bidirectional=True,\n",
    "           out_size=out_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,810,857 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"计算要训练的参数个数\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(net):,} trainable parameters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.4704, -0.4168,  0.0804,  ...,  0.5253, -1.4153,  0.6527],\n        [ 0.5952, -1.7709,  1.3419,  ..., -1.2439, -0.9224,  0.4309],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [-0.1775,  0.6091,  0.3570,  ..., -0.0507,  0.1808,  0.4038],\n        [ 0.2581,  0.4548, -0.6745,  ...,  0.1374, -0.2201,  0.7585],\n        [-0.1438, -0.3202,  0.4899,  ..., -0.5105, -0.1756,  0.2217]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.embed.weight.data.copy_(pretrained_embeddings)  # 也可以使用from_pretrained方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "<pad>\n",
      "0\n",
      "1\n",
      "tensor([-0.4704, -0.4168,  0.0804, -0.2398, -0.9571,  1.3535,  0.7417,  0.2002,\n",
      "         0.9520, -1.7906,  1.7478, -0.3042,  0.4464,  0.1124,  1.6594,  0.1385,\n",
      "         0.8991,  0.2505, -0.1612, -1.0242,  0.5758,  0.8801, -0.6415, -0.7938,\n",
      "         0.5940,  1.0979, -0.2262, -0.1885, -0.9740,  2.3827,  1.1368, -0.7608,\n",
      "         0.5174,  0.2106, -0.9644,  0.5810, -0.3412, -0.5013, -1.0705, -0.4449,\n",
      "        -0.9910, -0.9872, -0.0850, -2.4506, -0.1743,  1.2091, -1.2388,  0.3289,\n",
      "         0.5226,  1.4376, -2.3316, -0.4426, -0.3382, -0.0477,  1.3652,  0.6709,\n",
      "         0.2234, -0.2513, -1.6245, -2.0295, -0.1263,  0.5826,  1.1050,  1.1442,\n",
      "        -0.7573, -0.3753, -0.3928,  0.5462, -2.3406,  0.0702, -1.2683, -0.4450,\n",
      "         2.1960, -0.9264, -1.0451,  0.6124, -1.1049, -0.5299, -0.6392, -1.3246,\n",
      "        -0.0599,  1.8333,  0.3815, -1.6780, -0.7285,  0.2331,  1.3732, -0.7015,\n",
      "        -1.2674,  0.6737,  0.7955, -0.2906, -1.5995, -0.5399,  0.5840,  1.1428,\n",
      "         0.5917,  0.5253, -1.4153,  0.6527])\n",
      "tensor([ 0.5952, -1.7709,  1.3419, -0.8679, -0.4698,  0.1598,  1.7750, -1.8917,\n",
      "         0.7587, -0.0637,  1.5141, -0.7720, -0.0585, -2.2068, -0.6148, -0.4111,\n",
      "         0.1644,  0.2867,  0.6309, -1.0653, -0.2637,  1.3358,  0.2175,  0.4669,\n",
      "         2.1986,  1.3605, -0.8178, -0.2239,  0.0126, -0.0100, -1.1718, -1.5262,\n",
      "        -0.2851,  0.6067,  1.2526,  0.9174, -0.1636,  1.5346, -0.3712,  1.5452,\n",
      "         0.1487,  1.6779,  0.0471, -1.8126, -0.1544, -0.2415, -1.0035,  0.6236,\n",
      "        -0.6388,  0.9260,  1.6074,  1.0750,  0.2190,  1.3398,  0.2333,  0.1685,\n",
      "         0.5037,  0.6448, -0.5938, -0.7507, -0.7362, -0.1588, -1.1666,  0.2474,\n",
      "         0.5894,  1.2015, -0.8150,  0.7419,  1.0543,  0.3603,  0.5096,  0.8450,\n",
      "        -0.2511, -0.5569,  1.0606,  0.2347, -0.0798,  0.5593,  1.4628, -0.6263,\n",
      "         0.5104, -0.6580, -0.1696,  0.2190,  0.7684, -0.3907, -0.2547,  1.1978,\n",
      "        -2.5146, -0.3251,  1.8149,  1.4357,  0.3022, -0.5421, -0.6367,  0.8075,\n",
      "        -0.7807, -1.2439, -0.9224,  0.4309])\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.unk_token)\n",
    "print(TEXT.pad_token)\n",
    "print(TEXT.vocab.stoi['<unk>'])\n",
    "print(TEXT.vocab.stoi['<pad>'])\n",
    "print(TEXT.vocab.vectors[TEXT.vocab.stoi[TEXT.unk_token]])  # unk的预训练词向量(这个预训练的词向量没有设置为0)\n",
    "print(TEXT.vocab.vectors[TEXT.vocab.stoi[TEXT.pad_token]])  # pad的预训练词向量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-0.1775,  0.6091,  0.3570,  ..., -0.0507,  0.1808,  0.4038],\n",
      "        [ 0.2581,  0.4548, -0.6745,  ...,  0.1374, -0.2201,  0.7585],\n",
      "        [-0.1438, -0.3202,  0.4899,  ..., -0.5105, -0.1756,  0.2217]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "UNK_INDEX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_INDEX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "net.embed.weight.data[UNK_INDEX] = torch.zeros(embedding_size)\n",
    "net.embed.weight.data[PAD_INDEX] = torch.zeros(embedding_size)\n",
    "print(net.embed.weight)  # 此时前2行被初始化为0向量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二分类的损失函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "from Senti_train import Train_Evaluate\n",
    "% run Senti_train.py\n",
    "trainer = Train_Evaluate(model=net, optimizer=optimizer, criterion=criterion, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def epoch_time(start, end):\n",
    "    \"\"\"计算运行时间\"\"\"\n",
    "    elapsed_time = end - start\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = trainer.train(train_iterator)\n",
    "    valid_loss, valid_acc = trainer.evaluate(valid_iterator)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(trainer.model.state_dict(), 'Senti_model.pth')\n",
    "\n",
    "    print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = BRNN(vocal_size=vocal_size,\n",
    "                  embedding_size=embedding_size,\n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=num_layers,\n",
    "                  dropout=dropout,\n",
    "                  bidirectional=True,\n",
    "                  out_size=out_size)\n",
    "best_model.load_state_dict(torch.load('Senti_model.pth'))  # 加载模型\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = Train_Evaluate(model=best_model, criterion=criterion, device=device).evaluate(test_iterator)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABEL.vocab.stoi  # pos:用0表示,neg用1表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    \"\"\"预测句子的评价\"\"\"\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp_en.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_sentiment(best_model, \"fuck, garbage\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_sentiment(best_model, \"This film is terrible\")  # 越接近与1,越能代表为负面评价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_sentiment(best_model, \"This film is great\")  # 越接近与0,越能代表为正面评价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}