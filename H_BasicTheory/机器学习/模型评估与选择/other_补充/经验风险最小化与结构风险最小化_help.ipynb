{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在假设空间,损失函数及训练数据集确定的情况下,经验风险函数式就可以确定.经验风险最小化(empirical risk minimization,ERM)的策略认为,经验\n",
    "风险最小的模型是最优的模型.根据这一策略,根据经验风险最小化求最优模型就是求解最优化问题:    \n",
    "$$ \\min_{f \\in F} \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f(\\mathbf{x}_i)) $$     \n",
    "其中,$ F $是假设空间.   \n",
    "&emsp;&emsp;当样本容量足够大时,经验风险最小化能保证有很好的学习效果,在现实中被广泛采用.比如,极大似然估计( maximum likelihood estimation)就是经验\n",
    "风险最小化的一个例子.当模型是条件概率分布,损失函数是对数损失函数时,经验风险最小化就等价于极大似然估计.  \n",
    "&emsp;&emsp;但是,当样本容量很小时,经验风险最小化学习的效果就未必最好,会产生\"过拟合\"(over-fitting)现象.    \n",
    "&emsp;&emsp;经验风险最小化(structural risk minimization, SRM)是为了防止过拟合而提出来的策略.结构\n",
    "风险最小化等价于正则化(regularization).结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或\n",
    "罚项(penalty term).在假设空间,损失函数以及训练数据集确定的情况下,结构风险的定义是:   \n",
    "$$ R_{srm}(f) = \\frac{1}{N} \\sum_{i=1}^{N}  L(y_i, f(\\mathbf{x}_i))  + \\lambda J(f)$$   \n",
    "其中$J(f)$为模型的复杂度,是定义在假设空间$F$上的泛函.模型$f$越复杂,复杂度$  J(f)$就越大;反之,模型$ f$越\n",
    "简单,复杂度$ J(f)$就越小.也就是说,复杂度表示了对复杂模型的惩罚.$ \\lambda \\geq 0$是系数,用以权衡经验风险和\n",
    "模型复杂度.结构风险小需要经验风险和模型复杂度同事小.结构风险小的模型往往对训练数据及未知的测试数据都有较好的预测.   \n",
    "&emsp;&emsp;比如,贝叶斯估计中的最大后验概率估计(maximum posterior probability estimation, MAP)就是\n",
    "结构风险最小化的一个例子.当模型是条件概率,损失函数是对数损失函数,模型复杂度由模型的先验概率表示时,结构风险最小化就等价于\n",
    "最大后验概率估计.      \n",
    "&emsp;&emsp;结构风险最小化的策略认为结构风险最小的模型是最优的模型.所以求最优化模型,就是求解最优化问题:    \n",
    "$$ \\min_{f \\in F} \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, f(\\mathbf{x}_i)) +\\lambda J(f) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0886a02735466d80c36da7d0d184a8055779d3e497a063b4720b0317b8699033"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
