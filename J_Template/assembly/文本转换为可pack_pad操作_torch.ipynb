{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import spacy\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "test_iter = IMDB(split='test')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield [tok.text for tok in spacy_en.tokenizer(text)]  # 分词\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(test_iter))\n",
    "vocab.insert_token(\"<unk>\", 0)\n",
    "vocab.insert_token(\"<pad>\", 1)\n",
    "vocab.insert_token(\"<SOS>\", 2)\n",
    "vocab.insert_token(\"<EOS>\", 3)\n",
    "vocab.set_default_index(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# 文本内容转换为数字\n",
    "text_transform = lambda x: [vocab['<SOS>']] + [vocab[token] for token in\n",
    "                                               [tok.text for tok in spacy_en.tokenizer(x)]] + [vocab['<EOS>']]\n",
    "\n",
    "# 文本标签转换为数字\n",
    "label_transform = lambda x: 1.0 if x == 'pos' else 0.0\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\"\n",
    "    对文本标签和文本内容进行处理使之可以用于pack_padded_sequence操作\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    batch : 每个batch数据\n",
    "\n",
    "    Returns\n",
    "    label_tensor : 每个batch数据文本标签的数字化输出\n",
    "    text_pad : 每个batch数据文本内容的数字化输出\n",
    "    lengths : 每个batch数据文本内容的真实长度\n",
    "    -------\n",
    "    \"\"\"\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text))\n",
    "        lengths.append(len(processed_text))\n",
    "        text_list.append(processed_text)\n",
    "    label_tensor = torch.tensor(label_list)\n",
    "    text_pad = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
    "    # text_pad = text_pad[..., :10]  # 截断操作\n",
    "    lengths = torch.tensor(lengths)\n",
    "    return label_tensor, text_pad, lengths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "test_iter = IMDB(split='test')\n",
    "test_dataloader = Data.DataLoader(test_iter, batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([[    2, 25073,  2413,  ...,     0,     0,     0],\n",
      "        [    2, 24679,    16,  ...,     0,     0,     0],\n",
      "        [    2,    69,    11,  ...,     0,     0,     0],\n",
      "        [    2,    69,    21,  ...,  1947,     6,     3]])\n",
      "tensor([168, 429, 474, 534])\n"
     ]
    }
   ],
   "source": [
    "for label, text, length in test_dataloader:\n",
    "    print(label)\n",
    "    print(text)\n",
    "    print(length)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}