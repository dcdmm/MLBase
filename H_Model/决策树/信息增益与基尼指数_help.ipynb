{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 信息增益\n",
    "<font color='red' size=4>定义:</font>   \n",
    "&emsp;&emsp;特征$A$对训练数据集$ D $的信息增益$ g(D, A) $,定义为集合$D$的经验熵$ H(D) $与\n",
    "特征$A$给定条件下$D$的经验条件熵$ H(D|A) $之差,即    \n",
    "$$ g(D, A) = H(D) - H(D|A) $$   \n",
    "&emsp;&emsp;一般地,熵$ H(Y) $与条件熵$  H(Y|X) $的之差称为互信息(mutual information).决策树学习\n",
    "中的信息增益等价于训练数据集中类与特征的互信息.    \n",
    "&emsp;&emsp;决策树学习应用信息增益准则选择特征.给定训练数据集$D$的特征$A$,经验熵$ H(D) $表示对数据集$D$进行\n",
    "分类的不确定性.而经验条件熵$H(D|A)$表示在特征$A$给定的条件下对数据集$D$进行分类的不确定性.那么它们的差,即信息增益,就\n",
    "表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度.显然,对于数据集$D$而言,信息增益依赖于特征,不同的特征往往具有\n",
    "不同的信息增益.信息增益大的特征具有更强的分类能力.    \n",
    "&emsp;&emsp;根据信息增益准则的特征选择方法是:对训练数据集(或子集)$D$,计算其每个特征的信息增益,并比较它们的大小,选择\n",
    "信息增益最大的特征.     \n",
    "&emsp;&emsp;设训练数据集为$ D$,$ |D| $表示其样本容量,即样本个数.设有$K$个类$C_k,k=1,2,\\dots,K$,$|C_K|$为属于类$ C_k $的样本\n",
    "个数,$ \\sum_{k=1}^{K} |C_k| = |D| $.设特征$A$具有$n$个不同的取值$ \\{ a_1, a_2, \\dots, a_n \\} $,根据特征$A$的取值将$D$划分\n",
    "为$n$个子集$ D_1, D_2, \\dots, D_n $,$|D_i|$为$D_i$的样本个数,$ \\sum_{i=1}^{n}|D_i| = |D| $.记子集$D_i$中属于类$ C_k $的样本\n",
    "集合为$D_{ik}$,即$ D_{ik} = D_i \\bigcap D_k $,$ |D_{ik}| $为$ D_{ik} $的样本个数.于是信息增益的算法如下.      \n",
    "\n",
    "<font color='red' size=r>信息增益算法:</font>     \n",
    "输入:训练数据集$D$和特征$A$;\n",
    "输出:特征$A$对训练数据集$D$的信息增益$g(D, A)$.    \n",
    "1. 计算数据集$D$的经验熵$ H(D) $     \n",
    "$$ H(D) = -\\sum_{k =1}^{K} \\frac{|C_k|}{D} \\log_2 \\frac{|C_k|}{D}  $$     \n",
    "2. 计算特征$A$对数据集$D$的经验条件熵$ H(D|A) $    \n",
    "$$ H(D|A) = \\sum_{i=1}^{n} \\frac{|D_i|}{|D|} H(D_i) = - \\sum_{i=1}^{n} \\frac{|D_i|}{|D|} \\sum_{k=1}^{K} \\frac{|D_{ik}|}{|D_i|} \\log_2 \\frac{|D_{ik}|}{|D_i|}$$    \n",
    "3. 计算信息增益    \n",
    "$$ g(D, A) = H(D) - H(D|A)  $$\n",
    "\n",
    "<font color='red' size=4>信息增益比:</font>  \n",
    "&emsp;&emsp;以信息增益作为划分训练数据集的准则,存在偏向于选择取值较多的特征的问题.使用\n",
    "信息增益比(information gain ratio)可以对这一问题进行校正.(注意:一,信息增益率存在偏向于选择取值较少的特征的问题.二,C4.5算法并不是直接选择信息增益\n",
    "率最大的候选划分特征,而是使用了一个启发式[Quinlan,1993]:先从候选划分特征中找出信息增益高于平均水平的特征,再从中选择信息增益率最高的)                     \n",
    "&emsp;&emsp;特征$A$对训练数据集$ D $的信息增益比$g_R(D, A)$定义为其信息增益$g(D, A)$与训练\n",
    "数据集$D$关于特征$A$的值的熵$H_A(D)$之比,即    \n",
    "$$ g_R(D, A) = \\frac{g(D, A)}{H_A(D)} $$      \n",
    "其中,$ H_A(D) = -\\sum_{i=1}^{n} \\frac{|D_i|}{|D|} \\log_2 \\frac{|D_i|}{|D|}$, $n$是特征$A$取值的个数.   \n",
    "\n",
    "\n",
    "## 基尼指数\n",
    "<font color='red' size=4>定义:</font>    \n",
    "&emsp;&emsp;分类问题中,假设有 $ K $ 个类,样本点属于第$k$ 类的概率为$ p_k $,则\n",
    "概率分布的基尼指数定义为     \n",
    "$$  \\mathrm{Gini}(p) = \\sum_{k=1}^{K} p_k (1-p_k)  = 1 - \\sum_{k=1}^{K} p_{k}^{2}  $$     \n",
    "对于二分类问题,若样本点属于第$ 1 $个类的概率是$p$,则概率分布的基尼指数为     \n",
    "$$ \\mathrm{Gini}(p) = 2p(1-p) $$     \n",
    "对于给定的样本集合$D$,其基尼指数为     \n",
    "$$ \\mathrm{Gini}(D) = 1- \\sum_{k=1}^{K}  \\left( \\frac{|D_k|}{|D|} \\right)^2 $$  \n",
    "这里,$ C_k $ 是$D$中属于第$k$类的样本子集,$K$是类的个数.   \n",
    "&emsp;&emsp;如果样本集合$D$根据特征$A$是否取某一可能值$a$被分割成$D_1$和$D_2$两部分,即    \n",
    "$$ D_1 = \\{  (x,y) \\in D| A(x) = a  \\}, \\quad D_2 = D - D_1 $$   \n",
    "则在特征$A$的情况下,集合$D$的基尼指数定义为     \n",
    "$$ \\mathrm{Gini} (D, A) = \\frac{|D_1|}{ |D|}  \\mathrm{Gini} (D_1) + \\frac{|D_2|}{|D|}  \\mathrm{Gini} (D_2)  $$    \n",
    "&emsp;&emsp;基尼指数$ \\mathrm{Gini} (D) $表示集合$D$ 的不确定性,基尼指数$\\mathrm{Gini} (D, A)  $表示经$A=a$分割后集合$D$的\n",
    "不确定性.基尼指数越大,样本集合的不确定性就越大,这一点与熵相似."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
