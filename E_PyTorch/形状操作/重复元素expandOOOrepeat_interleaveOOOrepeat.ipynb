{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [2],\n        [3]])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1],\n",
    "                  [2],\n",
    "                  [3]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 1, 1],\n        [2, 2, 2, 2],\n        [3, 3, 3, 3]])"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.expand(3, 4)  # 维度0尺寸不变;维度1尺寸由1复制扩展为4(要扩充的维度尺寸必须为1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 1],\n        [2, 2, 2],\n        [3, 3, 3]])"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.expand(-1, 3)  # -1表示维度0尺寸不变\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  1,   1,   1],\n        [999, 999, 999],\n        [  3,   3,   3]])"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[1][0] = 999\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  1],\n        [999],\n        [  3]])"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  # ★★★★★x也发生改变(If you need to write to the tensors, please clone them first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[     1,      1,      1,      1,      1],\n        [100000, 100000, 100000, 100000, 100000],\n        [     3,      3,      3,      3,      3]])"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = copy.deepcopy(x)\n",
    "x2 = y.expand(-1, 5)\n",
    "x2[1][0] = 100000\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  1],\n        [999],\n        [  3]])"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  # x不再发生改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[1, 2],\n         [3, 4],\n         [5, 6]],\n\n        [[1, 2],\n         [3, 4],\n         [5, 6]]])"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "x = torch.unsqueeze(x, 0)\n",
    "print(x.shape)\n",
    "x.expand(2, 3, 2)  # 只能对维度信息为1的维度进行扩充"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### repeat_interleave\n",
    "### 参考numpy.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4]])"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 2, 2, 3, 3, 4, 4])"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By default, use the flattened input array, and return a flat output array.\n",
    "torch.repeat_interleave(x, 2)  # 默认dim=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 1, 2, 2, 2],\n        [3, 3, 3, 4, 4, 4]])"
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(x, 3, dim=1)  # x维度1每条数据连续重复3次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [3, 4],\n        [3, 4],\n        [3, 4]])"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat_interleave(3, dim=0)  # x维度0每条数据连续重复3次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 2, 2, 2, 2],\n        [3, 3, 4, 4, 4, 4]])"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(x, torch.tensor([2, 4]), dim=1)  # x维度1第0条数据重复2次,然后x维度1第1条数据重复4次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [1, 2],\n        [3, 4],\n        [3, 4],\n        [3, 4],\n        [3, 4]])"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.repeat_interleave(x, torch.tensor([2, 4]), dim=0)  # x维度0第0条数据重复2次,然后x维度0第1条数据重复4次\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[999,   2],\n        [  1,   2],\n        [  3,   4],\n        [  3,   4],\n        [  3,   4],\n        [  3,   4]])"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0][0] = 999\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4]])"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  # x不变(不需先进行copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### repeat\n",
    "### 参考numpy.tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 1, 2],\n        [3, 4, 3, 4],\n        [1, 2, 1, 2],\n        [3, 4, 3, 4],\n        [1, 2, 1, 2],\n        [3, 4, 3, 4],\n        [1, 2, 1, 2],\n        [3, 4, 3, 4]])"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[1, 2, 1, 2],\n          [3, 4, 3, 4]]]])"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(1, 1, 1, 2)  # 每个维度上重复该tensor的次数(整体重复)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[4, 4, 4, 4],\n         [4, 4, 4, 4]],\n\n        [[4, 4, 4, 4],\n         [4, 4, 4, 4]],\n\n        [[4, 4, 4, 4],\n         [4, 4, 4, 4]],\n\n        [[4, 4, 4, 4],\n         [4, 4, 4, 4]]])"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor(4).repeat(4, 2, 4)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[999,   4,   4,   4],\n         [  4,   4,   4,   4]],\n\n        [[  4,   4,   4,   4],\n         [  4,   4,   4,   4]],\n\n        [[  4,   4,   4,   4],\n         [  4,   4,   4,   4]],\n\n        [[  4,   4,   4,   4],\n         [  4,   4,   4,   4]]])"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0][0][0] = 999\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2],\n        [3, 4]])"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  # x不变(不需先进行copy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}