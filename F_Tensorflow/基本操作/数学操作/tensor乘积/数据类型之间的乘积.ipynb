{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参考numpy/基本操作/数组乘积/数据类型之间的乘积"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 标量 $ \\times $ 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar1 = tf.constant(3)\n",
    "scalar2 = tf.constant(4)\n",
    "\n",
    "scalar1 * scalar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 标量 $ \\times $ 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3  6  9 12], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "vector1 = tf.constant([1, 2, 3, 4])\n",
    "print(scalar1 * vector1)  # 等价于3 * vector1(广播)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 标量 $ \\times $ 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 3  6  9 12]\n",
      " [ 6  9 12 15]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "martrix1 = tf.constant([[1, 2, 3, 4],\n",
    "                        [2, 3, 4, 5]])\n",
    "print(scalar1 * martrix1)  # 等价于 3 * martrix1(广播机制)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 向量 $ \\times @ $ 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 2,  6, 12, 20])>"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = tf.constant([1, 2, 3, 4])\n",
    "vector2 = tf.constant([2, 3, 4, 5])\n",
    "vector1 * vector2  # 对应元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=40>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(vector1 * vector2)  # ★★★★★向量的(典范)内积(点积,数量积)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\narray([[ 2,  3,  4,  5],\n       [ 4,  6,  8, 10],\n       [ 6,  9, 12, 15],\n       [ 8, 12, 16, 20]])>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(vector1, (4, 1)) @ tf.reshape(vector2, (1, 4))  # [4, 1] @ [1, 4] --> [4, 4](矩阵代数)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 向量 $ \\times @ $ 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  4  9 16]\n",
      " [ 2  6 12 20]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  4  9 16]\n",
      " [ 2  6 12 20]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "martrix1 = tf.constant([[1, 2, 3, 4],\n",
    "                        [2, 3, 4, 5]])\n",
    "print(vector1 * martrix1)  # 广播机制[2, 4] broadcasting [4] --> [2, 4]\n",
    "print(martrix1 * vector1)  # 可交换顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[ 5,  8, 11, 14]])>"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1, 2]]) @ martrix1  # [1, 2] @ [2, 4] --> [1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[30],\n       [40]])>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martrix1 @ tf.reshape(vector1, (-1, 1))  # [2, 4] @ [4, 1] --> [2, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\narray([[30],\n       [40]])>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both matrices must be of the same type\n",
    "# The inputs must, following any transpositions, be tensors of rank >= 2 where the inner 2 dimensions specify valid matrix multiplication dimensions, and any further outer dimensions specify matching batch size.\n",
    "tf.matmul(martrix1, tf.reshape(vector1, (-1, 1)))  # 与上等价;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 矩阵 $ \\times @ $ 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[0, 0, 0, 0],\n       [2, 3, 4, 5]])>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martrix1 = tf.constant([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "martrix2 = tf.constant([[0, 0, 0, 0], [1, 1, 1, 1]])\n",
    "\n",
    "martrix1 * martrix2  # 对应元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[7, 7],\n       [9, 9]])>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martrix1 @ tf.reshape(martrix2, (4, 2))  # 必须满足矩阵代数运算法则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[7, 7],\n       [9, 9]])>"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(martrix1, tf.reshape(martrix2, (4, 2)))  # 与上等价"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 高维矩阵 @ 高维矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 5, 12, 9)\n",
      "(4, 3, 5, 9, 7)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.stateless_normal(shape=(4, 3, 5, 12, 9), seed=(1, 2))\n",
    "b = tf.random.stateless_normal(shape=(4, 3, 5, 9, 7), seed=(1, 2))\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 12, 7])"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = a @ b\n",
    "# [4, 3, 5, 12, 9] @ [4, 3, 5, 9, 7] -->\n",
    "# 1. [4, 3, 5] 不变(批次的概念)\n",
    "# 2. [12, 9] @ [9, 7] --> [12, 7]\n",
    "# 3. [4, 3, 5, 12, 7]\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 12, 7])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, b).shape  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 12, 8])"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.random.stateless_normal(shape=(4, 1, 5, 9, 8), seed=(1, 2))\n",
    "# [4, 3, 5, 12, 9] @ [4, 1, 5, 9, 8] -->\n",
    "# 1. [4, 3, 5] broadcasting [4, 1, 5] --> [4, 3, 5]\n",
    "# 2. [12, 9] @ [9, 8] --> [12, 8]\n",
    "# 3. [4, 3, 5, 12, 8]\n",
    "out1 = a @ c\n",
    "out1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 12, 8])"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a, c).shape  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 28, 32])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = tf.random.stateless_normal(shape=(4, 1, 5, 28, 64), seed=(1, 2))\n",
    "b1 = tf.random.stateless_normal(shape=(1, 3, 1, 64, 32), seed=(1, 2))\n",
    "# [4, 1, 5, 28, 64] @ [1, 3, 1, 64, 32] -->\n",
    "# 1. [4, 1, 5] broadcasting [1, 3, 1] --> [4, 3, 5]\n",
    "# 2. [28, 64] @ [64, 32] --> [28, 64]\n",
    "# 3. [4, 3, 5, 28, 64]\n",
    "out2 = a1 @ b1\n",
    "out2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 3, 5, 28, 32])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a1, b1).shape  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}