{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 对偶函数极大化    \n",
    "&emsp;&emsp;最大熵模型的学习就是求解最大熵模型的过程.最大熵模型的学习可以\n",
    "形式化为约束最优化问题.   \n",
    "&emsp;&emsp;对于给定的训练数据集$T = {(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\dots, (\\mathbf{x}_N, y_N)}$以及\n",
    "特征$ f_i(\\mathbf{x},y),i=1,2,\\dots,n $,最大熵模型的学习过程等价于约束最优化问题:     \n",
    "$$ \\max_{P \\in \\mathcal{C}} \\, H(P) = -\\sum_{\\mathbf{x},y}\\hat{P}(\\mathbf{x}) P(y|\\mathbf{x})\\log P(y|\\mathbf{x}) $$   \n",
    "\\begin{align}\n",
    "s.t \\quad \\quad  & E_P(f_i) = E_{\\hat{P}}(f_i), \\quad i=1,2,\\dots,n \\\\\n",
    "                 & \\sum_{y}P(y|\\mathbf{x}) = 1\n",
    "\\end{align}    \n",
    "&emsp;&emsp;按照最优化问题的习惯,将求最大值问题改写为等价的求最小值问题:  \n",
    "$$ \\min_{P \\in \\mathcal{C}} \\, -H(P) = \\sum_{\\mathbf{x},y}\\hat{P}(\\mathbf{x}) P(y|\\mathbf{x})\\log P(y|\\mathbf{x}) $$   \n",
    "\\begin{align}\n",
    "s.t \\quad \\quad  & E_P(f_i) - E_{\\hat{P}}(f_i) = 0, \\quad i=1,2,\\dots,n \\\\\n",
    "                 & \\sum_{y}P(y|\\mathbf{x}) = 1\n",
    "\\end{align}     \n",
    "&emsp;&emsp;这里,将约束最小化的原始问题转换为无约束最优化的对偶问题.通过求解对偶问题求解原始问题.  \n",
    "&emsp;&emsp;首先,引入拉格朗日乘子$ w_0, w_1, w_2, \\dots, w_n $,定义拉格朗日函数$ L(P,\\mathbf{w}) $:   \n",
    "\\begin{align}\n",
    "L(P,\\mathbf{w}) &= -H(P) + w_0(1 - \\sum_{y}P(y|\\mathbf{x})) + \\sum_{i=1}^{n}w_i(E_P(f_i) - E_{\\hat{P}}(f_i))  \\\\  \n",
    "       &= \\sum_{\\mathbf{x},y}\\hat{P}(\\mathbf{x}) P(y|\\mathbf{x})\\log P(y|\\mathbf{x})+ w_0(1 - \\sum_{y}P(y|\\mathbf{x})) + \\sum_{i=1}^{n}w_i(E_P(f_i) - E_{\\hat{P}}(f_i)) \n",
    "\\end{align}   \n",
    "&emsp;&emsp;最优化的原始问题是    \n",
    "$$\\min_{P \\in \\mathcal{C}} \\max_{\\mathbf{w}} L(P,\\mathbf{w}) $$   \n",
    "对偶问题是    \n",
    "$$ \\max_{\\mathbf{w}} \\min_{P \\in \\mathcal{C}} L(P, \\mathbf{w}) $$   \n",
    "&emsp;&emsp;由于拉格朗日函数$L(P,\\mathbf{w})$是$P$的凸函数,原始问题的解与对偶问题的解是等价的.这样,可以通过求解对偶问题来求解原始问题.    \n",
    "&emsp;&emsp;首先,求解对偶问题内部的极小化问题$ \\min_{P \\in \\mathcal{C}} L(P,\\mathbf{w}) $.$ \\min_{P \\in \\mathcal{C}} L(P,\\mathbf{w}) $是$\\mathbf{w}$的函数,将其记作   \n",
    "$$ \\psi(\\mathbf{w}) = \\min_{P \\in \\mathcal{C}} L(P,\\mathbf{w}) = L(P_\\mathbf{w}, \\mathbf{w}) $$   \n",
    "$ \\psi(\\mathbf{w}) $称为对偶函数,同时,将其解记作   \n",
    "$$P_\\mathbf{w}= \\mathrm{arg} \\min_{P \\in \\mathcal{C}} L(P,\\mathbf{w}) = P_\\mathbf{w}(y|\\mathbf{x})  $$    \n",
    "&emsp;&emsp;具体地,求$ L(P,\\mathbf{w}) $对$P(y|\\mathbf{x})$的偏导数    \n",
    "\\begin{align}\n",
    "\\frac{\\partial L(P,\\mathbf{w})}{\\partial P(y|\\mathbf{x})} &= \\sum_{\\mathbf{x},y}\\hat{P}(\\mathbf{x})(\\log P(y|\\mathbf{x}) + 1) - \\sum_{y}w_0 - \\sum_{\\mathbf{x},y} \\left( \\hat{p}(\\mathbf{x})\\sum_{i=1}^{n}w_if_i(\\mathbf{x},y) \\right) \\\\\n",
    "                                        &=\\sum_{\\mathbf{x},y}\\hat{P}(\\mathbf{x}) \\left( \\log P(y|\\mathbf{x}) + 1 - w_0 - \\sum_{i=1}^n w_i f_i(\\mathbf{x}, y) \\right)\n",
    "\\end{align}     \n",
    "令偏导数等于0,在$ \\hat{P}(\\mathbf{x}) > 0 $的情况下,解得    \n",
    "$$ P(y|\\mathbf{x}) = \\exp \\left( \\sum_{i=1}^{n} w_i f_i(\\mathbf{x}, y) +w_0 -1 \\right) = \\frac{\\exp \\left( \\sum_{i=1}^{n} w_i f_i(\\mathbf{x},y)  \\right)}{\\exp(1-w_0)} $$   \n",
    "由于$ \\sum_{y} P(y|\\mathbf{x}) = 1 $(即$P_{\\mathbf{w}}(y|\\mathbf{x})$是关于$y$的概率分布),得   \n",
    "$$ P_\\mathbf{w}(y|\\mathbf{x}) = \\frac{1}{Z_\\mathbf{w}(\\mathbf{x})} \\exp \\left( \\sum_{i=1}^{n} w_i f_i(\\mathbf{x},y) \\right) $$   \n",
    "其中,   \n",
    "$$ Z_\\mathbf{w}(\\mathbf{x}) = \\exp (1 - w_0) = \\sum_{y} \\exp \\left( \\sum_{i=1}^{n} w_i f_i(\\mathbf{x}, y) \\right) $$   \n",
    "$ Z_\\mathbf{w}(\\mathbf{x}) $称为规范化因子,$ f_i(\\mathbf{x}, y) $是特征函数;$ w_i$是特征的权值.由上式表示的模型$ P_\\mathbf{w} = P_\\mathbf{w}(y|x) $就是最大熵模型.这里,$\\mathbf{w}$是最大熵模型中的参数向量.   \n",
    "&emsp;&emsp;之后,求解对偶问题外部的极大值问题    \n",
    "$$ \\max_{\\mathbf{w}} \\psi(\\mathbf{w}) $$    \n",
    "将其解记为$ \\mathbf{w}^* $,即   \n",
    "$$ \\mathbf{w}^* = \\mathrm{arg} \\max_{\\mathbf{w}} \\psi(\\mathbf{w}) $$    \n",
    "&emsp;&emsp;这就是说,可以应用最优化算法求对偶问题$ \\psi(\\mathbf{w}) $的极大化,得到$\\mathbf{w}^*$,用来表示$ P^i \\in \\mathcal{C} $.这里,$ P^* =  P_{\\mathbf{w}^*} = P_{\\mathbf{w}^*}(y|x)$是学习到的最优模型(最大熵模型).也就是说,最大熵\n",
    "模型的学习归结为对偶函数$ \\psi(\\mathbf{w}) $的极大化.   \n",
    "\n",
    "\n",
    "## 极大似然估计\n",
    "&emsp;&emsp;已知训练数据的经验分布$ \\hat{P}(X,Y) $,条件分布的对数似然函数表示为     \n",
    "$$ L_{\\hat{p}} (P_\\mathbf{w}) = \\log \\prod_{x, y} P(y|x)^{\\hat{P}(x, y)} = \\sum_{x,y} = \\hat{P}(x,y) \\log P(y|x) $$    \n",
    "当条件分布$P(y|x)$是最大熵模型时,对数似然函数$L_{\\hat{p}} (P_\\mathbf{w}) $为    \n",
    "\\begin{align}\n",
    "L_{\\hat{P}} (P_\\mathbf{w}) &= \\sum_{x,y} \\hat{P}(x, y) \\log P(y|x) \\\\\n",
    "                  &=  \\sum_{x,y} \\hat{P}(x, y) \\sum_{i=1}^{n} w_i f_i(x, y) - \\sum_{x,y}  \\hat{P}(x, y) \\log Z_x(x) \\\\\n",
    "                  &= \\sum_{x, y} \\hat{P}(x, y) \\sum_{i=1}^{n} w_i f_i(x, y) - \\sum_{x} \\hat{P}(x) \\log Z_\\mathbf{w} (x)\n",
    "\\end{align}      \n",
    "\n",
    "&emsp;&emsp;再看对偶函数,可得     \n",
    "\\begin{align}   \n",
    "\\psi (\\mathbf{w}) &= \\sum_{x, y} \\hat{P}(x) P_\\mathbf{w}(y|x) \\log P_\\mathbf{w} (y|x) + \\sum_{i=1}^{n} w_i \\left( \\sum_{x,y} \\hat{P}(x, y) f_i (x, y) - \\sum_{x, y} \\hat{P}(x) P_\\mathbf{w} (y|x) f_i(x, y) \\right) \\\\\n",
    "         &= \\sum_{x, y} \\hat{P}(x, y) \\sum_{i=1}^{n} w_i f_i(x, y) + \\sum_{x, y} \\hat{P}(x) P_\\mathbf{w} (y|x) \\left( \\log P_\\mathbf{w} (y|x) - \\sum_{i=1}^{n} w_i f_i (x, y) \\right) \\\\\n",
    "         &= \\sum_{x, y} \\hat{p}(x, y) \\sum_{i=1}^{n} w_i f_i(x, y) -\\sum_{x, y} \\hat{P}(x) P_\\mathbf{w}(y|x) \\log Z_\\mathbf{w}(x) \\\\  \n",
    "         &= \\sum_{x, y} \\hat{p}(x, y) \\sum_{i=1}^{n} w_i f_i(x, y) -\\sum_{x} \\hat{P}(x) \\log Z_\\mathbf{w}(x)  \n",
    "\\end{align}    \n",
    "化简过程中用到了$ \\sum_{y} P(y|x) =1 $   \n",
    "&emsp;&emsp;比较上面的推导,可得:   \n",
    "$$  \\psi(\\mathbf{w}) = L_{\\hat{P}} (P_{\\mathbf{w}}) $$   \n",
    "既然对偶函数$ \\psi(x) $等价于对数似然函数$ L_{\\hat{P}} (P_{\\mathbf{w}}) $,于是证明了最大熵模型学习过程中的对偶函数极大化等价于最大熵模型的极大似然估计这一事实.   \n",
    "&emsp;&emsp;这样,最大熵模型的学习问题就转换为具体求解对数似然函数极大化或对偶函数极大化的问题.   \n",
    "&emsp;&emsp;可以将最大熵模型写成更一般的形式.    \n",
    "$$ P_\\mathbf{w}(y|x) = \\frac{1}{Z_x(x)}  \\exp  \\left( \\sum_{i=1}^{n} w_i f_i(x, y)) \\right) $$   \n",
    "其中,   \n",
    "$$ Z_\\mathbf{w}(x) = \\sum_{y} \\exp \\left( \\sum_{i=1} w_i f_i(x, y) \\right)  $$   \n",
    "这里,$ \\mathbf{x} \\in \\mathbb{R}^n $为输入,$ y \\in {1, 2, \\dots , K} $为输出,$ \\mathbf{w} \\in  R_n $为权值向量,$ f_i(\\mathbf{x}, y), i=1,2,\\dots,n $为任意实值特征函数.   \n",
    "&emsp;&emsp;最大熵模型与逻辑斯蒂回归模型有类似的形式,它们又称为对数线性模型(log linear model).模型学习就\n",
    "是"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}