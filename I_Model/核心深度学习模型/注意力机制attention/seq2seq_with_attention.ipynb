{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 设置中文字体和负号正常显示\n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('fra.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# 左边为英文句子,右边为对应的法文句子\n",
    "print(raw_text[:75])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça alors !\n"
     ]
    }
   ],
   "source": [
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理\"英语<--->法语\"数据集\"\"\"\n",
    "\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # 使用空格替换不间断空格(non-breaking space)\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # 使用小写字母替换大写字母\n",
    "    text = text.lower()\n",
    "    # 在单词和标点符号之间插⼊空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "\n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "([['go', '.'],\n  ['hi', '.'],\n  ['run', '!'],\n  ['run', '!'],\n  ['who', '?'],\n  ['wow', '!'],\n  ['fire', '!'],\n  ['help', '!'],\n  ['jump', '.'],\n  ['stop', '!']],\n [['va', '!'],\n  ['salut', '!'],\n  ['cours', '!'],\n  ['courez', '!'],\n  ['qui', '?'],\n  ['ça', 'alors', '!'],\n  ['au', 'feu', '!'],\n  ['à', \"l'aide\", '!'],\n  ['saute', '.'],\n  ['ça', 'suffit', '!']])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_nmt(text,\n",
    "                 num_examples=None):  # 参与训练的训练样本数\n",
    "    \"\"\"词元化\"英语<--->法语\"数据数据集\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        source.append(parts[0].split(' '))  # 英文数据\n",
    "        target.append(parts[1].split(' '))  # 法文数据\n",
    "    return source, target\n",
    "\n",
    "\n",
    "source, target = tokenize_nmt(text)\n",
    "source[:10], target[:10]  # 每个子列表表示一个句子的切分(根据' '切分)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "10012"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_corpus(tokens):\n",
    "    \"\"\"Count token frequencies\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text\"\"\"\n",
    "\n",
    "    def __init__(self, tokens=None,\n",
    "                 # The minimum frequency needed to include a token in the vocabulary.\n",
    "                 min_freq=2,\n",
    "                 reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = count_corpus(tokens)\n",
    "        # Sort according to frequencies\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {\n",
    "            token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        \"\"\"Index for the unknown token\"\"\"\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "\n",
    "\n",
    "# '<unk>':未知词元\n",
    "# '<pad>':填充词元\n",
    "# '<bos>':开始词元\n",
    "# '<eos>':结束词元\n",
    "src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "len(src_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # 句子截断\n",
    "    return line + [padding_token] * (num_steps - len(line))  # 句子填充\n",
    "\n",
    "\n",
    "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  47,    4,    3,  ...,    1,    1,    1],\n",
      "        [2944,    4,    3,  ...,    1,    1,    1],\n",
      "        [ 435,  126,    3,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [ 381,   60,   26,  ...,  480,   68, 4696],\n",
      "        [  66,  295,   90,  ...,   10, 1170, 1526],\n",
      "        [  17,  176,   32,  ...,    8, 1963,   16]])\n",
      "torch.Size([167130, 15])\n",
      "tensor([ 3,  3,  3,  ..., 15, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"将文本序列转换为数值矩阵\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]  # 使用'<eos>'表示句子的结尾\n",
    "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).to(dtype=torch.int32).sum(1)\n",
    "    return array, valid_len\n",
    "\n",
    "\n",
    "array, valid_len = build_array_nmt(source, src_vocab, 15)\n",
    "print(array)  # 通过vocab将句子从token转换为idx(等长,不足部分1填充)\n",
    "print(array.shape)\n",
    "print(valid_len)  # 每个句子的实际长度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 15,  19,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  7,  90,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 16,  31,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 57,   9,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  8,  25,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  8,  77,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  7, 139,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [151,  10,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 22,  29,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 13,  23,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 21, 115,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  7, 140,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 38,  33,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 45,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 13,  40,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 16,  31,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 13,  23,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 20,  75,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [130,  43,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 57,   9,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 97,  10,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 52,  27,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [157,  11,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 59,  28,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 13,  30,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  8,  18,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  6, 131,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 46,  82,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 16,  17,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 62,   6,  48,  12,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1]], dtype=torch.int32)\n",
      "valid lengths for X: tensor([4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 5])\n",
      "Y: tensor([[ 10,   0,  40,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 24,   0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  6,   7,   0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [105,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [104,  26,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 16,  83,  57,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 28,   7,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [140,   0,   0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   8,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 14,   0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0, 122,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  6,  35,  15,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,  29,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 14,  37,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 14, 100,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 46,  49,  10,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,  15,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,  26,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   8,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 54,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 14,  99,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 11,   0,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 27,  32,   0,  26,   4,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 45,   5,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1],\n",
      "        [ 68, 120,   9,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1]], dtype=torch.int32)\n",
      "valid lengths for Y: tensor([5, 4, 5, 3, 4, 3, 5, 4, 5, 4, 4, 4, 4, 5, 4, 3, 4, 3, 4, 5, 4, 4, 4, 3,\n",
      "        3, 3, 4, 3, 4, 6, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator\"\"\"\n",
    "    dataset = Data.TensorDataset(*data_arrays)\n",
    "    return Data.DataLoader(dataset, batch_size,\n",
    "                           shuffle=is_train)  # 训练模式下设置shuffle=True\n",
    "\n",
    "\n",
    "def load_data_nmt(text, batch_size, num_steps, num_examples=None):\n",
    "    \"\"\"返回翻译数据集的迭代器和词汇表\"\"\"\n",
    "    source, target = tokenize_nmt(text, num_examples=num_examples)\n",
    "    # 英文数据词表\n",
    "    src_vocab = Vocab(source, min_freq=2,\n",
    "                      reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    # 法文数据词表\n",
    "    tgt_vocab = Vocab(target, min_freq=2,\n",
    "                      reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab\n",
    "\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(text, batch_size=32, num_steps=15, num_examples=500)\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "    print('X:', X.type(torch.int32))\n",
    "    print('valid lengths for X:', X_valid_len)\n",
    "    print('Y:', Y.type(torch.int32))\n",
    "    print('valid lengths for Y:', Y_valid_len)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seq2Seq模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4, 16])\n",
      "torch.Size([2, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 # 单词表的单词数目\n",
    "                 vocab_size,\n",
    "                 # 输出词向量的维度大小\n",
    "                 embed_size,\n",
    "                 # GRU隐含变量的维度大小\n",
    "                 hidden_size, num_layers, dropout=0, bidirectional=False):\n",
    "        super(Seq2SeqEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers,\n",
    "                          dropout=dropout, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape=(N, T, C);其中T为序列的长度,N为min-batch的大小,C为输入的特征数目\n",
    "        X = self.embedding(X)\n",
    "        # 循环神经默认输入要求为:(T, N, C)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        output, state = self.rnn(X)\n",
    "        # output.shape=(T, N, hidden_size)\n",
    "        # state.shape=(num_layers, N, hidden_size)\n",
    "        return output, state\n",
    "\n",
    "\n",
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, hidden_size=16,\n",
    "                         num_layers=2)\n",
    "encoder.eval()\n",
    "\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "print(output.shape)\n",
    "print(state.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 16])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state[-1].shape=(N, hidden_size)\n",
    "state[-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens=None):\n",
    "    \"\"\"通过在最后⼀个轴上遮蔽元素来执⾏softmax操作\"\"\"\n",
    "\n",
    "    def sequence_mask(X, valid_len, value=0):\n",
    "        \"\"\"Mask irrelevant entries in sequences\"\"\"\n",
    "        maxlen = X.size(1)\n",
    "        mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                            device=X.device)[None, :] < valid_len[:, None]\n",
    "        X[~mask] = value\n",
    "        return X\n",
    "\n",
    "    if valid_lens is None:\n",
    "        return F.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 被遮蔽的元素使⽤⼀个⾮常⼤的负值替换,使其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                          value=-1e6)\n",
    "        return F.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 # 键特征数目\n",
    "                 key_size,\n",
    "                 # 查询特征数据\n",
    "                 query_size, num_hiddens, dropout):\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "        # self.W_k.weight.shape = (num_hiddens, key_size)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        # self.W_q.weight.shape = (num_hiddens, query_size)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        # self.W_v.weight.shape = (1, num_hiddens)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        \"\"\"\n",
    "        queries: 查询\n",
    "        keys: 键\n",
    "        values: 值\n",
    "        valid_lens: 计算attention_weights的有效长度\n",
    "        \"\"\"\n",
    "        # queries:(b, q?, query_size) x (query_size, num_hiddens) = (b, ?q, num_hiddens)\n",
    "        # keys:(b, k?, key_size) x (key_size, num_hiddens) = (b, ?k, num_hiddens)\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # queries.unsqueeze(2).shape=(b, ?q, 1, num_hiddens)\n",
    "        # keys.unsqueeze(1).shape=(b, 1, ?k, num_hiddens)\n",
    "        # features.shape=(b, ?q, ?k, num_hiddens)\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # scores:(b, ?q, ?k, num_hiddens) x (num_hiddens, 1) = (b, ?q, ?k, 1)\n",
    "        # scores.squeeze(-1).shape=(b, ?q, ?k)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # values.shape=(b, ?k, ?v)\n",
    "        # 返回值:(b, ?q, ?k) x (b, ?k, ?v) = (b, ?q, ?v)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "\n",
    "class Seq2SeqAttentionDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # 单词表的单词数目\n",
    "                 vocab_size,\n",
    "                 # 输出词向量的维度大小\n",
    "                 embed_size,\n",
    "                 num_hiddens, num_layers, dropout=0):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__()\n",
    "        self.attention = AdditiveAttention(\n",
    "            num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens):\n",
    "        # output.shape=(T, N, hidden_size)\n",
    "        # hidden_state.shape=(num_layers, N, hidden_size)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        # output.permute(1, 0, 2).shape=(N, T, hidden_size)\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs.shape=(N, T, hidden_size)\n",
    "        # hidden_state.shape=(num_layers, N, hidden_size)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state  # 元组解包\n",
    "        # self.embedding(X).shape=(N, T, C)\n",
    "        # X.permute(1, 0, 2).shape=(T, N, C)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # x.shape=(N, 1)\n",
    "            # query.shape.shape=(N, 1, hidden_size)\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # context.shape=(N, 1, num_hiddens)\n",
    "            # key,value均为enc_outputs(编码器的输出)\n",
    "            # 使用上一时刻的输出s_{t-1}^1和编码器的输出(enc_outputs)计算t时刻的上下文向量\n",
    "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "\n",
    "            # 在特征维度上连结\n",
    "            # torch.unsqueeze(x, dim=1).shape=(N, 1, C)\n",
    "            # x.shape=(N, 1, C+hidden_size)\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # x.permute(1, 0, 2).shape=(1, N, C+hidden_size)\n",
    "            # out.shape=(1, N, hidden_size)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)  # hidden_size被更新\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # torch.cat(outputs, dim=0).shape=(T, N, hidden_size)\n",
    "        # 全连接层之后:outputs.shape=(T, N, vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        # outputs.permute(1, 0, 2).shape=(N, T, vocab_size)\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 7, 10]), 3, torch.Size([4, 7, 16]), 2, torch.Size([4, 16]))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqAttentionDecoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "decoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)  # X.shaep=(N, T)\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, len(state), state[0].shape, len(state[1]), state[1][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"The base class for the encoder-decoder architecture\"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder  # 编码器\n",
    "        self.decoder = decoder  # 解码器\n",
    "\n",
    "    def forward(self, enc_X, dec_X, enc_valid_lens):\n",
    "        enc_outputs = self.encoder(enc_X)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, enc_valid_lens=enc_valid_lens)\n",
    "        return self.decoder(dec_X, dec_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 自定义损失函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 0],\n        [4, 5, 0]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"每行有效长度之外的值进行填充\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    # 广播机制\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "\n",
    "X = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "# 通过零值化屏蔽不相关的项,以便后面任何不相关预测的计算都是与零的乘积,结果都等于零\n",
    "sequence_mask(X, torch.tensor([1, 2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.3026, 1.1513, 0.0000])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskedSoftmaxCELoss(nn.Module):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        unweighted_loss = nn.CrossEntropyLoss(reduction='none')(pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "# 指定这些序列的有效⻓度为4、2、0,可以看出第⼀个序列的损失为第二个序列的两倍,第三个序列的损失为零\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long), torch.tensor([4, 2, 0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练seq2seq模型\"\"\"\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher Forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 3)  # 梯度裁剪\n",
    "            optimizer.step()\n",
    "            if batch_idx % 300 == 0:\n",
    "                print('loss:', l.sum().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32.09489059448242\n",
      "loss: 17.18158721923828\n",
      "loss: 14.40119743347168\n",
      "loss: 11.086263656616211\n",
      "loss: 12.216743469238281\n",
      "loss: 11.442331314086914\n",
      "loss: 9.792119979858398\n",
      "loss: 9.429816246032715\n",
      "loss: 7.6101531982421875\n",
      "loss: 5.980750560760498\n",
      "loss: 7.450530529022217\n",
      "loss: 9.265278816223145\n",
      "loss: 7.191188812255859\n",
      "loss: 6.401327133178711\n",
      "loss: 7.133780479431152\n",
      "loss: 6.776965141296387\n",
      "loss: 5.665550708770752\n",
      "loss: 5.071460247039795\n",
      "loss: 3.9234721660614014\n",
      "loss: 5.337695598602295\n",
      "loss: 4.92610502243042\n",
      "loss: 4.907920837402344\n",
      "loss: 4.653550148010254\n",
      "loss: 3.51749324798584\n",
      "loss: 3.3403403759002686\n",
      "loss: 4.995725154876709\n",
      "loss: 3.334987163543701\n",
      "loss: 3.8026440143585205\n",
      "loss: 3.4175543785095215\n",
      "loss: 3.383772850036621\n",
      "loss: 3.627635955810547\n",
      "loss: 3.4659602642059326\n",
      "loss: 4.620195388793945\n",
      "loss: 3.661541700363159\n",
      "loss: 3.198986291885376\n",
      "loss: 2.8333771228790283\n",
      "loss: 3.7583210468292236\n",
      "loss: 2.796978712081909\n",
      "loss: 2.804910659790039\n",
      "loss: 3.2903800010681152\n",
      "loss: 2.970715045928955\n",
      "loss: 2.8095133304595947\n",
      "loss: 2.6072959899902344\n",
      "loss: 2.3482484817504883\n",
      "loss: 2.8086140155792236\n",
      "loss: 3.6252803802490234\n",
      "loss: 3.04392409324646\n",
      "loss: 3.432758331298828\n",
      "loss: 3.310533046722412\n",
      "loss: 2.6453514099121094\n",
      "loss: 2.5733065605163574\n",
      "loss: 3.088225841522217\n",
      "loss: 2.577043294906616\n",
      "loss: 2.5231857299804688\n",
      "loss: 2.601315975189209\n",
      "loss: 2.5932555198669434\n",
      "loss: 2.4620492458343506\n",
      "loss: 3.1960132122039795\n",
      "loss: 2.58487868309021\n",
      "loss: 2.3989830017089844\n",
      "loss: 2.3253393173217773\n",
      "loss: 2.6483843326568604\n",
      "loss: 2.2130210399627686\n",
      "loss: 3.2750024795532227\n",
      "loss: 2.0637755393981934\n",
      "loss: 2.5261027812957764\n",
      "loss: 2.5246024131774902\n",
      "loss: 2.071737766265869\n",
      "loss: 2.511270761489868\n",
      "loss: 2.443239688873291\n",
      "loss: 3.313957691192627\n",
      "loss: 3.031494617462158\n",
      "loss: 2.668776512145996\n",
      "loss: 1.8675295114517212\n",
      "loss: 2.43595814704895\n",
      "loss: 2.4508705139160156\n",
      "loss: 2.5083394050598145\n",
      "loss: 2.403799057006836\n",
      "loss: 2.571953296661377\n",
      "loss: 2.8397932052612305\n",
      "loss: 2.2513628005981445\n",
      "loss: 1.905755877494812\n",
      "loss: 2.71400785446167\n",
      "loss: 2.877267599105835\n",
      "loss: 2.5059430599212646\n",
      "loss: 2.125943183898926\n",
      "loss: 2.5057878494262695\n",
      "loss: 1.966689944267273\n",
      "loss: 2.4904427528381348\n",
      "loss: 1.962160348892212\n",
      "loss: 1.904680609703064\n",
      "loss: 2.1110188961029053\n",
      "loss: 3.0331122875213623\n",
      "loss: 1.7173789739608765\n",
      "loss: 2.532735586166382\n",
      "loss: 2.4665489196777344\n",
      "loss: 2.6335110664367676\n",
      "loss: 2.3678112030029297\n",
      "loss: 2.1317496299743652\n",
      "loss: 2.870744228363037\n",
      "loss: 2.398402214050293\n",
      "loss: 2.5069494247436523\n",
      "loss: 2.525221824645996\n",
      "loss: 1.881454348564148\n",
      "loss: 2.2530415058135986\n",
      "loss: 2.559774875640869\n",
      "loss: 2.0468525886535645\n",
      "loss: 2.0372347831726074\n",
      "loss: 2.2656733989715576\n",
      "loss: 2.1698110103607178\n",
      "loss: 2.2165393829345703\n",
      "loss: 1.9719420671463013\n",
      "loss: 2.814572334289551\n",
      "loss: 1.7007622718811035\n",
      "loss: 2.5409488677978516\n",
      "loss: 2.2694029808044434\n",
      "loss: 1.9032812118530273\n",
      "loss: 1.8376896381378174\n",
      "loss: 2.296226739883423\n",
      "loss: 2.682704448699951\n",
      "loss: 2.168161153793335\n",
      "loss: 2.635221004486084\n",
      "loss: 2.2268009185791016\n",
      "loss: 2.604247808456421\n",
      "loss: 2.5564560890197754\n",
      "loss: 2.5917563438415527\n",
      "loss: 1.9729108810424805\n",
      "loss: 2.077873706817627\n",
      "loss: 1.3589662313461304\n",
      "loss: 2.6231698989868164\n",
      "loss: 2.021545886993408\n",
      "loss: 1.7509765625\n",
      "loss: 2.0213136672973633\n",
      "loss: 2.198610782623291\n",
      "loss: 2.1227567195892334\n",
      "loss: 2.3407704830169678\n",
      "loss: 2.3248538970947266\n",
      "loss: 1.5594958066940308\n",
      "loss: 2.854912281036377\n",
      "loss: 1.8440957069396973\n",
      "loss: 2.078429698944092\n",
      "loss: 2.770136833190918\n",
      "loss: 1.8033220767974854\n",
      "loss: 2.0515782833099365\n",
      "loss: 2.3044955730438232\n",
      "loss: 2.0661191940307617\n",
      "loss: 2.501962661743164\n",
      "loss: 2.4374871253967285\n",
      "loss: 2.3028550148010254\n",
      "loss: 2.6427340507507324\n",
      "loss: 2.6226730346679688\n",
      "loss: 1.9596346616744995\n",
      "loss: 1.8278319835662842\n",
      "loss: 2.2589147090911865\n",
      "loss: 2.0658535957336426\n",
      "loss: 3.0270018577575684\n",
      "loss: 1.8559353351593018\n",
      "loss: 1.9814518690109253\n",
      "loss: 2.3594295978546143\n",
      "loss: 2.1690611839294434\n",
      "loss: 1.775492787361145\n",
      "loss: 2.6757402420043945\n",
      "loss: 2.7940938472747803\n",
      "loss: 3.5810346603393555\n",
      "loss: 1.822514295578003\n",
      "loss: 2.251430034637451\n",
      "loss: 2.8342390060424805\n",
      "loss: 2.4035449028015137\n",
      "loss: 2.130613088607788\n",
      "loss: 2.1138062477111816\n",
      "loss: 2.0189013481140137\n",
      "loss: 2.1938884258270264\n",
      "loss: 1.7517125606536865\n",
      "loss: 2.059945821762085\n",
      "loss: 1.7875971794128418\n",
      "loss: 2.5724759101867676\n",
      "loss: 2.2801074981689453\n",
      "loss: 1.7885069847106934\n",
      "loss: 1.4684312343597412\n",
      "loss: 1.732047200202942\n",
      "loss: 2.534822463989258\n",
      "loss: 1.8187174797058105\n",
      "loss: 2.4714162349700928\n",
      "loss: 1.4298020601272583\n",
      "loss: 2.3530125617980957\n",
      "loss: 2.2065160274505615\n",
      "loss: 2.0567710399627686\n",
      "loss: 1.6937837600708008\n",
      "loss: 2.0994091033935547\n",
      "loss: 2.234869956970215\n",
      "loss: 1.7446056604385376\n",
      "loss: 2.233860492706299\n",
      "loss: 1.5978994369506836\n",
      "loss: 1.8109527826309204\n",
      "loss: 2.257852554321289\n",
      "loss: 2.6616578102111816\n",
      "loss: 1.783432126045227\n",
      "loss: 2.6936533451080322\n",
      "loss: 2.7113754749298096\n",
      "loss: 2.3187804222106934\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 32, 25\n",
    "lr, num_epochs, device = 0.005, 200, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(text, batch_size, num_steps, num_examples=1000)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                         dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                                  dropout)\n",
    "\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型预测与评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device):\n",
    "    \"\"\"Seq2Seq模型的预测\"\"\"\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X)\n",
    "    # 最终的隐藏状态\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_lens=enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 使用具有预测最高可能性的词元,作为解码器在下⼀时间步的输⼊\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        if pred == tgt_vocab['<eos>']:  # 如果单词为'<eos>',则表示输出序列预测结束\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    # 重新翻译回句子\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va au lit !, bleu 0.174\n",
      "i lost . => je l’ai perdu ., bleu 0.674\n",
      "he's calm . => il est réussi ., bleu 0.548\n",
      "i'm home . => je suis chez moi ., bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "all_attension_weight_seq = []\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    all_attension_weight_seq.append(dec_attention_weight_seq)\n",
    "    chencherry = SmoothingFunction()\n",
    "    # 使用bleu指标进行结果评估\n",
    "    blen = sentence_bleu([translation], fra, weights=(1 / 2.0, 1 / 2.0), smoothing_function=chencherry.method1)\n",
    "    print(f'{eng} => {translation}, bleu {blen:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2043, 0.2492, 0.2128, 0.1036, 0.0814, 0.2628],\n        [0.2509, 0.2682, 0.2743, 0.2438, 0.2951, 0.2066],\n        [0.2736, 0.2428, 0.2586, 0.3324, 0.3151, 0.2637],\n        [0.2713, 0.2398, 0.2543, 0.3202, 0.3084, 0.2669]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_attension_weight_seq[3]第四个句子的注意力分数\n",
    "first_sentence_attention_weight = torch.stack([i[0][0][0] for i in all_attension_weight_seq[3]], 1)[:4, :]\n",
    "first_sentence_attention_weight = first_sentence_attention_weight.cpu().detach()\n",
    "first_sentence_attention_weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax_1 = plt.subplot(111)\n",
    "sns.heatmap(first_sentence_attention_weight, cmap='Reds', ax=ax_1)\n",
    "ax_1.set_xlabel(\"目标句子\")\n",
    "ax_1.set_ylabel(\"原句子\")\n",
    "ax_1.set_title(\"注意力权重\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}