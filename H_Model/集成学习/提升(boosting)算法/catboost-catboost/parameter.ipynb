{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## cat主要调节参数及其含义\n",
    "\n",
    "1. 其他参数\n",
    "    * loss_function/objective===>xgboost(objective)\n",
    "    * thread_count===>xgboost(nthread)\n",
    "    * allow_writing_files\n",
    "    * eval_metric===>xgboost(eval_metric)\n",
    "    * task_type\n",
    "    * leaf_estimation_method\n",
    "    * iterations/n_estimators===>xgboost(num_boost_round)\n",
    "    * use_best_model\n",
    "    * *****************************\n",
    "    * pool===>xgboost(dtrain)\n",
    "    * early_stopping_rounds===>xgboost(early_stopping_rounds)\n",
    "    * eval_set===>xgboost(evals)\n",
    "    * verbose_eval===>xgboost(verbose_eval)\n",
    "\n",
    "3. 树调节参数\n",
    "    * max_depth/depth===>xgboost(max_depth)\n",
    "\n",
    "4. 防止过拟合参数\n",
    "    * colsample_bylevel===>xgboost(colsample_bylevel)\n",
    "    * learning_rate===>xgboost(learning_rate)\n",
    "    * reg_lambda===>xgboost(reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 54)\n",
      "(2250,)\n",
      "[1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "X = datasets.fetch_covtype().data[:3000]\n",
    "y = datasets.fetch_covtype().target[:3000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.unique(y_train))  # 7分类任务"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_dataset = cat.Pool(data=X_train, label=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# loss_function:The metric to use in training.\n",
    "# eval_metric:The metric used for overfitting detection (if enabled) and best model selection (if enabled).\n",
    "# loss_function/eval_metric可自定义:具体参考https://catboost.ai/docs/concepts/python-usages-examples.html#custom-loss-function-eval-metric\n",
    "loss_function/eval_metric可选参数:\n",
    "RMSE: 均方根误差==>loss_function/eval_metric\n",
    "MAE:平均绝对误差===>loss_function/eval_metric\n",
    "R2: R平方==>eval_metric\n",
    "\n",
    "CrossEntropy:交叉熵===>loss_function/eval_metric\n",
    "Logloss: 负对数似然函数值(二分类)===>loss_function/eval_metric\n",
    "\n",
    "MultiClass:多分类logloss===>loss_function/eval_metric\n",
    "\n",
    "Precision:查准率(多分类)===>eval_metric\n",
    "Recall:召回率(多分类)===>eval_metric\n",
    "F1:F1值(多分类)===>eval_metric\n",
    "Accuracy:精度(多分类)===>eval_metric\n",
    "AUC:多分类===>eval_metric\n",
    "'''\n",
    "\n",
    "'''\n",
    "verbose:\n",
    "The purpose of this parameter depends on the type of the given value:\n",
    "\n",
    "1. bool — Defines the logging level:\n",
    "    * “True”  corresponds to the Verbose logging level\n",
    "    * “False” corresponds to the Silent logging level\n",
    "2. int — Use the Verbose logging level and set the logging period to the value of this parameter.\n",
    "'''\n",
    "\n",
    "'''\n",
    "task_type:\n",
    "The processing unit type to use for training.\n",
    "\n",
    "Possible values:\n",
    "    * CPU\n",
    "    * GPU\n",
    "'''\n",
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          # 不支持定义多个eval_metric\n",
    "          # 默认与loss_function定义相同\n",
    "          \"eval_metric\": \"MultiClass\",\n",
    "          # Allow to write analytical and snapshot files during training.\n",
    "          # If set to “False”, the snapshot and data visualization tools are unavailable.\n",
    "          # 默认allow_writing_files=True\n",
    "          \"allow_writing_files\": False,\n",
    "          # The number of threads to use during the training.\n",
    "          \"thread_count\": -1,\n",
    "          \"task_type\": 'CPU'  # 默认task_type='CPU'\n",
    "          }\n",
    "\n",
    "'''\n",
    "相比xgboost/lightgbm\n",
    "    * y标签不要求0开始\n",
    "    * 不需要指定多分类类别数量,自动识别是否为多分类任务\n",
    "'''\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The method used to calculate the values in leaves.\n",
    "    * Possible values:\n",
    "    * Newton\n",
    "    * Gradient\n",
    "    * Exact\n",
    "\n",
    "默认值:\n",
    "Depends on the mode and the selected loss function:\n",
    "    * Regression with Quantile or MAE loss functions — One Exact iteration.\n",
    "    * Regression with any loss function but Quantile or MAE – One Gradient iteration.\n",
    "    * Classification mode – Ten Newton iterations.\n",
    "    * Multiclassification mode – One Newton iteration.\n",
    "\"\"\"\n",
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          \"leaf_estimation_method\": \"Gradient\"\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          \"n_estimators\": 200  # 默认n_estimators=1000\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          # 默认6 (16 if the growing policy is set to Lossguide)\n",
    "          \"max_depth\": 6\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          # Random subspace method. The percentage of features to use at each split selection, when features are selected over again at random.\n",
    "          \"colsample_bylevel\": 0.8  #\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          # Used for reducing the gradient step.\n",
    "          \"learning_rate\": 0.01\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(750, 7)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          # Coefficient at the L2 regularization term of the cost function.\n",
    "          \"reg_lambda\": 1  # 默认reg_lambda=3.0\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "To employ param {'use_best_model': True} provide non-empty 'eval_set'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-505d8df2e88c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m           }\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpool\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(pool, params, dtrain, logging_level, verbose, iterations, num_boost_round, evals, eval_set, plot, verbose_eval, metric_period, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   5887\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5888\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCatBoost\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5889\u001B[1;33m     model.fit(X=pool, eval_set=eval_set, logging_level=logging_level, plot=plot, verbose=verbose,\n\u001B[0m\u001B[0;32m   5890\u001B[0m               \u001B[0mverbose_eval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose_eval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric_period\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetric_period\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5891\u001B[0m               \u001B[0mearly_stopping_rounds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mearly_stopping_rounds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_snapshot\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msave_snapshot\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   2141\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mCatBoost\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2142\u001B[0m         \"\"\"\n\u001B[1;32m-> 2143\u001B[1;33m         return self._fit(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id,\n\u001B[0m\u001B[0;32m   2144\u001B[0m                          \u001B[0mpairs_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbaseline\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0muse_best_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meval_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogging_level\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2145\u001B[0m                          \u001B[0mcolumn_description\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose_eval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric_period\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msilent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mearly_stopping_rounds\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   1976\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mCatBoostError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1977\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1978\u001B[1;33m         train_params = self._prepare_train_params(\n\u001B[0m\u001B[0;32m   1979\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcat_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcat_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtext_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0membedding_features\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0membedding_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1980\u001B[0m             \u001B[0mpairs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpairs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup_id\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroup_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroup_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_prepare_train_params\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001B[0m\n\u001B[0;32m   1949\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1950\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_param\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'use_best_model'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0meval_total_row_count\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1951\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mCatBoostError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"To employ param {'use_best_model': True} provide non-empty 'eval_set'.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1952\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1953\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minit_model\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPATH_TYPES\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mCatBoostError\u001B[0m: To employ param {'use_best_model': True} provide non-empty 'eval_set'."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If this parameter is set, the number of trees that are saved in the resulting model is defined as follows:\n",
    "    Build the number of trees defined by the training parameters.\n",
    "    Use the validation dataset to identify the iteration with the optimal value of the metric specified in  --eval-metric (eval_metric).\n",
    "\"\"\"\n",
    "params = {\"loss_function\": \"MultiClass\",\n",
    "          \"allow_writing_files\": False,\n",
    "          \"verbose\": False,\n",
    "          # 通过eval_metric选择最优模型\n",
    "          # 必须设置eval_set参数\n",
    "          \"use_best_model\": True\n",
    "          }\n",
    "\n",
    "model = cat.train(pool=train_dataset, params=params)\n",
    "model.predict(X_test).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}