{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 极大似然估计\n",
    "&emsp;&emsp;在朴素贝叶斯中,学习意味着估计$ P(Y=c_k) $和$ P(X^{(j)}=x^{(j)}|Y=c_k) $.可以应用极大似然估计法估计相应的概率.\n",
    "先验概率$P(Y=c_k)$的极大似然估计是                 \n",
    "$$ P(Y=c_k) = \\frac{\\sum_{i=1}^N I(y_i = c_k)}{N} \\quad k=1,2,3\\dots,K $$                \n",
    "\n",
    "***\n",
    "\n",
    "<font color='red' size=4>证明:</font> 设$c_1, c_2, \\cdots, c_K$,对应的元概率为$ p_1, p_2, \\cdots, p_K$,\n",
    "$ N $次试验中出现的次数为$ m_1, m_2, \\dots, m_K $,\n",
    "易知$\\sum_{i=1}^K p_k = 1$,$\\sum_{i=1}^K m_k = N$.\n",
    "显然$ (M_1, ..., M_K) $服从$ N $ 次试验丶元概率为$ p_1, ..., p_K $的多项分布,\n",
    "则随机变量向量$ (M_1, ...., M_K) $的联合概率密度函数为:             \n",
    "\n",
    "\\begin{equation}\n",
    "f(m_1,...,m_K|p_1, \\cdots, p_K) = \\frac{N!}{m_1 ! ...m_K !} p_1^{m_1} ...p_K^{m_K} = N! \\prod_{k=1}^K \\frac{p_k^{m_k}}{m_k !}\n",
    "\\end{equation}  \n",
    "\n",
    "<font color='red' size=4>定义:</font>设$f(\\mathbf{x}|\\theta)$为样本$(X_1, X_2, \\cdots, X_n)$的联合概率密度(质量)函数,\n",
    "如果观测到$X=\\mathbf{x}$,则称$\\theta$的函数       \n",
    "$$ L(\\theta|\\mathbf{x}) = f(\\mathbf{x}|\\theta) $$        \n",
    "为似然函数(likelihood function)            \n",
    "&emsp;&emsp;由似然函数的定义可知此时对应的似然函数为                      \n",
    "$$  f(p_1, \\cdots, p_K|m_1, \\cdots, m_K) =  \\frac{N!}{m_1 ! ...m_K !} p_1^{m_1} ...p_K^{m_K} $$            \n",
    "对数似然函数为             \n",
    "$$ \\ln f(p_1, \\cdots, p_K|m_1, \\cdots, m_K) = \\ln \\frac{N!}{m_1! \\cdots m_K!} \\sum_{k=1}^K (m_k \\ln p_k)  $$            \n",
    "&emsp;&emsp;为了找到$ p $的最大似然解,需要关于$ p_k$最大化$ \\ln f(p_1, \\cdots, p_k|m_1, \\cdots, m_k) $,\n",
    "因为有$ \\sum_{k=1}^K p_k =1 $,于是引入拉格朗日函数($ \\lambda $为拉格朗如乘子)                                         \n",
    "$$ \\ln \\frac{N!}{m_1! \\cdots m_K!} \\sum_{k=1}^K (m_k \\ln p_k) + \\lambda (\\sum_{k=1}^K p_k -1)   $$               \n",
    "上式对$ p_k $求导并令为零,可得         \n",
    "$$ p_k = - \\frac{m_k}{\\lambda} $$         \n",
    "由$ \\sum_{k=1}^K p_k =1 $可得     \n",
    "$$ \\frac{\\sum_{k=1}^K m_k}{\\lambda} = -1 $$         \n",
    "解得\n",
    "$$ \\lambda = - N $$           \n",
    "即有                  \n",
    "$$ p_k = \\frac{m_k}{N} \\quad k=1,2,3\\dots,K $$             \n",
    "即\n",
    "$$ P(Y=c_k) = \\frac{\\sum_{i=1}^N I(y_i = c_k)}{N} \\quad k=1,2,3\\dots,K $$            \n",
    "得证! \n",
    "***\n",
    "\n",
    "设第$j$个特征$ X^{(j)} $的可能取值的结合为$ \\{  a_{j1}, a_{j2}, \\dots, a_{jS_j} \\} $,\n",
    "条件概率$ P(X^{(j)} = a_{jl} |Y=c_k )$的极大似然估计是              \n",
    "$$  P(X^{(j)} = a_{jl} |Y=c_k) = \\frac{\\sum_{i=1}^N I(X_i^{(j)} = a_{jl}, y_i=c_k)}{\\sum_{i=1}^N I(y_i = c_k)}, \\quad j=1,2,\\cdots, n; \\quad l = 1,2,\\cdots, S_j; \\quad k=1,2,\\cdots, K  \\qquad \\text{注:基于多项式模型} $$       \n",
    "其中,$N$为样本数量,$n$为特征数量,$S_j$为第$j$个特征取值的数量.     \n",
    "&emsp;&emsp;对连续数据可考虑概率密度函数(离散为:基于多项式模型或伯努利模型(将重复的样本都视为其只出现1次)),假定$ P(X^{(j)} = a_{jl} |Y=c_k) \\sim N(\\mu_{c_k, j}, \\sigma^2_{c_k, j}) $,其中\n",
    "$ \\mu_{c_k, j} $和$ \\sigma^2_{c_k, j} $分别是$c_k$类样本在第$j$个属性上取值的均值和方差,则有   \n",
    "$$  P(X^{(j)} = a_{jl} |Y=c_k) = \\frac{1}{ \\sqrt{2 \\pi}  \\sigma_{c_k, j}} \\exp \\left( - \\frac{(a_{jl} - \\mu_{c_k, j})^2}{2 \\sigma^2_{c_k, j}}  \\right)  $$    \n",
    "参数$ \\mu_{c_k, j} $和$ \\sigma^2_{c_k, j} $使用最大似然估计\n",
    "\n",
    "### 贝叶斯估计\n",
    "&emsp;&emsp;用极大似然估计可能会出现所要估计的概率值为0的情况.\n",
    "这时会影响到后验概率的计算结果(即连乘式中有一项为零,即使其他项均不为零,连乘式计算出的概率值也为零,这显然不可理),易使分类产生偏差.\n",
    "解决这一问题的方法使采用贝叶斯估计.具体地,条件概率的贝叶斯估计是      \n",
    "\n",
    "$$P_{\\lambda}(X^{(j)} = a_{jl} |Y=c_k) = \\frac{\\sum_{i=1}^N I(X_i^{(j)} = a_{jl}, y_i=c_k) + \\lambda}{\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda}$$\n",
    "\n",
    "式中$ \\lambda \\geq 0 $.等价于在随机变量各个取值的频数上赋予一个正数$ \\lambda >0 $(拉普拉斯修正实质上假设了属性值与类别均匀分布).\n",
    "当$ \\lambda =0 $时就是极大似然估计.常取$ \\lambda=1 $,这时称为拉普拉斯平滑(Laplacian smoothing).显然,\n",
    "拉普拉斯修正了因训练数据集样本补充而导致概率估计为零的问题,并且在训练集变大时,修正过程引入的先验(prior)的影响也会逐渐变得可忽略,\n",
    "使得估计值趋向于实际概率值.易得,对任何$ l=1,2,\\cdots, S_j , k=1,2,\\cdots,K$,有      \n",
    "\n",
    "\\begin{align}        \n",
    "& P_{\\lambda}(X^{(j)} = a_{jl} |Y=c_k) > 0 \\\\\n",
    "& \\sum_{l=1}^{S_j} P(X^{(j)} = a_{jl} |Y=c_k) =1\n",
    "\\end{align}        \n",
    "\n",
    "这表明贝叶斯估计确为一种概率分布.同样,先验概率的贝叶斯估计是                       \n",
    "$$  P_{\\lambda}(Y=c_k) = \\frac{\\sum_{i=1}^N I(y_i = c_k) + \\lambda}{N + K \\lambda}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
