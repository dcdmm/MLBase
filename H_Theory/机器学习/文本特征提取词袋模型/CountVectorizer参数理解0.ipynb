{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 文档级别的,即根据词袋模型来计算文档基于单词的特征\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "stop_word = ['as', 'at', 'was', 'were', 'when', 'to', 'on', 'of', 'has', 'in', 'an']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "CountVectorizer(max_df=0.7, max_features=10, min_df=0.2,\n                stop_words=['as', 'at', 'was', 'were', 'when', 'to', 'on', 'of',\n                            'has', 'in', 'an'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "max_dffloat in range [0.0, 1.0] or int, default=1.0\n",
    "    When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "min_dffloat in range [0.0, 1.0] or int, default=1\n",
    "    When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "    This value is also called cut-off in the literature.\n",
    "    If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "stop_wordsstring {‘english’}, list, default=None\n",
    "    If ‘english’, a built-in stop word list for English is used.\n",
    "    If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "\n",
    "max_featuresint, default=None\n",
    "    If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "'''\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1),\n",
    "                             max_features=10, # 最大特征数为10\n",
    "                             stop_words=stop_word,\n",
    "                             max_df=0.7, # 忽略频率大于0.7的词,若为整数,即表示频数\n",
    "                             min_df=0.2) # 忽略频率小于0.2的词\n",
    "vectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['Age has reached the end of the beginning of a word.\\n',\n 'May be guilty in his seems to passing a lot of different life became the appearance of the same day;\\n',\n 'May be back in the past, to oneself the paranoid weird belief disillusionment, these days, my mind has been very messy, in my mind constantly.\\n',\n 'Always feel oneself should go to do something, or write something. Twenty years of life trajectory deeply shallow, suddenly feel something, do it.\\n',\n 'During my childhood, think lucky money and new clothes are necessary for New Year, but as the advance of the age, will be more and more found that those things are optional;\\n',\n \"Junior high school, thought to have a crush on just means that the real growth, but over the past three years later, his writing of alumni in peace, suddenly found that isn't really grow up, it seems is not so important;\\n\",\n \"Then in high school, think don't want to give vent to out your inner voice can be in the high school children of the feelings in a period, but was eventually infarction when graduation party in the throat, later again stood on the pitch he has sweat profusely, looked at his thrown a basketball hoops, suddenly found himself has already can't remember his appearance.\\n\",\n \"A person's time, your ideas are always special to clear. Want, want, line is clear, as if nothing could shake his.\\n\",\n 'Also once seemed to be determined to do something, but more often is he backed out at last. Dislike his cowardice, finally found that there are a lot of love, there are a lot of miss, like shadow really have been doomed.\\n',\n 'Those who do, just green years oneself give oneself an arm injection, or is a self-righteous spiritual.\\n',\n 'At the moment, the sky is dark, the air is fresh factor after just rained. Suddenly thought of blue plaid shirt;\\n',\n 'Those were broken into various shapes of stationery;\\n',\n 'From the corner at the beginning of deep friendship;\\n',\n \"Have declared the end of the encounter that haven't start planning... Those years, those days of do, finally, like youth, will end in our life.\"]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data.txt', 'r', encoding='utf-8') as f:\n",
    "    a = f.readlines()\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "14"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n       [0, 1, 0, 1, 0, 0, 0, 2, 0, 0],\n       [0, 1, 0, 0, 0, 1, 0, 2, 0, 0],\n       [0, 0, 2, 0, 0, 1, 0, 0, 0, 1],\n       [2, 1, 0, 0, 0, 0, 1, 2, 1, 0],\n       [0, 0, 0, 1, 1, 0, 2, 2, 0, 1],\n       [0, 1, 0, 2, 0, 0, 0, 4, 0, 0],\n       [1, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n       [2, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n       [0, 0, 1, 0, 1, 2, 0, 0, 1, 1],\n       [0, 0, 0, 0, 2, 0, 0, 3, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n       [0, 0, 1, 0, 0, 0, 1, 2, 2, 1]], dtype=int64)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(a)\n",
    "X.toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['are', 'be', 'do', 'his', 'is', 'oneself', 'that', 'the', 'those', 'years']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 降序排列\n",
    "vectorizer.get_feature_names() # Array mapping from feature integer indices to feature name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'the': 7,\n 'be': 1,\n 'his': 3,\n 'oneself': 5,\n 'do': 2,\n 'years': 9,\n 'are': 0,\n 'that': 6,\n 'those': 8,\n 'is': 4}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_ # A mapping of terms to feature indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}