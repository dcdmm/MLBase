{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_data = datasets.MNIST('../../../../Other/datasets/PyTorch',\n",
    "                            train=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ]))\n",
    "\n",
    "test_data = datasets.MNIST('../../../../Other/datasets/PyTorch',\n",
    "                           train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ]))\n",
    "\n",
    "# 手写数字训练数据集\n",
    "train_loader = Data.DataLoader(dataset=train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True)\n",
    "\n",
    "# 手写数字测试数据集\n",
    "test_loader = Data.DataLoader(dataset=test_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.featrues = nn.Sequential(  # 内部实现了forward函数;各模块顺序执行\n",
    "            nn.Conv2d(1, 6, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),  # 10分类问题\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.featrues(x)\n",
    "        x = x.reshape(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criteon = nn.CrossEntropyLoss()  # 定义损失函数为交叉熵\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = LeNet()\n",
    "lenet = net.to(device)  # 模型设备转移必须在优化器定义前执行\n",
    "\n",
    "# RMSprop优化器\n",
    "optimizer = optim.RMSprop(net.parameters(),\n",
    "                          lr=learning_rate,  # 学习率\n",
    "                          momentum=0.4,  # 动量参数\\alpha;默认momentum=0\n",
    "                          alpha=0.9,  # 衰减速率\\rho\n",
    "                          eps=1e-10)  # 分母中的小常数\\delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n\n\n        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n\n\n        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n\n\n        ...,\n\n\n        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n\n\n        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n\n\n        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          ...,\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms_data = []\n",
    "for i, j in train_data:\n",
    "    transforms_data.append(i.tolist())\n",
    "transforms_data_ten = torch.tensor(transforms_data)\n",
    "transforms_data_ten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "transforms_data_loader = Data.DataLoader(transforms_data_ten, batch_size=200, shuffle=True)\n",
    "y_label = train_loader.dataset.targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch_model.train_evaluate import Train_Evaluate\n",
    "\n",
    "t_and_v = Train_Evaluate(model=lenet, optimizer=optimizer, criterion=criteon, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  [0    /60000 (0  %)]\tLoss: 2.306799\n",
      "Train Epoch: 0  [2000 /60000 (3  %)]\tLoss: 2.219586\n",
      "Train Epoch: 0  [4000 /60000 (7  %)]\tLoss: 1.588877\n",
      "Train Epoch: 0  [6000 /60000 (10 %)]\tLoss: 1.532783\n",
      "Train Epoch: 0  [8000 /60000 (13 %)]\tLoss: 0.637401\n",
      "Train Epoch: 0  [10000/60000 (17 %)]\tLoss: 0.555727\n",
      "Train Epoch: 0  [12000/60000 (20 %)]\tLoss: 0.254109\n",
      "Train Epoch: 0  [14000/60000 (23 %)]\tLoss: 0.319782\n",
      "Train Epoch: 0  [16000/60000 (27 %)]\tLoss: 0.312815\n",
      "Train Epoch: 0  [18000/60000 (30 %)]\tLoss: 0.216359\n",
      "Train Epoch: 0  [20000/60000 (33 %)]\tLoss: 0.307836\n",
      "Train Epoch: 0  [22000/60000 (37 %)]\tLoss: 0.221181\n",
      "Train Epoch: 0  [24000/60000 (40 %)]\tLoss: 0.111998\n",
      "Train Epoch: 0  [26000/60000 (43 %)]\tLoss: 0.202543\n",
      "Train Epoch: 0  [28000/60000 (47 %)]\tLoss: 0.229926\n",
      "Train Epoch: 0  [30000/60000 (50 %)]\tLoss: 0.113203\n",
      "Train Epoch: 0  [32000/60000 (53 %)]\tLoss: 0.224661\n",
      "Train Epoch: 0  [34000/60000 (57 %)]\tLoss: 0.241728\n",
      "Train Epoch: 0  [36000/60000 (60 %)]\tLoss: 0.223739\n",
      "Train Epoch: 0  [38000/60000 (63 %)]\tLoss: 0.125573\n",
      "Train Epoch: 0  [40000/60000 (67 %)]\tLoss: 0.168908\n",
      "Train Epoch: 0  [42000/60000 (70 %)]\tLoss: 0.194137\n",
      "Train Epoch: 0  [44000/60000 (73 %)]\tLoss: 0.112182\n",
      "Train Epoch: 0  [46000/60000 (77 %)]\tLoss: 0.184201\n",
      "Train Epoch: 0  [48000/60000 (80 %)]\tLoss: 0.133007\n",
      "Train Epoch: 0  [50000/60000 (83 %)]\tLoss: 0.144319\n",
      "Train Epoch: 0  [52000/60000 (87 %)]\tLoss: 0.281212\n",
      "Train Epoch: 0  [54000/60000 (90 %)]\tLoss: 0.051469\n",
      "Train Epoch: 0  [56000/60000 (93 %)]\tLoss: 0.145976\n",
      "Train Epoch: 0  [58000/60000 (97 %)]\tLoss: 0.150377\n",
      "Train Epoch: 0  [60000/60000 (100%)]\tLoss: 0.098960\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1  [0    /60000 (0  %)]\tLoss: 0.117146\n",
      "Train Epoch: 1  [2000 /60000 (3  %)]\tLoss: 0.255218\n",
      "Train Epoch: 1  [4000 /60000 (7  %)]\tLoss: 0.073057\n",
      "Train Epoch: 1  [6000 /60000 (10 %)]\tLoss: 0.100656\n",
      "Train Epoch: 1  [8000 /60000 (13 %)]\tLoss: 0.128334\n",
      "Train Epoch: 1  [10000/60000 (17 %)]\tLoss: 0.113422\n",
      "Train Epoch: 1  [12000/60000 (20 %)]\tLoss: 0.067058\n",
      "Train Epoch: 1  [14000/60000 (23 %)]\tLoss: 0.149124\n",
      "Train Epoch: 1  [16000/60000 (27 %)]\tLoss: 0.124250\n",
      "Train Epoch: 1  [18000/60000 (30 %)]\tLoss: 0.204396\n",
      "Train Epoch: 1  [20000/60000 (33 %)]\tLoss: 0.089639\n",
      "Train Epoch: 1  [22000/60000 (37 %)]\tLoss: 0.041276\n",
      "Train Epoch: 1  [24000/60000 (40 %)]\tLoss: 0.130996\n",
      "Train Epoch: 1  [26000/60000 (43 %)]\tLoss: 0.161034\n",
      "Train Epoch: 1  [28000/60000 (47 %)]\tLoss: 0.051694\n",
      "Train Epoch: 1  [30000/60000 (50 %)]\tLoss: 0.101085\n",
      "Train Epoch: 1  [32000/60000 (53 %)]\tLoss: 0.185843\n",
      "Train Epoch: 1  [34000/60000 (57 %)]\tLoss: 0.157718\n",
      "Train Epoch: 1  [36000/60000 (60 %)]\tLoss: 0.152803\n",
      "Train Epoch: 1  [38000/60000 (63 %)]\tLoss: 0.076400\n",
      "Train Epoch: 1  [40000/60000 (67 %)]\tLoss: 0.078271\n",
      "Train Epoch: 1  [42000/60000 (70 %)]\tLoss: 0.046565\n",
      "Train Epoch: 1  [44000/60000 (73 %)]\tLoss: 0.137816\n",
      "Train Epoch: 1  [46000/60000 (77 %)]\tLoss: 0.067680\n",
      "Train Epoch: 1  [48000/60000 (80 %)]\tLoss: 0.121464\n",
      "Train Epoch: 1  [50000/60000 (83 %)]\tLoss: 0.061355\n",
      "Train Epoch: 1  [52000/60000 (87 %)]\tLoss: 0.080368\n",
      "Train Epoch: 1  [54000/60000 (90 %)]\tLoss: 0.064667\n",
      "Train Epoch: 1  [56000/60000 (93 %)]\tLoss: 0.115547\n",
      "Train Epoch: 1  [58000/60000 (97 %)]\tLoss: 0.094613\n",
      "Train Epoch: 1  [60000/60000 (100%)]\tLoss: 0.076146\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 2  [0    /60000 (0  %)]\tLoss: 0.071522\n",
      "Train Epoch: 2  [2000 /60000 (3  %)]\tLoss: 0.055605\n",
      "Train Epoch: 2  [4000 /60000 (7  %)]\tLoss: 0.074335\n",
      "Train Epoch: 2  [6000 /60000 (10 %)]\tLoss: 0.063700\n",
      "Train Epoch: 2  [8000 /60000 (13 %)]\tLoss: 0.131106\n",
      "Train Epoch: 2  [10000/60000 (17 %)]\tLoss: 0.094874\n",
      "Train Epoch: 2  [12000/60000 (20 %)]\tLoss: 0.134778\n",
      "Train Epoch: 2  [14000/60000 (23 %)]\tLoss: 0.108434\n",
      "Train Epoch: 2  [16000/60000 (27 %)]\tLoss: 0.034917\n",
      "Train Epoch: 2  [18000/60000 (30 %)]\tLoss: 0.107816\n",
      "Train Epoch: 2  [20000/60000 (33 %)]\tLoss: 0.132187\n",
      "Train Epoch: 2  [22000/60000 (37 %)]\tLoss: 0.070526\n",
      "Train Epoch: 2  [24000/60000 (40 %)]\tLoss: 0.113774\n",
      "Train Epoch: 2  [26000/60000 (43 %)]\tLoss: 0.093358\n",
      "Train Epoch: 2  [28000/60000 (47 %)]\tLoss: 0.061567\n",
      "Train Epoch: 2  [30000/60000 (50 %)]\tLoss: 0.206801\n",
      "Train Epoch: 2  [32000/60000 (53 %)]\tLoss: 0.009045\n",
      "Train Epoch: 2  [34000/60000 (57 %)]\tLoss: 0.088564\n",
      "Train Epoch: 2  [36000/60000 (60 %)]\tLoss: 0.079938\n",
      "Train Epoch: 2  [38000/60000 (63 %)]\tLoss: 0.264005\n",
      "Train Epoch: 2  [40000/60000 (67 %)]\tLoss: 0.081849\n",
      "Train Epoch: 2  [42000/60000 (70 %)]\tLoss: 0.184790\n",
      "Train Epoch: 2  [44000/60000 (73 %)]\tLoss: 0.033310\n",
      "Train Epoch: 2  [46000/60000 (77 %)]\tLoss: 0.174460\n",
      "Train Epoch: 2  [48000/60000 (80 %)]\tLoss: 0.049338\n",
      "Train Epoch: 2  [50000/60000 (83 %)]\tLoss: 0.072067\n",
      "Train Epoch: 2  [52000/60000 (87 %)]\tLoss: 0.108375\n",
      "Train Epoch: 2  [54000/60000 (90 %)]\tLoss: 0.093013\n",
      "Train Epoch: 2  [56000/60000 (93 %)]\tLoss: 0.398767\n",
      "Train Epoch: 2  [58000/60000 (97 %)]\tLoss: 0.046716\n",
      "Train Epoch: 2  [60000/60000 (100%)]\tLoss: 0.070416\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 3  [0    /60000 (0  %)]\tLoss: 0.062861\n",
      "Train Epoch: 3  [2000 /60000 (3  %)]\tLoss: 0.051617\n",
      "Train Epoch: 3  [4000 /60000 (7  %)]\tLoss: 0.064289\n",
      "Train Epoch: 3  [6000 /60000 (10 %)]\tLoss: 0.071266\n",
      "Train Epoch: 3  [8000 /60000 (13 %)]\tLoss: 0.027477\n",
      "Train Epoch: 3  [10000/60000 (17 %)]\tLoss: 0.036986\n",
      "Train Epoch: 3  [12000/60000 (20 %)]\tLoss: 0.080075\n",
      "Train Epoch: 3  [14000/60000 (23 %)]\tLoss: 0.117331\n",
      "Train Epoch: 3  [16000/60000 (27 %)]\tLoss: 0.189135\n",
      "Train Epoch: 3  [18000/60000 (30 %)]\tLoss: 0.063245\n",
      "Train Epoch: 3  [20000/60000 (33 %)]\tLoss: 0.203286\n",
      "Train Epoch: 3  [22000/60000 (37 %)]\tLoss: 0.030510\n",
      "Train Epoch: 3  [24000/60000 (40 %)]\tLoss: 0.089329\n",
      "Train Epoch: 3  [26000/60000 (43 %)]\tLoss: 0.043160\n",
      "Train Epoch: 3  [28000/60000 (47 %)]\tLoss: 0.111021\n",
      "Train Epoch: 3  [30000/60000 (50 %)]\tLoss: 0.072094\n",
      "Train Epoch: 3  [32000/60000 (53 %)]\tLoss: 0.103829\n",
      "Train Epoch: 3  [34000/60000 (57 %)]\tLoss: 0.035891\n",
      "Train Epoch: 3  [36000/60000 (60 %)]\tLoss: 0.111160\n",
      "Train Epoch: 3  [38000/60000 (63 %)]\tLoss: 0.033014\n",
      "Train Epoch: 3  [40000/60000 (67 %)]\tLoss: 0.112085\n",
      "Train Epoch: 3  [42000/60000 (70 %)]\tLoss: 0.088365\n",
      "Train Epoch: 3  [44000/60000 (73 %)]\tLoss: 0.043973\n",
      "Train Epoch: 3  [46000/60000 (77 %)]\tLoss: 0.074703\n",
      "Train Epoch: 3  [48000/60000 (80 %)]\tLoss: 0.070567\n",
      "Train Epoch: 3  [50000/60000 (83 %)]\tLoss: 0.203312\n",
      "Train Epoch: 3  [52000/60000 (87 %)]\tLoss: 0.053787\n",
      "Train Epoch: 3  [54000/60000 (90 %)]\tLoss: 0.094752\n",
      "Train Epoch: 3  [56000/60000 (93 %)]\tLoss: 0.041827\n",
      "Train Epoch: 3  [58000/60000 (97 %)]\tLoss: 0.117478\n",
      "Train Epoch: 3  [60000/60000 (100%)]\tLoss: 0.131591\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 4  [0    /60000 (0  %)]\tLoss: 0.159517\n",
      "Train Epoch: 4  [2000 /60000 (3  %)]\tLoss: 0.022674\n",
      "Train Epoch: 4  [4000 /60000 (7  %)]\tLoss: 0.114692\n",
      "Train Epoch: 4  [6000 /60000 (10 %)]\tLoss: 0.091615\n",
      "Train Epoch: 4  [8000 /60000 (13 %)]\tLoss: 0.060834\n",
      "Train Epoch: 4  [10000/60000 (17 %)]\tLoss: 0.156455\n",
      "Train Epoch: 4  [12000/60000 (20 %)]\tLoss: 0.105753\n",
      "Train Epoch: 4  [14000/60000 (23 %)]\tLoss: 0.022385\n",
      "Train Epoch: 4  [16000/60000 (27 %)]\tLoss: 0.116673\n",
      "Train Epoch: 4  [18000/60000 (30 %)]\tLoss: 0.106157\n",
      "Train Epoch: 4  [20000/60000 (33 %)]\tLoss: 0.042759\n",
      "Train Epoch: 4  [22000/60000 (37 %)]\tLoss: 0.167500\n",
      "Train Epoch: 4  [24000/60000 (40 %)]\tLoss: 0.076992\n",
      "Train Epoch: 4  [26000/60000 (43 %)]\tLoss: 0.092115\n",
      "Train Epoch: 4  [28000/60000 (47 %)]\tLoss: 0.087070\n",
      "Train Epoch: 4  [30000/60000 (50 %)]\tLoss: 0.080914\n",
      "Train Epoch: 4  [32000/60000 (53 %)]\tLoss: 0.090344\n",
      "Train Epoch: 4  [34000/60000 (57 %)]\tLoss: 0.100864\n",
      "Train Epoch: 4  [36000/60000 (60 %)]\tLoss: 0.128640\n",
      "Train Epoch: 4  [38000/60000 (63 %)]\tLoss: 0.079927\n",
      "Train Epoch: 4  [40000/60000 (67 %)]\tLoss: 0.145130\n",
      "Train Epoch: 4  [42000/60000 (70 %)]\tLoss: 0.132597\n",
      "Train Epoch: 4  [44000/60000 (73 %)]\tLoss: 0.067785\n",
      "Train Epoch: 4  [46000/60000 (77 %)]\tLoss: 0.170658\n",
      "Train Epoch: 4  [48000/60000 (80 %)]\tLoss: 0.088636\n",
      "Train Epoch: 4  [50000/60000 (83 %)]\tLoss: 0.043452\n",
      "Train Epoch: 4  [52000/60000 (87 %)]\tLoss: 0.095513\n",
      "Train Epoch: 4  [54000/60000 (90 %)]\tLoss: 0.113555\n",
      "Train Epoch: 4  [56000/60000 (93 %)]\tLoss: 0.107379\n",
      "Train Epoch: 4  [58000/60000 (97 %)]\tLoss: 0.094090\n",
      "Train Epoch: 4  [60000/60000 (100%)]\tLoss: 0.140173\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[12.682374000549316],\n [19.897192001342773],\n [21.733537673950195],\n [21.752864837646484],\n [32.318443298339844]]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_reslut = t_and_v.train_eval(train_loader=train_loader, valid_sets=[(transforms_data_loader, y_label)])\n",
    "metric_reslut"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}