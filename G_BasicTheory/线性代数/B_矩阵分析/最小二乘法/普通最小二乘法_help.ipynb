{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;考虑超定矩阵方程$ A\\mathbf{x} = b $,其中$b$为 $ m \\times 1 $数据向量,$ A$为 $ m \\times n $数据矩阵,并且 $ m >n $.   \n",
    "&emsp;&emsp;假定数据向量存在加性观测误差或噪音,即$ b = b_0 + e $,其中$ b_0$和 $ e$分别是无误差的数据向量和误差向量.   \n",
    "&emsp;&emsp;为了抵制误差对矩阵求解的影响,引入一校正向量$ \\Delta b $,并且用它去\"扰动\"有误差的数据向量$ b$.我们的目标是,\n",
    "使校正项$ \\Delta b $\"尽可能小(因为:$ E(e)=0 $)\",同时通过强令$ A\\mathbf{x} = b + \\Delta b $补偿存在于数据向量$ b$中的不确定性(噪音或误差),使\n",
    "得$ b + \\Delta b = b_0 + e+ \\Delta b \\rightarrow b_0 $,从而实现   \n",
    "$$ A\\mathbf{x} =b + \\Delta b \\Longrightarrow A\\mathbf{x} = b_0  $$    \n",
    "的转换.也就是,如果直接选择选择校正$ \\Delta b = A\\mathbf{x} -b $,并且使校正向量\"尽可能小\",则可以实现无误差的矩阵$ A \\mathbf{x} = b_0 $的求解.  \n",
    "&emsp;&emsp;矩阵方程这一求解思路可以用下面的优化问题进行描述    \n",
    "$$ \\min \\limits _\\mathbf{x} \\| \\Delta b \\|^2 = \\|  A\\mathbf{x}-b \\|^2_2  = (A\\mathbf{x}-b)^T(A\\mathbf{x}-b)$$   \n",
    "这一方法称为普通最小二乘法(ordinary least squares, OLS),常简称为最小二乘法.    \n",
    "&emsp;&emsp;事实上,校正向量$ \\Delta b = A\\mathbf{x} -b $恰好是矩阵方程 $ A \\mathbf{x} =b$的误差向量.因此,最小二乘方法的核心思想是\n",
    "求出的解向量$\\mathbf{x} $能使矩阵方程的误差平方和最小化.于是,矩阵方程$ A\\mathbf{x} = b $的普通最小二乘解为   \n",
    "$$ \\hat{\\mathbf{x}}_{LS} = \\mathrm{arg}\\min_\\mathbf{x} \\| A\\mathbf{x}-b \\|^2_2 $$  \n",
    "&emsp;&emsp;为了推导$\\mathbf{x}$的解析解,展开上式得    \n",
    "$$ \\phi = \\mathbf{x}^TA^TA\\mathbf{x} - \\mathbf{x}^TA^Tb - b^TA\\mathbf{x} + b^Tb \\qquad 注:(A\\mathbf{x}-b)^T = \\mathbf{x}^TA^T -b^T$$\n",
    "求$ \\phi $相对于$\\mathbf{x}$的导数,并令其结果等于零,则有   \n",
    "$$ \\frac{\\mathrm{d} \\phi}{\\mathrm{d}\\mathbf{x}} =2A^TA\\mathbf{x} - 2A^T b = 0 $$  \n",
    "也就是说,解$ \\mathbf{x}$必然满足      \n",
    "$$ A^T A \\mathbf{x} = A^T b $$   \n",
    "&emsp;&emsp;当 $ m \\times n $矩阵$ A$ 有不同的秩时,上叙方程的解有两种不同的情况.\n",
    "<font color='red' size=4>情况1:</font>&emsp;超定方程$ m >n  $满列秩,即$ \\mathrm{rank} A = n $.              \n",
    "&emsp;&emsp;由于$ A^T A $非奇异,所有方程有唯一的解   \n",
    "$$ \\mathbf{x}_{LS} = (A^TA)^{-1}A^Tb $$    \n",
    "&emsp;&emsp;在参数估计理论中,称这种可以唯一确定的未知参数$\\mathbf{x}$是(唯一)可辨识的.  \n",
    "&emsp;&emsp;对于秩亏损$(\\mathrm{rank}A < n)$的超定方程,则最小二乘解为   \n",
    "$$ \\mathbf{x}_{LS} = (A^T A)^+A^T b $$     \n",
    "其中$ B+ $表示矩阵$B$的Moore-Penrose逆矩阵      \n",
    "<font color='red' size=4>情况2:</font>&emsp;欠定方程$ \\mathrm{rank} A =m<n$.    \n",
    "&emsp;&emsp;在这种情况下,由$ \\mathbf{x}$的不同解均得到相同的$A\\mathbf{x} $值.显而易见,虽然数据向量$ b$可以提供有关$ A\\mathbf{x}$的\n",
    "某些信息,但是无法区分对应于相同$ A\\mathbf{x}$值的各个不同的未知参数向量$ \\mathbf{x}$.因此,称这样的参数向量是不可辨识的.更一般的,如果\n",
    "某参数的不同值给出在抽样空间上的相同分布,则称该参数是不可辨识的.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}