{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始输入为:\n",
      "(tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]]),)\n",
      "修改初始输入后,输出为:\n",
      " tensor([[[[10., 10.],\n",
      "          [10., 10.]]]])\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module, ABC):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "'''\n",
    "The hook will be called every time before forward() is invoked. It should have the following signature:\n",
    "    hook(module, input) -> None or modified input\n",
    "'''\n",
    "\n",
    "\n",
    "def forward_pre_hook(module,\n",
    "                     data_input):  # 模块的输入参数元组(即该模块forward方法的参数构成的参数元组)\n",
    "    \"\"\"对输入进行相关操作\"\"\"\n",
    "    print(\"初始输入为:\\n{}\".format(data_input))\n",
    "    data_input[0].mul_(5)  # 初始输入*=5\n",
    "    return data_input[0].mul_(2)  # 初始输入再*=2\n",
    "\n",
    "\n",
    "net.pool1.register_forward_pre_hook(forward_pre_hook)  # 模块前向传播之前\n",
    "\n",
    "fake_img = torch.ones((1, 1, 4, 4))\n",
    "output = net(fake_img)\n",
    "print('修改初始输入后,输出为:\\n', output)  # 结果为1*5*2=10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始卷积核:\n",
      "tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]]], grad_fn=<CloneBackward>)\n",
      "修改后的卷积核为:\n",
      " Parameter containing:\n",
      "tensor([[[[0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000]]],\n",
      "\n",
      "\n",
      "        [[[0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net1 = Net1()\n",
    "init.constant_(net1.conv1.weight, 1)  # 将conv1的卷积核初始化为全1的tensor\n",
    "weight_lst = list()\n",
    "\n",
    "\n",
    "def forward_pre_hook1(module, data_input):\n",
    "    \"\"\"对模块权重进行相关操作\"\"\"\n",
    "\n",
    "    # module.weight为可变数据类型,模型运行过程中,module.weight的改变都为in-place操作,若要保存其渐变过程,必须使用.clone()函数先拷贝,得到其副本\n",
    "    weight = module.weight.clone()\n",
    "    weight_lst.append(weight)\n",
    "    print('初始卷积核:\\n{}'.format(weight))\n",
    "    with torch.no_grad():\n",
    "        module.weight.div_(2)  # 初始卷积核/=2\n",
    "    return module.weight.data.div_(5)  # 初始卷积核/=5\n",
    "\n",
    "\n",
    "net1.conv1.register_forward_pre_hook(forward_pre_hook1)\n",
    "\n",
    "fake_img = torch.ones((1, 1, 4, 4))\n",
    "out1 = net1(fake_img)\n",
    "print('修改后的卷积核为:\\n', net1.conv1.weight)  # 结果为1/2/5=0.10000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[[[1., 1., 1.],\n           [1., 1., 1.],\n           [1., 1., 1.]]],\n \n \n         [[[1., 1., 1.],\n           [1., 1., 1.],\n           [1., 1., 1.]]]], grad_fn=<CloneBackward>)]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_lst"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}