{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before step:tensor([[10., 11.],\n",
      "        [12., 13.]])\n",
      "weight after step:tensor([[ 9.9000, 10.9000],\n",
      "        [11.9000, 12.9000]])\n"
     ]
    }
   ],
   "source": [
    "weight = torch.tensor([[10, 11],\n",
    "                       [12, 13]], dtype=torch.float32, requires_grad=True)\n",
    "weight.grad = torch.ones((2, 2))\n",
    "\n",
    "optimizer = optim.SGD([weight],  # iterable of parameters\n",
    "                      lr=0.1)\n",
    "\n",
    "print(\"weight before step:{}\".format(weight.data))\n",
    "optimizer.step()  # 进行一次梯度更新\n",
    "print(\"weight after step:{}\".format(weight.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[ 9.9000, 10.9000],\n",
      "        [11.9000, 12.9000]], requires_grad=True)], 'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
      "\n",
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[ 9.9000, 10.9000],\n",
      "        [11.9000, 12.9000]], requires_grad=True)], 'lr': 0.1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}, {'params': [tensor([[100., 200.],\n",
      "        [300., 400.]], requires_grad=True)], 'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n"
     ]
    }
   ],
   "source": [
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups), end='\\n\\n')\n",
    "\n",
    "weight1 = torch.tensor([[100, 200],\n",
    "                        [300, 400]], dtype=torch.float32, requires_grad=True)\n",
    "weight1.grad = torch.ones((2, 2))\n",
    "\n",
    "optimizer.add_param_group({\"params\": weight1,\n",
    "                           'lr': 0.0001})  # Add a param group to the Optimizer s param_groups.\n",
    "\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'params': [tensor([[ 9.9000, 10.9000],\n           [11.9000, 12.9000]], requires_grad=True)],\n  'momentum': 0.7,\n  'lr': 1e-05,\n  'dampening': 0,\n  'weight_decay': 0,\n  'nesterov': False},\n {'params': [tensor([[100., 200.],\n           [300., 400.]], requires_grad=True)],\n  'momentum': 0.5,\n  'lr': 0.01,\n  'dampening': 0,\n  'weight_decay': 0,\n  'nesterov': False}]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建多个参数组(list内的每一个字典为一组参数组);list外参数可作用与所有参数组,但优先级低于字典内参数\n",
    "optimizer1 = optim.SGD([dict(params=weight, momentum=0.7, lr=0.00001),\n",
    "                        dict(params=weight1, momentum=0.5)],\n",
    "                       lr=0.01)  # dicts defining parameter groups\n",
    "optimizer1.param_groups"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight in optimizer id is:2071899966184\n",
      "weight id is:2071899966184\n",
      "\n",
      "weight1 in optimizer id is:2071899978472\n",
      "weight1 id is:2071899978472\n",
      "\n",
      "weight.grad is tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "weight1.grad is tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "after optimizer.zero_grad(), weight.grad is\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "after optimizer.zero_grad(), weight1.grad is\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"weight in optimizer id is:{}\\nweight id is:{}\\n\".\n",
    "      format(id(optimizer.param_groups[0]['params'][0]),\n",
    "             id(weight)))\n",
    "print(\"weight1 in optimizer id is:{}\\nweight1 id is:{}\\n\".\n",
    "      format(id(optimizer.param_groups[1]['params'][0]),\n",
    "             id(weight1)))  # 优化器管理的参数和实际参数指向同一内存地址\n",
    "\n",
    "print(\"weight.grad is {}\".format(weight.grad))\n",
    "print(\"weight1.grad is {}\".format(weight1.grad), end='\\n\\n')\n",
    "optimizer.zero_grad()  # 清零所有参数的梯度\n",
    "\n",
    "print(\"after optimizer.zero_grad(), weight.grad is\\n{}\".format(weight.grad))\n",
    "print(\"after optimizer.zero_grad(), weight1.grad is\\n{}\".format(weight1.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}