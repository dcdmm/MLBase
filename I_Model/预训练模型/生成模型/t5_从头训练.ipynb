{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8bc64c-fa83-47f1-8612-f5e14532dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514ae099-e936-4765-a7fc-9f09cbd86fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = load_from_disk(\"billsum\")['train']\n",
    "billsum = billsum.remove_columns(['Unnamed: 0', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bb087c-8d54-4564-84e9-1fd5f9b49398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary'],\n",
       "        num_rows: 15159\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary'],\n",
       "        num_rows: 3790\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)\n",
    "billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82b3024-177e-4822-b73c-e22e26b311b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/env_3812/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d646a5-5402-432d-914c-4e7e74e3ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Prefix the input with a prompt so T5 knows this is a summarization task. Some models capable of multiple NLP tasks require prompting for specific tasks.\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764d3c95-99e4-4b5f-9eaa-e7bd8c44c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02668595314025879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 16,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef9afb1b110439ab3652d703103738c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021994829177856445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e521bad6a04bffb46ae80545cda4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15159\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3790\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# T5ForConditionalGeneration forward函数函数签名:\n",
    "'''\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids: Optional[torch.LongTensor] = None,\n",
    "    attention_mask: Optional[torch.FloatTensor] = None,\n",
    "    decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "    decoder_attention_mask: Optional[torch.BoolTensor] = None,\n",
    "    head_mask: Optional[torch.FloatTensor] = None,\n",
    "    decoder_head_mask: Optional[torch.FloatTensor] = None,\n",
    "    cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "    encoder_outputs: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "    past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n",
    "    inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "    decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "    labels: Optional[torch.LongTensor] = None,\n",
    "    use_cache: Optional[bool] = None,\n",
    "    output_attentions: Optional[bool] = None,\n",
    "    output_hidden_states: Optional[bool] = None,\n",
    "    return_dict: Optional[bool] = None,\n",
    ") -> Union[Tuple[torch.FloatTensor], Seq2SeqLMOutput]:\n",
    "'''\n",
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "tokenized_billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a33366-5a23-4280-a83b-ecac8343eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相当于torch.utils.data.DataLoader中collate_fn的作用(可以重写,参考K_demo/way_of_training/pytorch_transformer.ipynb)\n",
    "# Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "'''\n",
    "model ([`PreTrainedModel`]):\n",
    "    The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n",
    "    prepare the *decoder_input_ids*\n",
    "\n",
    "    This is useful when using *label_smoothing* to avoid calculating loss twice.\n",
    "'''\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d453e691-1009-463c-a541-96eccb79e769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics and a software package used for\\nevaluating automatic summarization and machine translation software in natural language processing.\\nThe metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation.\\n\\nNote that ROUGE is case insensitive, meaning that upper case letters are treated the same way as lower case letters.\\n\\nThis metrics is a wrapper around Google Research reimplementation of ROUGE:\\nhttps://github.com/google-research/google-research/tree/master/rouge\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837bf8ee-79ee-49a7-9dd0-f7b97c6dec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # predictions.shape=[batch_size, max(该批次生成句子长度)]\n",
    "    # labels.shape=[batch_size, max(该批次句子长度)]\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b8b027-e6cd-4377-9e06-adfa9cdcc005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /t5-small/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f5ed3f27520>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/t5-small/resolve/main/config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.23.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5889ba1-5dc7-491c-852c-3e6e86c8ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从头训练\n",
    "model = AutoModelForSeq2SeqLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cb8216c-cb7c-47b4-ac41-b8825e7624e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/root/miniconda3/envs/env_3812/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 15159\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9480\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9480' max='9480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9480/9480 1:37:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.856100</td>\n",
       "      <td>7.113714</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.073200</td>\n",
       "      <td>6.748777</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.138200</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.780300</td>\n",
       "      <td>6.520914</td>\n",
       "      <td>0.152400</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.595600</td>\n",
       "      <td>6.331944</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>6.416400</td>\n",
       "      <td>6.184151</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.270900</td>\n",
       "      <td>6.062525</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>6.162200</td>\n",
       "      <td>5.950559</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>6.058500</td>\n",
       "      <td>5.857097</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>18.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>5.774234</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.886200</td>\n",
       "      <td>5.702372</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.814900</td>\n",
       "      <td>5.637588</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>18.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.754900</td>\n",
       "      <td>5.592557</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>18.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>5.706300</td>\n",
       "      <td>5.540424</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>18.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.663200</td>\n",
       "      <td>5.503357</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>18.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>5.624400</td>\n",
       "      <td>5.476897</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>18.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.600200</td>\n",
       "      <td>5.448681</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>18.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>5.569800</td>\n",
       "      <td>5.434177</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>18.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>5.558500</td>\n",
       "      <td>5.422565</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>18.990800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-500/spiece.model\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-1000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-1000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-1000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-1000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-1500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-1500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-1500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-1500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-2000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-2000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-2000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-2000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-2500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-2500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-2500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-2500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-2000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-3000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-3000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-3000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-3000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-3500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-3500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-3500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-3500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-4000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-4000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-4000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-4000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-3500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-4500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-4500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-4500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-4500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-5000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-5000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-5000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-5000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-4500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-5500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-5500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-5500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-5500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-6000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-6000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-6000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-6000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-6500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-6500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-6500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-6500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-7000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-7000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-7000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-7000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-7500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-7500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-7500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-7500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-8000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-8000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-8000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-8000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-7500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-8500\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-8500/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-8500/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-8500/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, text. If summary, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3790\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to my_awesome_billsum_model_t5/checkpoint-9000\n",
      "Configuration saved in my_awesome_billsum_model_t5/checkpoint-9000/config.json\n",
      "Model weights saved in my_awesome_billsum_model_t5/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in my_awesome_billsum_model_t5/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in my_awesome_billsum_model_t5/checkpoint-9000/special_tokens_map.json\n",
      "Copy vocab file to my_awesome_billsum_model_t5/checkpoint-9000/spiece.model\n",
      "Deleting older checkpoint [my_awesome_billsum_model_t5/checkpoint-8500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9480, training_loss=6.101312281612605, metrics={'train_runtime': 5857.4807, 'train_samples_per_second': 25.88, 'train_steps_per_second': 1.618, 'total_flos': 4.103292737028096e+16, 'train_loss': 6.101312281612605, 'epoch': 10.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model_t5\",\n",
    "    save_total_limit=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=10,\n",
    "\n",
    "    # 区别于TrainingArguments特有参数:\n",
    "    # predict_with_generate (bool, optional, defaults to False) — Whether to use generate to calculate generative metrics (ROUGE, BLEU).\n",
    "    predict_with_generate=True,\n",
    "    # generation_max_length (int, optional) — The max_length to use on each evaluation loop when predict_with_generate=True. Will default to the max_length value of the model configuration.\n",
    "    generation_max_length=32,  # 生成的最大长度\n",
    "    # generation_num_beams (int, optional) — The num_beams to use on each evaluation loop when predict_with_generate=True. Will default to the num_beams value of the model configuration.\n",
    "    generation_num_beams=4  # 集束搜索\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9882a1d-bd9f-4337-98ad-ef41e8607542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# T5ForConditionalGeneration\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a9f24f-785d-427a-ba51-e956c90dd5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  736,  989,    7,    8, 5034, 4336, 1081,   12,    3,    9, 1015,\n",
       "            3,    9,  568,    3,    9,    3,    9,    3,    9,    3,    9, 1015,\n",
       "           42,    3,    9,    3,    9,    3,    9,    3,    9,    3,    9,    3,\n",
       "            9,    3,    9,    3,    9,    3,    9,    3,    9,  568,    3,    9,\n",
       "          568,   24]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference\n",
    "# generate具体参数参考:huggingface GenerationConfig类\n",
    "inputs = tokenizer(\n",
    "    \"summarize: Shields a business entity from civil liability relating to any injury or death occurring at a facility of that entity in connection with a use of such facility by a nonprofit organization if: (1) the use occurs outside the scope of business of the business entity; (2) such injury or death occurs during a period that such facility is used by such organization; and (3) the business entity authorized the use of such facility by the organization. Makes this Act inapplicable to an injury or death that results from an act or omission of a business entity that constitutes gross negligence or intentional misconduct, including misconduct that: (1) constitutes a hate crime or a crime of violence or act of international terrorism for which the defendant has been convicted in any court; or (2) involves a sexual offense for which the defendant has been convicted in any court or misconduct for which the defendant has been found to have violated a Federal or State civil rights law. Preempts State laws to the extent that such laws are inconsistent with this Act, except State law that provides additional protection from liability. Specifies that this Act shall not be construed to supersede any Federal or State health or safety law. Makes this Act inapplicable to any civil action in a State court against a business entity in which all parties are citizens of the State if such State, citing this Act's authority and containing no other provision, enacts a statute declaring the State's election that this Act shall not apply to such action in the State.\",\n",
    "    return_tensors=\"pt\").input_ids\n",
    "inputs = inputs.to(model.device)\n",
    "'''\n",
    "repetition_penalty (`float`, *optional*, defaults to 1.0):\n",
    "    The parameter for repetition penalty. 1.0 means no penalty. See [this\n",
    "    paper](https://arxiv.org/pdf/1909.05858.pdf) for more details.\n",
    "'''\n",
    "outputs = model.generate(inputs,\n",
    "                         repetition_penalty=1.0,\n",
    "                         # The minimum length of the sequence to be generated.默认min_length=0\n",
    "                         min_length=0,\n",
    "                         # The maximum length the generated tokens can have.默认max_length=20\n",
    "                         max_length=50)  # 贪心搜索\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c5b915-f78c-44f2-b7ae-8ed7ec94c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amends the Federal criminal code to a State a person a a a a State or a a a a a a a a a a person a person that\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aeffb30-33ff-48db-a16f-23821d03e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sec. 3) Directs the Secretary of the Interior to provide for a\n"
     ]
    }
   ],
   "source": [
    "# 集束搜索:选择了概率最大的前k个(本质上也是贪心的思想,只不过它考虑了更多的候选搜索空间,因此可以得到更多的生成结果)\n",
    "'''\n",
    "length_penalty (`float`, *optional*, defaults to 1.0):\n",
    "    Exponential penalty to the length that is used with beam-based generation. It is applied as an exponent to\n",
    "    the sequence length, which in turn is used to divide the score of the sequence. Since the score is the log\n",
    "    likelihood of the sequence (i.e. negative), `length_penalty` > 0.0 promotes longer sequences, while\n",
    "    `length_penalty` < 0.0 encourages shorter sequences.\n",
    "'''\n",
    "print(tokenizer.decode(model.generate(inputs,\n",
    "                                      length_penalty=1.0,\n",
    "                                      # Number of beams for beam search. 1 means no beam search.默认num_beams=1\n",
    "                                      num_beams=5)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bfd747-92a1-4d95-ab13-49595503ba08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3812",
   "language": "python",
   "name": "env_3812"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}