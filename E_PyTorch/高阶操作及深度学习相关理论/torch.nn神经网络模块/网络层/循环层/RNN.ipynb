{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 100)\n",
    "\n",
    "rnn = nn.RNN(input_size=100, hidden_size=30)\n",
    "\n",
    "out, h = rnn(x)  # 单层,序列长度为1\n",
    "print(out - h)  # 此时out=h;即相当于RNNCell(只输出h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 10]) torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=100,  # The number of expected features in the input x\n",
    "             hidden_size=10,  # 隐含变量的维度大小\n",
    "             num_layers=2,  # 循环神经网络层的多少.若num_layers=2,则第2层的输入是第1层的输出(每一层都有一套参数,层与层之间的参数相互独立)\n",
    "             nonlinearity='tanh',  # 非线性激活函数类型,也可以设置为'relu'.默认nonlinearity='tanh'\n",
    "             bias=True,  # 是否添加偏置.默认bias=True\n",
    "             batch_first=False,  # 如果batch_first=True,则输入张量大小为(N,T,C),而不是(T,N,C).默认batch_first=False\n",
    "             dropout=0.5)  # 如果这个值非零,则在循环神经网络最后输出的基础上加上丢弃层,丢弃的概率由输入的dropout确定.默认dropout=0\n",
    "x = torch.randn(20, 3, 100)  # 输入的默认形状为(T,N,C),其中T为序列的长度,N为min-batch的大小,C为输入的特征数目\n",
    "h_0 = torch.ones((2, 3, 10))  # (L*D, N, hidden_size),其中L为循环神经网络层数,D为1(单向)或2(双向)\n",
    "out, h = rnn(x, hx=h_0)  # 自定h_0,默认h_0为全0张量\n",
    "print(out.shape, h.shape)  # out.shape=(T, N, hidden_size);h.shape=(L*D, N, hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([10, 100])\n",
      "weight_hh_l0   shape= torch.Size([10, 10])\n",
      "bias_ih_l0   shape= torch.Size([10])\n",
      "bias_hh_l0   shape= torch.Size([10])\n",
      "weight_ih_l1   shape= torch.Size([10, 10])\n",
      "weight_hh_l1   shape= torch.Size([10, 10])\n",
      "bias_ih_l1   shape= torch.Size([10])\n",
      "bias_hh_l1   shape= torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in rnn.named_parameters():\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 30]) torch.Size([4, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "b_run = nn.RNN(input_size=100, hidden_size=15, num_layers=2,\n",
    "               bidirectional=True)  # 是否为设置为双向循环神经网络,默认为False\n",
    "b_h_0 = torch.ones((4, 3, 15))\n",
    "b_out, b_h = b_run(x, hx=b_h_0)\n",
    "# b_out为每个序列最后一层的输出(双向则2维度*2);b_h为最后一个序列每层的输出(双向则0维度*2)\n",
    "print(b_out.shape, b_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0   shape= torch.Size([15, 100])\n",
      "weight_hh_l0   shape= torch.Size([15, 15])\n",
      "bias_ih_l0   shape= torch.Size([15])\n",
      "bias_hh_l0   shape= torch.Size([15])\n",
      "weight_ih_l0_reverse   shape= torch.Size([15, 100])\n",
      "weight_hh_l0_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l0_reverse   shape= torch.Size([15])\n",
      "bias_hh_l0_reverse   shape= torch.Size([15])\n",
      "weight_ih_l1   shape= torch.Size([15, 30])\n",
      "weight_hh_l1   shape= torch.Size([15, 15])\n",
      "bias_ih_l1   shape= torch.Size([15])\n",
      "bias_hh_l1   shape= torch.Size([15])\n",
      "weight_ih_l1_reverse   shape= torch.Size([15, 30])\n",
      "weight_hh_l1_reverse   shape= torch.Size([15, 15])\n",
      "bias_ih_l1_reverse   shape= torch.Size([15])\n",
      "bias_hh_l1_reverse   shape= torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "for name, param in b_run.named_parameters():\n",
    "    '''正向和反向两个方向的循环神经网络有各自的相互独立的参数'''\n",
    "    print(name, '  shape=', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0151,  0.2416, -0.1300,  0.2511, -0.1046, -0.2568, -0.0399, -0.0436,\n         -0.0560, -0.1171,  0.1784, -0.1166,  0.0170, -0.2542, -0.0576],\n        [ 0.1710,  0.0177,  0.2132,  0.1023,  0.0123, -0.2208, -0.0694, -0.0633,\n          0.0901, -0.1417, -0.0244,  0.1078,  0.0665,  0.0623, -0.0622],\n        [ 0.0223,  0.0194,  0.1586,  0.0082, -0.0610, -0.1835,  0.0842,  0.0679,\n          0.2415,  0.0253, -0.0188,  0.0402, -0.0924, -0.1708, -0.1862],\n        [-0.0646, -0.2451,  0.2310,  0.0786,  0.1117,  0.1437,  0.1339,  0.2013,\n          0.2449, -0.1397,  0.0485,  0.1635,  0.0893, -0.0083, -0.1293],\n        [-0.0877, -0.2164,  0.1001,  0.1458,  0.2493,  0.2552,  0.0658, -0.1343,\n          0.1258,  0.1682, -0.0175,  0.0632, -0.1136,  0.1003,  0.1862],\n        [-0.1152,  0.1715, -0.2484, -0.0080,  0.1486,  0.2519, -0.2383,  0.2436,\n          0.0661, -0.0351,  0.0128, -0.1589,  0.0005,  0.2010, -0.0897],\n        [ 0.0659, -0.1093,  0.2278, -0.1867,  0.1529,  0.1795, -0.0826,  0.2168,\n          0.1536, -0.1944,  0.2553, -0.0017,  0.0732, -0.0542,  0.1833],\n        [-0.1960,  0.1551, -0.0127,  0.0655, -0.1572, -0.2479,  0.1801, -0.2580,\n         -0.1208, -0.1117,  0.1242, -0.1467, -0.1384, -0.0988, -0.1146],\n        [-0.0421, -0.0355,  0.1378,  0.1195,  0.1532,  0.2117,  0.0691, -0.0288,\n          0.0051, -0.0237, -0.0632, -0.1979, -0.0570, -0.2315,  0.1778],\n        [ 0.1111, -0.1709, -0.2448, -0.0633,  0.0584,  0.0961,  0.1612,  0.0220,\n          0.2235, -0.0861, -0.1012,  0.2282,  0.1182,  0.0187,  0.1362],\n        [-0.2075,  0.0147,  0.0489,  0.2580, -0.2487,  0.0581, -0.1859,  0.0155,\n          0.2085,  0.2086,  0.0462, -0.2470,  0.1924, -0.2524,  0.0583],\n        [-0.0930, -0.0106,  0.0312,  0.2150, -0.0909,  0.1379,  0.0430,  0.1216,\n          0.0997, -0.2513, -0.0898,  0.1430, -0.0739, -0.1855, -0.0998],\n        [ 0.0080,  0.1960, -0.0034, -0.2450,  0.1102, -0.2418, -0.1271, -0.1198,\n         -0.1290,  0.0040, -0.1470,  0.0631,  0.2135, -0.1952,  0.1434],\n        [ 0.1717, -0.1882, -0.0596,  0.2349, -0.0751, -0.0294,  0.1733, -0.0549,\n          0.2369,  0.0129, -0.2113, -0.0366,  0.0372,  0.0013, -0.0424],\n        [-0.0168, -0.2566, -0.1389, -0.2579, -0.1620, -0.2091,  0.1543, -0.1989,\n         -0.1875,  0.1849,  0.0104, -0.0758, -0.0801,  0.1996,  0.0541]],\n       requires_grad=True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_hh_l0  # all the weights and biases are initialized from U(-\\sqrt{k}, \\sqrt{k}), where k=1/hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0966, -0.1513, -0.1663,  0.1073,  0.0128, -0.0440, -0.1607, -0.0373,\n          0.0577,  0.2502,  0.2120, -0.1458,  0.2072,  0.2539, -0.1886,  0.0592,\n         -0.1056, -0.2543, -0.0498,  0.1931,  0.1678, -0.2482, -0.1619,  0.1888,\n         -0.2212, -0.1199,  0.2173,  0.1100,  0.1541,  0.1874],\n        [ 0.0346, -0.0526,  0.1500,  0.1631,  0.0500, -0.0284, -0.2350,  0.2069,\n         -0.1388,  0.2476,  0.1115, -0.1041,  0.1347,  0.1144, -0.0265,  0.1072,\n          0.0079, -0.2297,  0.0762,  0.1567,  0.2171, -0.1911, -0.0843, -0.0939,\n         -0.0571,  0.1494, -0.0350, -0.2530,  0.1366, -0.1039],\n        [ 0.0522, -0.1960, -0.1029,  0.0592, -0.2230,  0.2427,  0.1275,  0.0909,\n          0.1935,  0.0555, -0.2453,  0.1403, -0.2141, -0.0277, -0.0187,  0.1958,\n         -0.1234, -0.2159,  0.2092,  0.1423, -0.2287, -0.0164, -0.1524, -0.1810,\n         -0.0498,  0.0433, -0.0319,  0.1020,  0.1557,  0.0984],\n        [-0.1029, -0.0461,  0.0122,  0.0928, -0.0769,  0.2359,  0.2515,  0.1601,\n         -0.0743,  0.0144,  0.0721, -0.0101,  0.1203,  0.2167,  0.1069, -0.1340,\n          0.1469, -0.0564,  0.0693, -0.2341, -0.1048,  0.0571, -0.1211, -0.2110,\n         -0.2158,  0.0031,  0.1256,  0.1400,  0.1864,  0.0327],\n        [ 0.2548, -0.0902, -0.1097,  0.2006, -0.1517,  0.1257,  0.0037, -0.0678,\n          0.0959, -0.1681,  0.0066,  0.1282,  0.0429, -0.0321, -0.2041, -0.2049,\n          0.0639, -0.2499, -0.1497, -0.2020, -0.1124,  0.1645,  0.2498, -0.0364,\n          0.1859, -0.2079, -0.1003, -0.0557, -0.2169, -0.0936],\n        [ 0.0184, -0.0678, -0.1605,  0.1262, -0.1699,  0.2271,  0.2266, -0.1192,\n         -0.1790, -0.1091,  0.0067, -0.2019,  0.1975, -0.1917,  0.0053,  0.1607,\n         -0.1935,  0.2362,  0.0161, -0.0964,  0.0990, -0.1639, -0.0084, -0.1270,\n          0.1088, -0.2051, -0.1220, -0.2089, -0.1888,  0.2387],\n        [-0.1391, -0.0273,  0.1287,  0.0952,  0.1449, -0.1425, -0.1979, -0.1456,\n          0.0235,  0.1912,  0.1620,  0.1010, -0.0319,  0.0363, -0.0434, -0.0126,\n          0.0260, -0.2533,  0.0265,  0.1486, -0.0949, -0.1198, -0.0170,  0.1627,\n         -0.1642, -0.0281, -0.0139,  0.2123, -0.1453,  0.2007],\n        [ 0.1550,  0.2334,  0.0414,  0.1840, -0.0514,  0.0461, -0.2106,  0.1807,\n         -0.1455, -0.0937, -0.1382,  0.1836, -0.0378, -0.0535,  0.1046,  0.2075,\n         -0.0567, -0.0826,  0.2152, -0.0083,  0.2023,  0.0706,  0.1372,  0.0692,\n          0.1230,  0.1453,  0.0008,  0.2296, -0.2473,  0.0053],\n        [-0.1809, -0.1909,  0.0279,  0.0701,  0.1324, -0.0631,  0.0997,  0.2341,\n         -0.0235, -0.2079,  0.1462,  0.1326,  0.0228, -0.0911,  0.1772,  0.1554,\n         -0.1808, -0.0699, -0.0334, -0.0912,  0.0534,  0.0885,  0.1881,  0.2066,\n          0.0057, -0.1776, -0.0249, -0.2535,  0.1577, -0.2345],\n        [-0.0946,  0.1815,  0.2572,  0.2364,  0.2171, -0.1226,  0.1821,  0.1039,\n          0.2513, -0.1913, -0.2045, -0.2556,  0.0622, -0.1154, -0.2259,  0.2152,\n         -0.2024,  0.1172, -0.1783, -0.2249,  0.2501, -0.0926, -0.1627, -0.1180,\n          0.0287, -0.2481, -0.0276, -0.0007, -0.0240,  0.1354],\n        [-0.0469, -0.1802,  0.0504, -0.1249,  0.0068,  0.1248,  0.2475,  0.1909,\n          0.1211,  0.0072,  0.1218,  0.0085,  0.0304,  0.0867,  0.0962,  0.1862,\n         -0.1579,  0.1239,  0.1023, -0.1851,  0.2137,  0.1113,  0.2435, -0.0118,\n          0.0608, -0.0598,  0.0175,  0.0166,  0.2175, -0.0380],\n        [-0.2554,  0.2373,  0.0757, -0.2067,  0.0706,  0.1413,  0.1410,  0.1095,\n         -0.2370,  0.0937,  0.0062,  0.2264,  0.1340,  0.0617, -0.0825,  0.1075,\n          0.0487,  0.0318,  0.2201,  0.0338, -0.1991, -0.2368,  0.1993, -0.1281,\n         -0.1328, -0.0484,  0.1925, -0.1615, -0.0278,  0.2510],\n        [-0.2372,  0.0294, -0.2309, -0.1617,  0.0043, -0.1201,  0.1639,  0.2515,\n          0.0595, -0.1910, -0.2579,  0.0864,  0.1536,  0.1370, -0.2248,  0.1612,\n         -0.0996, -0.1134, -0.1899, -0.1619, -0.1658, -0.0640,  0.0079,  0.0079,\n         -0.0644, -0.0906, -0.1696,  0.0743, -0.1283, -0.0668],\n        [-0.1868, -0.2109,  0.1274, -0.1807, -0.0462, -0.2166, -0.0572, -0.1227,\n         -0.2276,  0.0182, -0.0713,  0.2150,  0.1651,  0.1582, -0.0045,  0.2203,\n         -0.0312,  0.1282,  0.1942,  0.1595,  0.0113,  0.0382, -0.1985,  0.2073,\n         -0.2218, -0.1501,  0.1329, -0.0689, -0.2428,  0.1643],\n        [-0.1805, -0.0451, -0.1311,  0.0882, -0.0765, -0.1660,  0.1876, -0.1509,\n         -0.0578,  0.1204,  0.0524, -0.1142,  0.0982,  0.2241,  0.0433,  0.1157,\n         -0.1995,  0.0192,  0.2413,  0.2460, -0.1117, -0.1194, -0.2212,  0.1725,\n          0.0432, -0.0227, -0.1362,  0.1041, -0.0528,  0.2309]],\n       requires_grad=True)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_run.weight_ih_l1  # 参数全部都requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}