{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import IMDB\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_iter = IMDB(split='train')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield [tok.text for tok in spacy_en.tokenizer(text)]  # 分词\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter))  # Build a Vocab from an iterator."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "vocab.insert_token(\"<unk>\", 0)\n",
    "vocab.insert_token(\"<pad>\", 1)\n",
    "vocab.insert_token(\"<SOS>\", 2)\n",
    "vocab.insert_token(\"<EOS>\", 3)\n",
    "vocab.set_default_index(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 200])\n",
      "tensor([[-0.0715,  0.0935,  0.0237,  ...,  0.3362,  0.0306,  0.2558],\n",
      "        [ 0.1765,  0.2921, -0.0021,  ..., -0.2077, -0.2319, -0.1081],\n",
      "        [ 0.1229,  0.5804, -0.0696,  ..., -0.0392, -0.1624, -0.0967],\n",
      "        ...,\n",
      "        [-0.0020,  0.0202, -0.0244,  ...,  0.0142, -0.8224, -0.3703],\n",
      "        [ 0.1291, -0.2605,  0.0139,  ...,  0.1384, -0.0146,  0.4337],\n",
      "        [-0.7300,  0.5164, -0.5798,  ...,  0.3581,  1.1576,  0.2573]])\n"
     ]
    }
   ],
   "source": [
    "# 预训练词向量\n",
    "vec1 = torchtext.vocab.Vectors(name=\"glove.6B.200d.txt\",\n",
    "                               max_vectors=25000,\n",
    "                               cache=r'C:\\Users\\duanm\\Music\\GitHubProjects\\MLNote\\E_PyTorch\\高阶操作及深度学习相关理论\\torchtext自然语言处理\\.vector_cache')\n",
    "\n",
    "print(vec1.vectors.shape)\n",
    "print(vec1.vectors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121068, 200])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = vec1.get_vecs_by_tokens(vocab.get_itos())\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "print(pretrained_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def to_map_style_dataset(iter_data):\n",
    "    r\"\"\"Convert iterable-style dataset to map-style dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    class _MapStyleDataset(Data.Dataset):\n",
    "\n",
    "        def __init__(self, iter_data):\n",
    "            # TODO Avoid list issue #1296\n",
    "            self._data = list(iter_data)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self._data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self._data[idx]\n",
    "\n",
    "    return _MapStyleDataset(iter_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_iter, test_iter = IMDB(split=('train', 'test'))\n",
    "\n",
    "train_data = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "num_train = int(len(train_data) * 0.7)\n",
    "train_dataset, valid_dataset = random_split(train_data,\n",
    "                                            [num_train, len(train_data) - num_train])  # 划分数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "text_transform = lambda x: [vocab['<SOS>']] + [vocab[token] for token in\n",
    "                                               [tok.text for tok in spacy_en.tokenizer(x)]] + [vocab['<EOS>']]\n",
    "label_transform = lambda x: 1.0 if x == 'pos' else 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text))\n",
    "        lengths.append(len(processed_text))\n",
    "        text_list.append(processed_text)\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, batch_first=False, padding_value=0), torch.tensor(lengths)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
    "                              collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "vocal_size, embedding_size = pretrained_embeddings.shape\n",
    "hidden_size = 256\n",
    "dropout = 0.5\n",
    "bidirectional = True\n",
    "out_size = 1\n",
    "num_layers = 2\n",
    "lr = 0.001  # 学习率\n",
    "weight_decay = 1e-5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from BRNNModel import BRNN\n",
    "% run BRNNModel.py\n",
    "\n",
    "net = BRNN(vocal_size=vocal_size,\n",
    "           embedding_size=embedding_size,\n",
    "           hidden_size=hidden_size,\n",
    "           num_layers=num_layers,\n",
    "           dropout=dropout,\n",
    "           bidirectional=True,\n",
    "           out_size=out_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用预训练词向量\n",
    "net.embed.weight.data.copy_(pretrained_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二分类的损失函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from train_evaluate_change import Train_Evaluate\n",
    "% run train_evaluate_change.py\n",
    "\n",
    "t_and_v = Train_Evaluate(net, optimizer, criterion, 5, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).to(torch.float32)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  [0    /17500 (0  %)]\tLoss: 0.691380\taccuracy: 0.523438\n",
      "Train Epoch: 0  [6400 /17500 (36 %)]\tLoss: 0.586455\taccuracy: 0.726562\n",
      "Train Epoch: 0  [12800/17500 (73 %)]\tLoss: 0.632992\taccuracy: 0.664062\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1  [0    /17500 (0  %)]\tLoss: 0.509753\taccuracy: 0.781250\n",
      "Train Epoch: 1  [6400 /17500 (36 %)]\tLoss: 0.581940\taccuracy: 0.781250\n",
      "Train Epoch: 1  [12800/17500 (73 %)]\tLoss: 0.424808\taccuracy: 0.812500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 2  [0    /17500 (0  %)]\tLoss: 0.438248\taccuracy: 0.812500\n",
      "Train Epoch: 2  [6400 /17500 (36 %)]\tLoss: 0.346905\taccuracy: 0.867188\n",
      "Train Epoch: 2  [12800/17500 (73 %)]\tLoss: 0.432456\taccuracy: 0.789062\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 3  [0    /17500 (0  %)]\tLoss: 0.302999\taccuracy: 0.882812\n",
      "Train Epoch: 3  [6400 /17500 (36 %)]\tLoss: 0.339026\taccuracy: 0.859375\n",
      "Train Epoch: 3  [12800/17500 (73 %)]\tLoss: 0.342340\taccuracy: 0.867188\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 4  [0    /17500 (0  %)]\tLoss: 0.154728\taccuracy: 0.960938\n",
      "Train Epoch: 4  [6400 /17500 (36 %)]\tLoss: 0.156423\taccuracy: 0.945312\n",
      "Train Epoch: 4  [12800/17500 (73 %)]\tLoss: 0.173267\taccuracy: 0.960938\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train_loss': [0.41986435651779175,\n  0.2845507860183716,\n  0.25453224778175354,\n  0.11173132807016373,\n  0.0711987167596817],\n 'val_loss': [0.45011159777641296,\n  0.36576783657073975,\n  0.390453964471817,\n  0.3022767901420593,\n  0.4003587067127228],\n 'train_accuracy': [0.8184571266174316,\n  0.8875428438186646,\n  0.904285728931427,\n  0.968742847442627,\n  0.9800000190734863],\n 'val_accuracy': [0.8044000267982483,\n  0.8442666530609131,\n  0.8447999954223633,\n  0.8902666568756104,\n  0.8713333606719971]}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = t_and_v.train_eval(train_dataloader, valid_dataloader, verbose=50, metric=accuracy)\n",
    "history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    \"\"\"预测句子的评价\"\"\"\n",
    "    model.eval()\n",
    "    processed_text = torch.tensor(text_transform(sentence)).to(device)\n",
    "    processed_text = processed_text.unsqueeze(1)\n",
    "    length = [len(processed_text)]\n",
    "    prediction = torch.sigmoid(model(processed_text, length))\n",
    "    return prediction.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0.048988379538059235"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, \"fuck, garbage\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0.14703738689422607"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, \"This film is terrible\")  # 越接近与0,越能代表为负面评价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9958744645118713"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, \"This film is great\")  # 越接近与1,越能代表为正面评价\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-spacy_test-py",
   "language": "python",
   "display_name": "Python [conda env:spacy_test] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}