{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 54)\n",
      "(9000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "data = fetch_covtype()\n",
    "\n",
    "X, y = data['data'][:10000], data['target'][:10000]\n",
    "\n",
    "ord = OrdinalEncoder()\n",
    "y_enc = ord.fit_transform(y.reshape(-1, 1))\n",
    "y_enc = y_enc.reshape(-1, )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.1, random_state=1)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset(eff47fde69d1e04cb6dc241bb4c1d9b5)"
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建数据集\n",
    "'''\n",
    "use_cache : bool, default True\n",
    "    If use_cache=True then preprocessing step will be cached until function code is changed.\n",
    "'''\n",
    "dataset = Dataset(X_train=X_train, y_train=y_train, X_test=X_test, y_test=None, use_cache=True)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2167.  129.   26. ...    0.    0.    0.]\n",
      " [2813.  117.   13. ...    0.    0.    0.]\n",
      " [2993.  286.   14. ...    0.    0.    0.]\n",
      " ...\n",
      " [2929.   75.   15. ...    0.    0.    0.]\n",
      " [2208.  317.   33. ...    0.    0.    0.]\n",
      " [2606.  356.   18. ...    0.    0.    0.]]\n",
      "\n",
      "[3. 1. 0. ... 4. 5. 1.]\n",
      "\n",
      "[[2979.   89.   18. ...    0.    0.    0.]\n",
      " [2083.   21.   28. ...    0.    0.    0.]\n",
      " [2322.  281.   17. ...    0.    0.    0.]\n",
      " ...\n",
      " [2306.  224.   25. ...    0.    0.    0.]\n",
      " [3029.  113.   14. ...    0.    0.    0.]\n",
      " [2882.   37.   10. ...    0.    0.    0.]]\n",
      "\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset.X_train, end='\\n\\n')\n",
    "print(dataset.y_train, end='\\n\\n')\n",
    "print(dataset.X_test, end='\\n\\n')\n",
    "print(dataset.y_test, end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "def xgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    \"\"\"参数必须为X_train,y_train,X_test,y_test\"\"\"\n",
    "    params = {'objective': 'multi:softprob',\n",
    "              \"eval_metric\": 'mlogloss',\n",
    "              \"verbosity\": 0,\n",
    "              'num_class': 7,\n",
    "              'nthread': -1}\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=300)\n",
    "    predict = model.predict(dtest)\n",
    "\n",
    "    return predict  # 返回值必须为X_test的预测\n",
    "\n",
    "\n",
    "def lgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    params = {\"objective\": \"multiclass\",\n",
    "              \"num_class\": 7,\n",
    "              \"n_jobs\": -1,\n",
    "              \"verbose\": -4, \"metric\": (\"multi_logloss\",)}\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=300)\n",
    "    predict = model.predict(X_test)\n",
    "\n",
    "    return predict\n",
    "\n",
    "\n",
    "def rf_model(X_train, y_train, X_test, y_test=None):\n",
    "    params = {\"n_estimators\": 100, \"n_jobs\": -1}\n",
    "    model = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "    predict = model.predict_proba(X_test)\n",
    "\n",
    "    return predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "'''\n",
    "name : str, optional\n",
    "    The unique name of Estimator object.\n",
    "\n",
    "use_cache : bool, optional\n",
    "    if True then validate/predict/stack/blend results will be cached.\n",
    "\n",
    "'''\n",
    "model_xgb = Classifier(dataset=dataset, estimator=xgb_model, name='xgb', use_cache=False)\n",
    "model_lgb = Classifier(dataset=dataset, estimator=lgb_model, name='lgb', use_cache=False)\n",
    "model_rf = Classifier(dataset=dataset, estimator=rf_model,\n",
    "                      name='rf',  # 默认parameters=None\n",
    "                      use_cache=False)  # 默认use_cache=True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "outputs": [
    {
     "data": {
      "text/plain": "<heamy.pipeline.ModelsPipeline at 0x23c669e0820>"
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = ModelsPipeline(model_xgb, model_lgb, model_rf)\n",
    "pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [
    {
     "data": {
      "text/plain": "<heamy.pipeline.PipeApply at 0x23c66a33e20>"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies weighted mean to models.\n",
    "pipeline.weight([0.5, 0.3, 0.2])  # 这里指定xgb模型权重0.5,lgb权重为0.3,rf权重为0.2(线性加权)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset(7be1d2d7735f7b716e841f8628b878c8)"
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "k : int, default 5\n",
    "    Number of folds.\n",
    "\n",
    "stratify : bool, default False\n",
    "\n",
    "shuffle : bool, default True\n",
    "\n",
    "seed : int, default 100\n",
    "\n",
    "full_test : bool, default True\n",
    "    If True then evaluate test dataset on the full data otherwise take the mean of every fold.\n",
    "'''\n",
    "stack_ds = pipeline.stack(k=5,\n",
    "                          stratify=False,  # 是否为分层k折\n",
    "                          shuffle=True,\n",
    "                          seed=1,\n",
    "                          full_test=False)\n",
    "stack_ds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             xgb_0         xgb_1         xgb_2         xgb_3         xgb_4  \\\n",
      "0     4.534841e-08  2.541179e-07  2.733032e-03  9.972505e-01  5.520512e-07   \n",
      "1     1.026551e-03  5.745058e-01  6.193155e-05  6.089087e-06  4.243897e-01   \n",
      "2     9.931676e-01  6.827588e-03  6.073082e-08  9.379712e-08  2.986425e-06   \n",
      "3     1.024370e-05  1.215085e-03  2.224298e-06  2.022765e-06  9.987329e-01   \n",
      "4     2.070961e-06  2.478734e-04  4.268239e-05  1.892980e-08  2.222941e-05   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "8995  1.498728e-06  7.729919e-06  9.997123e-01  1.818914e-05  3.111986e-07   \n",
      "8996  2.466629e-03  8.747428e-07  1.366907e-06  9.943136e-08  2.284424e-07   \n",
      "8997  4.480495e-03  2.889213e-01  6.571934e-05  1.598638e-06  7.065006e-01   \n",
      "8998  6.482577e-06  8.352361e-05  3.192859e-01  5.541099e-06  3.409723e-07   \n",
      "8999  4.172878e-04  9.854028e-01  1.783861e-03  1.912048e-06  1.223199e-02   \n",
      "\n",
      "             xgb_5         xgb_6         lgb_0         lgb_1         lgb_2  \\\n",
      "0     1.523519e-05  3.317873e-07  2.948738e-10  2.393523e-09  1.306743e-05   \n",
      "1     2.771559e-06  7.163896e-06  1.031326e-03  3.418498e-01  8.436671e-07   \n",
      "2     1.725809e-07  1.553244e-06  9.997157e-01  2.832818e-04  1.757258e-09   \n",
      "3     3.500483e-05  2.496738e-06  8.328621e-08  6.372429e-05  3.064596e-09   \n",
      "4     9.996850e-01  6.317720e-08  8.054011e-06  9.340819e-04  2.180221e-05   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "8995  2.597058e-04  2.188967e-07  2.071008e-08  1.433841e-07  9.999876e-01   \n",
      "8996  3.413513e-06  9.975274e-01  1.022808e-04  1.213109e-09  8.477269e-09   \n",
      "8997  4.880789e-06  2.533228e-05  5.982391e-04  1.041582e-01  5.031231e-08   \n",
      "8998  6.805968e-01  2.132009e-05  1.093692e-06  2.759543e-05  1.746375e-01   \n",
      "8999  1.520641e-04  1.003229e-05  2.147179e-04  9.994839e-01  2.836797e-05   \n",
      "\n",
      "      ...         lgb_4         lgb_5         lgb_6  rf_0  rf_1  rf_2  rf_3  \\\n",
      "0     ...  2.585061e-10  9.617795e-08  9.365659e-11  0.00  0.00  0.01  0.99   \n",
      "1     ...  6.571168e-01  1.157059e-06  1.693615e-08  0.13  0.44  0.00  0.00   \n",
      "2     ...  9.633757e-07  1.990608e-09  8.793855e-09  0.58  0.20  0.00  0.00   \n",
      "3     ...  9.999361e-01  4.413642e-08  4.536169e-11  0.00  0.00  0.00  0.00   \n",
      "4     ...  1.264324e-04  9.989096e-01  3.544767e-10  0.05  0.07  0.06  0.00   \n",
      "...   ...           ...           ...           ...   ...   ...   ...   ...   \n",
      "8995  ...  2.399200e-10  1.188213e-05  3.038512e-11  0.00  0.00  0.84  0.03   \n",
      "8996  ...  1.581365e-09  1.050151e-07  9.998976e-01  0.03  0.00  0.00  0.00   \n",
      "8997  ...  8.952435e-01  2.654109e-08  2.518098e-09  0.14  0.58  0.01  0.00   \n",
      "8998  ...  8.177757e-08  8.253336e-01  2.274948e-08  0.00  0.00  0.48  0.00   \n",
      "8999  ...  1.755359e-04  9.748730e-05  1.099679e-09  0.09  0.78  0.01  0.00   \n",
      "\n",
      "      rf_4  rf_5  rf_6  \n",
      "0     0.00  0.00  0.00  \n",
      "1     0.42  0.01  0.00  \n",
      "2     0.10  0.00  0.12  \n",
      "3     1.00  0.00  0.00  \n",
      "4     0.08  0.74  0.00  \n",
      "...    ...   ...   ...  \n",
      "8995  0.00  0.13  0.00  \n",
      "8996  0.00  0.00  0.97  \n",
      "8997  0.27  0.00  0.00  \n",
      "8998  0.00  0.52  0.00  \n",
      "8999  0.09  0.03  0.00  \n",
      "\n",
      "[9000 rows x 21 columns]\n",
      "[3. 1. 0. ... 4. 5. 1.]\n",
      "            xgb_0     xgb_1         xgb_2         xgb_3         xgb_4  \\\n",
      "0    8.131402e-01  0.186717  8.656114e-06  1.311125e-05  4.694143e-05   \n",
      "1    4.976726e-06  0.001448  2.397805e-01  1.328249e-05  1.544654e-06   \n",
      "2    3.379331e-06  0.000006  2.938978e-04  9.287729e-04  2.148000e-05   \n",
      "3    1.037145e-02  0.000046  3.112013e-07  4.553492e-07  2.564838e-07   \n",
      "4    2.181071e-07  0.000002  7.791304e-04  9.991627e-01  1.831632e-05   \n",
      "..            ...       ...           ...           ...           ...   \n",
      "995  4.977564e-02  0.006236  1.543476e-04  4.074186e-06  1.623728e-05   \n",
      "996  8.161975e-04  0.014963  1.404793e-03  3.925740e-05  9.823974e-01   \n",
      "997  1.373955e-05  0.000444  7.141369e-01  2.380274e-01  7.023184e-06   \n",
      "998  1.182706e-01  0.880993  1.057344e-04  3.358099e-05  2.914155e-05   \n",
      "999  3.397970e-01  0.621999  5.494626e-05  3.789779e-05  3.810450e-02   \n",
      "\n",
      "            xgb_5         xgb_6         lgb_0         lgb_1         lgb_2  \\\n",
      "0    2.258938e-05  5.158303e-05  6.793326e-01  3.206142e-01  8.976305e-07   \n",
      "1    7.587358e-01  1.555999e-05  5.330249e-07  3.127667e-03  2.471813e-01   \n",
      "2    9.987456e-01  5.056456e-07  3.502078e-07  2.790583e-06  1.512028e-04   \n",
      "3    1.548684e-07  9.895816e-01  2.184471e-03  2.945862e-07  5.022028e-11   \n",
      "4    3.705848e-05  5.048751e-07  6.331697e-10  2.353739e-08  1.858618e-05   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "995  1.812329e-06  9.438123e-01  1.685392e-03  2.121832e-04  4.413776e-08   \n",
      "996  3.107066e-04  6.863884e-05  1.919656e-04  4.189111e-03  1.316186e-04   \n",
      "997  4.736711e-02  4.135077e-06  4.233668e-06  1.456287e-04  8.666346e-01   \n",
      "998  2.421723e-05  5.439048e-04  6.575667e-02  9.342311e-01  1.623353e-06   \n",
      "999  2.714654e-06  4.100544e-06  2.221416e-01  7.692582e-01  4.453007e-07   \n",
      "\n",
      "     ...         lgb_4         lgb_5         lgb_6   rf_0   rf_1   rf_2  \\\n",
      "0    ...  4.586979e-05  5.253863e-06  1.066365e-06  0.394  0.368  0.014   \n",
      "1    ...  9.312075e-08  7.496903e-01  1.400495e-08  0.000  0.014  0.316   \n",
      "2    ...  2.151144e-07  9.997792e-01  9.454383e-10  0.000  0.000  0.086   \n",
      "3    ...  1.408569e-10  5.376641e-11  9.978152e-01  0.170  0.024  0.000   \n",
      "4    ...  2.206449e-09  2.466963e-07  1.125244e-10  0.000  0.000  0.038   \n",
      "..   ...           ...           ...           ...    ...    ...    ...   \n",
      "995  ...  7.820248e-09  7.597262e-10  9.981024e-01  0.166  0.046  0.000   \n",
      "996  ...  9.954639e-01  2.310140e-05  2.772402e-08  0.076  0.106  0.074   \n",
      "997  ...  8.199096e-07  5.385289e-02  7.729523e-09  0.000  0.002  0.304   \n",
      "998  ...  4.755855e-06  8.631815e-07  4.834077e-06  0.290  0.642  0.000   \n",
      "999  ...  8.599377e-03  7.574753e-08  3.929602e-10  0.268  0.346  0.002   \n",
      "\n",
      "      rf_3   rf_4   rf_5   rf_6  \n",
      "0    0.000  0.130  0.018  0.076  \n",
      "1    0.004  0.000  0.666  0.000  \n",
      "2    0.062  0.002  0.850  0.000  \n",
      "3    0.000  0.000  0.000  0.806  \n",
      "4    0.958  0.000  0.004  0.000  \n",
      "..     ...    ...    ...    ...  \n",
      "995  0.000  0.004  0.000  0.784  \n",
      "996  0.002  0.668  0.060  0.014  \n",
      "997  0.532  0.000  0.162  0.000  \n",
      "998  0.000  0.032  0.000  0.036  \n",
      "999  0.000  0.382  0.000  0.002  \n",
      "\n",
      "[1000 rows x 21 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 第一层模型训练第二层模型的输出;这里xgb模型输出为概率,故有xgb_0, xgb_1,...,xgb_6\n",
    "print(stack_ds.X_train)\n",
    "print(stack_ds.y_train)\n",
    "print(stack_ds.X_test)  # 第一层模型测试第二层模型的输出\n",
    "print(stack_ds.y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6.29203235e-01, 3.48298112e-01, 1.01394789e-03, ...,\n        4.25259346e-03, 1.29883381e-03, 1.52996377e-02],\n       [1.50250570e-03, 1.00879343e-02, 1.63825755e-01, ...,\n        3.99544855e-03, 8.13759417e-01, 5.57208616e-04],\n       [8.35311190e-04, 4.18506185e-03, 2.75112334e-02, ...,\n        1.85843757e-03, 9.62402882e-01, 2.45975115e-04],\n       ...,\n       [2.49040372e-03, 1.23287821e-02, 7.09353513e-01, ...,\n        7.49429720e-03, 1.15042186e-01, 1.49341473e-03],\n       [1.69065534e-01, 8.17630553e-01, 1.21458050e-03, ...,\n        7.39291524e-03, 1.95500961e-03, 2.37682449e-03],\n       [3.42020909e-01, 5.97225486e-01, 2.07764400e-03, ...,\n        4.85210971e-02, 2.64880921e-03, 6.78472189e-03]])"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker = Classifier(dataset=stack_ds, estimator=LogisticRegression, parameters={\"solver\": 'lbfgs', \"max_iter\": 1000},\n",
    "                     use_cache=False)\n",
    "# stack_ds.X_test的预测结果\n",
    "predict_stack = stacker.predict()\n",
    "predict_stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858\n",
      "0.865\n",
      "0.859\n",
      "0.868\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(np.argmax(stack_ds.X_test.iloc[:, :7].values, axis=1), y_test))\n",
    "print(accuracy_score(np.argmax(stack_ds.X_test.iloc[:, 7:14].values, axis=1), y_test))\n",
    "print(accuracy_score(np.argmax(stack_ds.X_test.iloc[:, 14:].values, axis=1), y_test))\n",
    "\n",
    "# 通过stacking模型融合,准确率得到了提升\n",
    "print(accuracy_score(np.argmax(predict_stack, axis=1), y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}