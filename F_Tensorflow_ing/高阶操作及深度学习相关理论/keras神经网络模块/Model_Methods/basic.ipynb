{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 54) (4500,)\n",
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "X = datasets.fetch_covtype().data[:5000]\n",
    "y = datasets.fetch_covtype().target[:5000]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "y_train = enc.fit_transform(y_train.reshape(-1, 1)).reshape(-1, )\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).reshape(-1, )\n",
    "print(np.unique(y_train))  # 7分类任务\n",
    "\n",
    "X_train, X_test, y_train, y_test = tf.constant(X_train), tf.constant(X_test), tf.constant(y_train), tf.constant(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_84 (InputLayer)       [(None, 54)]              0         \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 256)               14080     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,391\n",
      "Trainable params: 64,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(54,))\n",
    "x = tf.keras.layers.Dense(256, activation='tanh')(inputs)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "predictions = tf.keras.layers.Dense(7)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [],
   "source": [
    "# Configures the model for training.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # 优化器\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # 损失函数\n",
    "              metrics=['accuracy'])  # 评估函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 - 1s - loss: 1.4301 - accuracy: 0.4562 - val_loss: 1.1324 - val_accuracy: 0.5380 - 536ms/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "71/71 - 0s - loss: 1.2301 - accuracy: 0.5084 - val_loss: 1.0904 - val_accuracy: 0.5760 - 215ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "71/71 - 0s - loss: 1.2015 - accuracy: 0.5176 - val_loss: 1.0643 - val_accuracy: 0.5720 - 206ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "71/71 - 0s - loss: 1.1602 - accuracy: 0.5242 - val_loss: 1.0790 - val_accuracy: 0.5500 - 224ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "71/71 - 0s - loss: 1.1495 - accuracy: 0.5287 - val_loss: 1.0505 - val_accuracy: 0.5680 - 201ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "71/71 - 0s - loss: 1.1336 - accuracy: 0.5329 - val_loss: 1.0041 - val_accuracy: 0.5800 - 177ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "71/71 - 0s - loss: 1.1211 - accuracy: 0.5436 - val_loss: 0.9953 - val_accuracy: 0.6040 - 189ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "71/71 - 0s - loss: 1.1109 - accuracy: 0.5482 - val_loss: 0.9257 - val_accuracy: 0.6160 - 209ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "71/71 - 0s - loss: 1.0894 - accuracy: 0.5542 - val_loss: 0.9553 - val_accuracy: 0.5880 - 203ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "71/71 - 0s - loss: 1.0485 - accuracy: 0.5678 - val_loss: 0.9256 - val_accuracy: 0.6340 - 182ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2992912df40>"
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "model.fit(X_train,  # Input data\n",
    "          y_train,  # Target data\n",
    "          # x是生成器或 tf.data.Dataset 的对象时,将忽略此参数\n",
    "          # Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). This argument is ignored when x is a generator or an object of tf.data.\n",
    "          shuffle=True,\n",
    "          # Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32.\n",
    "          batch_size=64,\n",
    "          epochs=10,  # Integer. Number of epochs to train the model.\n",
    "          # 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases\n",
    "          verbose=2,\n",
    "          # Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.\n",
    "          validation_data=(X_test, y_test),\n",
    "          # Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "          # validation_split=0.2 # 验证数据集占训练数据集的比例,取值范围为0~1\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9256449341773987\n",
      "test acc: 0.6340000033378601\n"
     ]
    }
   ],
   "source": [
    "# Returns the loss value & metrics values for the model in test mode.\n",
    "'''\n",
    "batch_size:Integer or None. Number of samples per batch of computation. If unspecified, batch_size will default to 32. Do not specify the batch_size if your data is in the form of a dataset, generators, or keras.utils.Sequence instances (since they generate batches).\n",
    "verbose:0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
    "'''\n",
    "loss, metric = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "\n",
    "print(\"test loss:\", loss)\n",
    "print(\"test acc:\", metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029929482700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "predictions shape: [[-2.861379   -0.84848404  2.4295695   3.3494418   1.1932477   1.0286329\n",
      "  -6.627928  ]\n",
      " [-1.6492828   0.33578384  2.1444478   0.30763477  0.11676084  1.9300216\n",
      "  -3.9182441 ]\n",
      " [ 0.862491    2.995561   -0.3893175  -2.5053957   3.033133    0.41988632\n",
      "  -3.0754466 ]\n",
      " [ 0.03761072  1.6790218  -1.1376354   1.8506185   0.19919974 -1.1811516\n",
      "  -3.1601036 ]\n",
      " [ 0.18730937  2.4615493  -0.07888934 -1.4982382   2.7107925   0.52728105\n",
      "  -3.5910306 ]\n",
      " [ 5.936987    6.0237923  -3.901294   -5.122726    3.5687194  -2.9142792\n",
      "   1.9628466 ]\n",
      " [-1.3649368  -0.18735461 -0.6049171   2.570648   -0.259143    0.17863344\n",
      "  -2.4850726 ]\n",
      " [-0.26244146  2.3950436   1.2656142  -1.9224949   2.100164    1.8372741\n",
      "  -3.942083  ]\n",
      " [-1.050584    1.3406141   0.8805519   3.0829873  -0.3326287   0.16411455\n",
      "  -5.621588  ]\n",
      " [-0.3388325   0.4021878  -0.40360144  1.2024801   1.0382622  -0.08057243\n",
      "  -2.1980808 ]]\n"
     ]
    }
   ],
   "source": [
    "# Generates output predictions for the input samples.\n",
    "'''\n",
    "batch_size:Integer or None. Number of samples per batch. If unspecified, batch_size will default to 32. Do not specify the batch_size if your data is in the form of dataset, generators, or keras.utils.Sequence instances (since they generate batches).\n",
    "verbose:Verbosity mode, 0 or 1.\n",
    "'''\n",
    "predictions = model.predict(X_test[:10],  # 预测10条样本\n",
    "                            batch_size=32, verbose=0)\n",
    "print('predictions shape:', predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}