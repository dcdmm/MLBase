{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "解析:\n",
    "\n",
    "$ z = [x_0^2, x_1^2, x_2^2] $\n",
    "\n",
    "$ \\frac{\\partial z}{ \\partial x_0} = \\lambda_0 * (\\frac{\\partial z_0}{\\partial x_0}) + \\lambda_1 * (\\frac{\\partial z_1}{\\partial x_0})   + \\lambda_2 * (\\frac{\\partial z_2}{\\partial x_0})$\n",
    "\n",
    "$ \\frac{\\partial z}{ \\partial x_1} = \\lambda_0 * (\\frac{\\partial z_0}{\\partial x_1}) + \\lambda_1 * (\\frac{\\partial z_1}{\\partial x_1})   + \\lambda_2 * (\\frac{\\partial z_2}{\\partial x_1})$\n",
    "\n",
    "$ \\frac{\\partial z}{ \\partial x_2} = \\lambda_0 * (\\frac{\\partial z_0}{\\partial x_2}) + \\lambda_1 * (\\frac{\\partial z_1}{\\partial x_2})   + \\lambda_2 * (\\frac{\\partial z_2}{\\partial x_2})$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 9.], grad_fn=<PowBackward0>)\n",
      "tensor([ 0.2000,  4.0000, 60.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3],\n",
    "                  requires_grad=True,\n",
    "                  dtype=torch.float32) # x为向量\n",
    "\n",
    "\n",
    "z = x ** 2\n",
    "v = torch.tensor([0.1, 1, 10], dtype=torch.float) # 权重向量(与z同形)\n",
    "print(z)\n",
    "z.backward(v)\n",
    "print(x.grad) # 与x同型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解析:\n",
    "$z = $\n",
    "\\begin{pmatrix}\n",
    "A[0][0]*vec[0] + A[0][1]*vec[1] + A[0][2]*vec[2] \\\\\n",
    "A[1][0]*vec[0] + A[1][1]*vec[1] + A[1][2]*vec[2]  \\\\\n",
    "A[2][0]*vec[0] + A[2][1]*vec[1] + A[2][2]*vec[2]  \n",
    "\\end{pmatrix}\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial vec[0]}  = \\lambda_0 * \\frac{\\partial z[0]}{\\partial vec[0]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial vec[0]} + \\lambda_2 * \\frac{\\partial z[2]}{\\partial vec[0]} $\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial vec[1]}  = \\lambda_0 * \\frac{\\partial z[0]}{\\partial vec[1]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial vec[1]} + \\lambda_2 * \\frac{\\partial z[2]}{\\partial vec[1]} $\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial vec[2]}  = \\lambda_0 * \\frac{\\partial z[0]}{\\partial vec[2]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial vec[2]} + \\lambda_3 * \\frac{\\partial z[2]}{\\partial vec[2]} $"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[49.],\n        [59.],\n        [69.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1., 2., 3.],\n",
    "                  [4., 5., 6.],\n",
    "                  [7., 8., 9.]], requires_grad=True)\n",
    "vec = torch.tensor([[1.],\n",
    "                    [2.],\n",
    "                    [3.]], requires_grad=True)\n",
    "\n",
    "r_vec = A @ vec\n",
    "r_vec.backward(gradient=torch.tensor([[2.],\n",
    "                                      [3.],\n",
    "                                      [5]])) # 权值向量(与r_vec同型)\n",
    "vec.grad # 与vec同型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解析\n",
    "$z = $\n",
    "\\begin{pmatrix}\n",
    "A[0][0]*vec[0] + A[0][1]*vec[1] + A[0][2]*vec[2] \\\\\n",
    "A[1][0]*vec[0] + A[1][1]*vec[1] + A[1][2]*vec[2]  \\\\\n",
    "A[2][0]*vec[0] + A[2][1]*vec[1] + A[2][2]*vec[2]  \n",
    "\\end{pmatrix}\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial A[0][0]}  = \\lambda_0 * \\frac{\\partial z[0]}{\\partial A[0][0]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial A[0][0]} + \\lambda_2 * \\frac{\\partial z[2]}{\\partial A[0][0]} $\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial A[0][1]}  = \\lambda_0 * \\frac{\\partial z[0]}{\\partial A[0][1]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial A[0][1]} + \\lambda_2 * \\frac{\\partial z[2]}{\\partial A[0][1]} $\n",
    "\n",
    "$ \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad  \\vdots $\n",
    "\n",
    "$ \\frac{\\partial z}{\\partial A[2][2]}  = \\lambda_0 * \\frac{\\partial z[1]}{\\partial A[2][2]} + \\lambda_1 * \\frac{\\partial z[1]}{\\partial A[2][2]} + \\lambda_2 * \\frac{\\partial z[2]}{\\partial A[2][2]} $\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.,  4.,  6.],\n        [ 3.,  6.,  9.],\n        [ 5., 10., 15.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.grad # 与A同型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}