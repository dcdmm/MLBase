{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 基础概念\n",
    "&emsp;&emsp;超参数(参数的参数,每次改变超参数,模型都要重新训练)是在模型训练之前设置值的参数,其值不能通过训练过程得到.通常情况下,在模型训练过程中需要对\n",
    "超参数进行优化,给训练器(模型)选择一组最优的超参数,以提高训练器的性能和效果.比如,树的数量或树的深度,学习率(多种模式),以及k均值\n",
    "聚类中的簇数等都是超参数.   \n",
    "&emsp;&emsp;与超参数区别的概念是参数,参数的值通过训练器学习得出,比如回归系数,神经网络权重等.\n",
    "常见的超参数搜索算法:   \n",
    "1. 网格搜索\n",
    "2. 随机搜索\n",
    "3. 贝叶斯搜索\n",
    "\n",
    "\n",
    "## 网格搜索\n",
    "* 网格搜索通过穷举法列出不同的超参数组合(某组超参数值域的笛卡尔集为一组超参数网格),搜索算法使用不同的超参数组合训练模型并挑选验证误差最小的超参数组合(暴力搜索)\n",
    "* 为了评价每次挑选的超参数组合的好坏,需要选择合适评价指标,评价指标可以根据自己的需要选择accuracy、f1-score、f-beta、percision、recall等\n",
    "* 为了避免数据的划分对评价结果产生影响,需要采用k折交叉验证的方式来减少偶然性造成的误差\n",
    "\n",
    "\n",
    "## 随机搜索\n",
    "\n",
    "1. 对于搜索范围是distribution的超参数,根据给定的distribution随机采样\n",
    "\n",
    "2. 对于搜索范围是array_like的超参数,在给定的array_like中等概率采样\n",
    "\n",
    "3. 对a、b两步中得到的n_iter组采样结果,进行遍历\n",
    "    * 如果给定的搜索范围均为array_like,则不放回抽样n_iter次\n",
    "\n",
    "#### 随机搜索有效性解释\n",
    "\n",
    "<img src=\"../../../Other/img/随机搜索.jpg\" style=\"width:500px;height:300px;float:bottom\">\n",
    "\n",
    "* 目标函数为$f(x,y)=g(x)+h(y)$,其中绿色为$g(x)$,黄色为$h(y)$,目标是求$f$的最大值\n",
    "\n",
    "* 其中由于$g(x)$数值上要明显大于$h(y)$,因此有$f(x,y)=g(x)+h(y)≈g(x)$,也就是说在整体求解$f(x,y)$最大值的过程中,$g(x)$的影响明显大于$h(y)$\n",
    "\n",
    "* 两个图都进行9次实验(搜索),可以看到左图实际探索了各三个点(在横轴和纵轴上的投影均为3个),而右图随机探索了9个不同的点\n",
    "\n",
    "* 可以看出,右图更可能找到目标函数的最大值\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}