{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "import torch.utils.data as Data\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since dair-ai/emotion couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'split' at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\dair-ai___emotion\\split\\0.0.0\\cab853a1dbdf4c42c2b3ef2173804746df8825fe (last modified on Wed Jun 18 11:28:24 2025).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'i am feeling grouchy',\n",
       "  'ive been feeling a little burdened lately wasnt sure why that was',\n",
       "  'ive been taking or milligrams or times recommended amount and ive fallen asleep a lot faster but i also feel like so funny',\n",
       "  'i feel as confused about life as a teenager or as jaded as a year old man',\n",
       "  'i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
       "  'i feel romantic too'],\n",
       " 'label': [0, 0, 3, 2, 3, 0, 5, 4, 1, 2]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(path='dair-ai/emotion')['train']\n",
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('E:\\huggingface_models\\Qwen3-0.6B')\n",
    "train_dataset = train_dataset.map(lambda samples: tokenizer(samples[\"text\"], padding=True), batched=True, batch_size=batch_size)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset.select(range(0, 10)):\n",
    "    print(len(i['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask', 'xx', 'yy'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_data = [str(i) for i in range(16000)]\n",
    "train_dataset = train_dataset.add_column(\"xx\", add_data)  # 非数值类型列\n",
    "yy_list = []\n",
    "for i in range(0, len(train_dataset)):\n",
    "    if i % batch_size == 0:\n",
    "        length = random.randint(32, 64)\n",
    "    yy_list.append(list(range(0, length)))\n",
    "train_dataset = train_dataset.add_column(\"yy\", yy_list)  # 数值类型列\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'attention_mask', 'yy'])\n",
      "labels:  tensor([0, 0, 3, 2])\n",
      "yy:  torch.Size([4, 57])\n",
      "labels.shape:  torch.Size([4])\n",
      "input_ids.shape:  torch.Size([4, 21])\n",
      "attention_mask.shape:  torch.Size([4, 21])\n"
     ]
    }
   ],
   "source": [
    "dac = Data.DataLoader(train_dataset, \n",
    "                      # 保留所有数值类型字段\n",
    "                      # labal/labels字段(如果有)必须为数值类型\n",
    "                      # 每个batch_size的数据必须可以转换为一个tensor\n",
    "                      collate_fn=default_data_collator, \n",
    "                      batch_size=batch_size)\n",
    "\n",
    "for i in dac:\n",
    "    print(i.keys())\n",
    "    print(\"labels: \", i['labels'])\n",
    "    print(\"yy: \", i['yy'].shape)\n",
    "    print(\"labels.shape: \", i['labels'].shape)\n",
    "    print(\"input_ids.shape: \", i['input_ids'].shape)\n",
    "    print(\"attention_mask.shape: \", i['attention_mask'].shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
