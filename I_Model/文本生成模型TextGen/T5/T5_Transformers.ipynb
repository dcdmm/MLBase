{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5Model, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "model = T5Model.from_pretrained(\"t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\"Studies have been shown that owning a dog is good for you\",\n",
    "                      return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "# This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)   # Teacher Forcing\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "# Sequence of hidden-states at the output of the last layer of the decoder of the model.\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states.shape)  # [batch_size, sequence_length, hidden_size]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7837, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([1, 7, 32128])\n"
     ]
    }
   ],
   "source": [
    "model_cg = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# training\n",
    "input_ids = tokenizer(\"The <extra_id_0> walks in <extra_id_1> park\", return_tensors=\"pt\").input_ids\n",
    "labels = tokenizer(\"<extra_id_0> cute dog <extra_id_1> the <extra_id_2>\", return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model_cg(input_ids=input_ids, labels=labels)\n",
    "loss = outputs.loss  # Language modeling loss.\n",
    "# Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "logits = outputs.logits\n",
    "print(loss)\n",
    "print(logits.shape)  # batch_size, sequence_length, config.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0, 2116,   43, 2008,   24,  293,   53,    3,    9, 1782,   19,  207,\n",
      "           21,   25,    3,    5,    1]])\n",
      "studies have shown that owning a dog is good for you.\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "input_ids = tokenizer(\"summarize: studies have shown that owning a dog is good for you\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "outputs = model_cg.generate(input_ids)\n",
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# studies have shown that owning a dog is good for you."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}