{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torchtext\\data\\example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "TEXT = data.Field(sequential=True, lower=True)\n",
    "\n",
    "train, val = data.TabularDataset.splits(path='test_text', train='train.csv', validation='val.csv',\n",
    "                                        format='csv', skip_header=True,\n",
    "                                        fields=[('PhraseId', None), ('SentenceId', None),\n",
    "                                                ('Phrase', TEXT), ('Sentiment', LABEL)])\n",
    "\n",
    "TEXT.build_vocab(train, vectors='glove.6B.100d', vectors_cache='vector_cache/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  ★★★★★Iterator输出的<font color='red'>所有</font>设置方法(<font color='red'>根据需求合理选择其中某一个</font>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "\n",
      "\n",
      "[torchtext.data.batch.Batch of size 12]\n",
      "\t[.Phrase]:[torch.LongTensor of size 1x12]\n",
      "\t[.Sentiment]:[torch.LongTensor of size 12]\n",
      "\n",
      "tensor([[13658,  1854,   640, 12904, 13753, 14087, 11736, 14194, 12555, 13138,\n",
      "         12541,     1]])\n",
      "\n",
      "torch.Size([1, 12])\n",
      "\n",
      "tensor([2, 2, 3, 2, 2, 2, 2, 3, 1, 3, 2, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: Iterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# 设置方法一:(全部)根据sort_key进行排序后输出\n",
    "train_iterator_sort = data.Iterator(dataset=train, device=device, batch_size=12,\n",
    "                                    sort=True, # Whether to sort examples according to self.sort_key\n",
    "                                    #  A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. The sort_key provided to the Iterator constructor overrides the sort_key attribute of the Dataset, or defers to it if None.\n",
    "                                    sort_key=lambda x: len(x.Phrase))\n",
    "'''\n",
    "self.sort_within_batch/self.sort_key/self.sort三者之间的区别\n",
    "if sort_within_batch is None:\n",
    "    self.sort_within_batch = self.sort\n",
    "else:\n",
    "    self.sort_within_batch = sort_within_batch\n",
    "if sort_key is None:\n",
    "    self.sort_key = dataset.sort_key\n",
    "else:\n",
    "    self.sort_key = sort_key\n",
    "'''\n",
    "\n",
    "\n",
    "for batch in train_iterator_sort:\n",
    "    print(type(batch), end='\\n\\n')\n",
    "    print(batch, end='\\n\\n')\n",
    "    print(batch.Phrase, end='\\n\\n')\n",
    "    print(batch.Phrase.shape, end='\\n\\n')\n",
    "    print(batch.Sentiment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "\n",
      "\n",
      "[torchtext.data.batch.Batch of size 12]\n",
      "\t[.Phrase]:[torch.LongTensor of size 17x12]\n",
      "\t[.Sentiment]:[torch.LongTensor of size 12]\n",
      "\n",
      "tensor([[    2,   666,   142,   177,    13,    90,   271, 12541,   121,     4,\n",
      "            11,     4],\n",
      "        [ 1685, 11049,    10,   554,     9,     7,    76,     1,    23,  1120,\n",
      "             2, 16459],\n",
      "        [  537, 15341,  2464,    43, 13876,   116,     1,     1,    21,   681,\n",
      "            32,  1289],\n",
      "        [    5,     1,     8,  6316,   227,     1,     1,     1,    54,     1,\n",
      "           388,     1],\n",
      "        [ 4198,     1,     1,  2164,    50,     1,     1,     1,     1,     1,\n",
      "             6,     1],\n",
      "        [    6,     1,     1,     1,     2,     1,     1,     1,     1,     1,\n",
      "         11439,     1],\n",
      "        [12652,     1,     1,     1,   268,     1,     1,     1,     1,     1,\n",
      "           146,     1],\n",
      "        [  479,     1,     1,     1,    18,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [15589,     1,     1,     1,  3295,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    2,     1,     1,     1,     8,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [13247,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [ 1305,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   28,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [  113,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [ 4308,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    6,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]])\n",
      "\n",
      "torch.Size([17, 12])\n",
      "\n",
      "tensor([1, 2, 3, 3, 4, 2, 3, 2, 3, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 设置方法二:按照原有顺序输出\n",
    "train_iterator_no_shuff = data.Iterator(dataset=train, device=device, batch_size=12,\n",
    "                                        shuffle=False)\n",
    "for batch in train_iterator_no_shuff:\n",
    "    print(type(batch), end='\\n\\n')\n",
    "    print(batch, end='\\n\\n')\n",
    "    print(batch.Phrase, end='\\n\\n')\n",
    "    print(batch.Phrase.shape, end='\\n\\n')\n",
    "    print(batch.Sentiment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "\n",
      "\n",
      "[torchtext.data.batch.Batch of size 12]\n",
      "\t[.Phrase]:[torch.LongTensor of size 19x12]\n",
      "\t[.Sentiment]:[torch.LongTensor of size 12]\n",
      "\n",
      "tensor([[  180,    50,     2,     2,    11,     4,     7,     5,    19,    49,\n",
      "            41,    85],\n",
      "        [ 1246,   100,   145,   120,    21,    62,  2487,     2,  2122,     5,\n",
      "            24,    72],\n",
      "        [    1,    27,    11, 13184,   117,   128,    47,   106,   127,  3379,\n",
      "           211,  2270],\n",
      "        [    1,  8437, 14618,   227,   419,   235,    71,     1,    60,     9,\n",
      "           186,    19],\n",
      "        [    1,    34,  2923,    47,    16,    37,    54,     1,    58,   117,\n",
      "             4,   185],\n",
      "        [    1,  2243,     1,    10,   122,    27,   307,     1,  2577,     1,\n",
      "            20,   518],\n",
      "        [    1,     1,     1,  1610,     1,  1259,    22,     1,  1663,     1,\n",
      "           383,     1],\n",
      "        [    1,     1,     1,  2138,     1,     3,    33,     1,    11,     1,\n",
      "             5,     1],\n",
      "        [    1,     1,     1,  1342,     1,    27,    92,     1,    26,     1,\n",
      "            19,     1],\n",
      "        [    1,     1,     1,     1,     1,   199,     7,     1,     3,     1,\n",
      "          1547,     1],\n",
      "        [    1,     1,     1,     1,     1,     6,    82,     1,  1287,     1,\n",
      "          2204,     1],\n",
      "        [    1,     1,     1,     1,     1,    27,    21,     1,     3,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,   632,   328,     1,    11,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,    37,  1707,     1,   185,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,    34,   641,     1,     8,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,    17,  4612,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,  3000,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,  1842,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,   338,     1,     1,     1,     1,\n",
      "             1,     1]])\n",
      "\n",
      "torch.Size([19, 12])\n",
      "\n",
      "tensor([3, 1, 3, 1, 2, 4, 1, 2, 2, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 设置方法二:完全随机输出\n",
    "train_iterator_shuff = data.Iterator(dataset=train, device=device, batch_size=12,\n",
    "                                     shuffle=True)\n",
    "for batch in train_iterator_shuff:\n",
    "    print(type(batch), end='\\n\\n')\n",
    "    print(batch, end='\\n\\n')\n",
    "    print(batch.Phrase, end='\\n\\n')\n",
    "    print(batch.Phrase.shape, end='\\n\\n')\n",
    "    print(batch.Sentiment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.batch.Batch'>\n",
      "\n",
      "\n",
      "[torchtext.data.batch.Batch of size 12]\n",
      "\t[.Phrase]:[torch.LongTensor of size 19x12]\n",
      "\t[.Sentiment]:[torch.LongTensor of size 12]\n",
      "\n",
      "tensor([[    4,     7,    19,    41,     2,    50,    11,    85,     2,    49,\n",
      "             5,   180],\n",
      "        [   62,  2487,  2122,    24,   120,   100,    21,    72,   145,     5,\n",
      "             2,  1246],\n",
      "        [  128,    47,   127,   211, 13184,    27,   117,  2270,    11,  3379,\n",
      "           106,     1],\n",
      "        [  235,    71,    60,   186,   227,  8437,   419,    19, 14618,     9,\n",
      "             1,     1],\n",
      "        [   37,    54,    58,     4,    47,    34,    16,   185,  2923,   117,\n",
      "             1,     1],\n",
      "        [   27,   307,  2577,    20,    10,  2243,   122,   518,     1,     1,\n",
      "             1,     1],\n",
      "        [ 1259,    22,  1663,   383,  1610,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    3,    33,    11,     5,  2138,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   27,    92,    26,    19,  1342,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [  199,     7,     3,  1547,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    6,    82,  1287,  2204,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   27,    21,     3,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [  632,   328,    11,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   37,  1707,   185,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   34,   641,     8,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [   17,  4612,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [ 3000,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [ 1842,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [  338,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]])\n",
      "\n",
      "torch.Size([19, 12])\n",
      "\n",
      "tensor([4, 1, 2, 3, 1, 1, 2, 4, 3, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 设置方法三:对随机选择的每个batch内的数据根据sort_key进行排序后输出\n",
    "train_iterator_com = data.Iterator(dataset=train, device=device, batch_size=12,\n",
    "                                   shuffle=True,\n",
    "                                   sort_key=lambda x: len(x.Phrase),\n",
    "                                   sort_within_batch=True) # Whether to sort (in descending order according to self.sort_key) within each batch\n",
    "for batch in train_iterator_com:\n",
    "    print(type(batch), end='\\n\\n')\n",
    "    print(batch, end='\\n\\n')\n",
    "    print(batch.Phrase, end='\\n\\n')\n",
    "    print(batch.Phrase.shape, end='\\n\\n')\n",
    "    print(batch.Sentiment)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}