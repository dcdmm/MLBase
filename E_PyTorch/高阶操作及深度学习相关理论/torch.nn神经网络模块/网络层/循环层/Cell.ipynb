{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "tensor([[ 0.2308, -0.0559, -0.4646,  0.2800, -0.2547,  0.2419, -0.3084,  0.0310,\n",
      "          0.1770, -0.2312,  0.2936, -0.5103,  0.4401,  0.4752, -0.7395,  0.1788,\n",
      "          0.3818,  0.5918,  0.1369,  0.1747],\n",
      "        [ 0.5410,  0.4939, -0.5544,  0.3502,  0.5437,  0.0473,  0.2441, -0.4738,\n",
      "          0.0407, -0.4108, -0.2749, -0.5996,  0.4776,  0.1159, -0.5173, -0.2493,\n",
      "         -0.3762,  0.2695,  0.2138,  0.2232],\n",
      "        [ 0.7325,  0.0562,  0.0716,  0.3966, -0.6194, -0.2798, -0.3374, -0.2798,\n",
      "          0.1757,  0.3716,  0.1285, -0.4428, -0.1493,  0.3853, -0.1636,  0.0200,\n",
      "         -0.0895,  0.1375,  0.3772, -0.1241]], grad_fn=<TanhBackward0>)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 参数含义完全类似RNN\n",
    "rnn = nn.RNNCell(input_size=10,\n",
    "                 hidden_size=20,\n",
    "                 bias=True,\n",
    "                 nonlinearity='tanh')\n",
    "\n",
    "entry = torch.randn(6, 3, 10)\n",
    "h = torch.randn(3, 20)\n",
    "\n",
    "h_all = []  # 所有的h\n",
    "\n",
    "for i in range(6):\n",
    "    # 前一个序列的输出h,作为下次序列的h\n",
    "    h = rnn(entry[i], hx=h)  # 输入是(N, C)的张量,输出为h\n",
    "    print(h.shape)\n",
    "    h_all.append(h)\n",
    "\n",
    "print(h)  # 最后一个序列的输出\n",
    "print(len(h_all))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "h1.shape: torch.Size([3, 30])\n",
      "h2.shape: torch.Size([3, 10])\n",
      "torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "# 双层循环神经网络RNN\n",
    "entry = torch.randn(10, 3, 100)\n",
    "\n",
    "cell1 = nn.RNNCell(100, 30)  # 第一层\n",
    "h1 = torch.zeros(3, 30)\n",
    "\n",
    "cell2 = nn.RNNCell(30, 10)  # 第二层\n",
    "h2 = torch.zeros(3, 10)\n",
    "\n",
    "for i in range(6):\n",
    "    h1 = cell1(entry[i], h1)\n",
    "    print(\"h1.shape:\", h1.shape)\n",
    "    # 第2层的输入是第1层的输出\n",
    "    h2 = cell2(h1, h2)\n",
    "    print(\"h2.shape:\", h2.shape)\n",
    "\n",
    "print(h2.shape)  # 最后一个序列的输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10])\n",
      "torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "# 双层循环神经网络LSTM\n",
    "entry = torch.randn(10, 3, 100)\n",
    "\n",
    "cell1 = nn.LSTMCell(input_size=100,\n",
    "                    hidden_size=30,\n",
    "                    bias=True)  # 第一层\n",
    "cell2 = nn.LSTMCell(30, 10)  # 第二层\n",
    "h1 = torch.zeros(3, 30)\n",
    "c1 = torch.ones(3, 30)\n",
    "h2 = torch.zeros(3, 10)\n",
    "c2 = torch.ones(3, 10)\n",
    "\n",
    "for i in range(6):\n",
    "    h1, c1 = cell1(entry[i], hx=(h1, c1))\n",
    "    h2, c2 = cell2(h1, hx=(h2, c2))\n",
    "\n",
    "# 最后一个序列的输出\n",
    "print(h2.shape)\n",
    "print(c2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "# 双层循环神经网络GRU\n",
    "entry = torch.randn(10, 3, 100)\n",
    "\n",
    "cell1 = nn.GRUCell(input_size=100,\n",
    "                   hidden_size=30,\n",
    "                   bias=True)  # 第一层\n",
    "cell2 = nn.GRUCell(30, 10)  # 第二层\n",
    "h1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 10)\n",
    "\n",
    "for i in range(6):\n",
    "    h1 = cell1(entry[i], hx=h1)\n",
    "    h2 = cell2(h1, h2)\n",
    "\n",
    "print(h2.shape)  # 最后一个序列的输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n",
      "torch.Size([2, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 双向循环神经网络RNN\n",
    "rnn = nn.RNNCell(input_size=10,\n",
    "                 hidden_size=20)\n",
    "\n",
    "entry = torch.randn(6, 3, 10)\n",
    "h_p = torch.randn(3, 20)\n",
    "h_b = torch.randn(3, 20)\n",
    "\n",
    "h_p_all = []  # 正向所有的h\n",
    "h_b_all = []  # 反向所有的h\n",
    "\n",
    "for i in range(6):\n",
    "    # 前一个序列的输出h,作为下次序列的h\n",
    "    h_p = rnn(entry[i], hx=h_p)  # 正向\n",
    "    h_p_all.append(h_p)\n",
    "    h_b = rnn(entry[i - 6], hx=h_b)  # 反向\n",
    "    h_b_all.append(h_b)\n",
    "\n",
    "for i in range(6):\n",
    "    # 每个t时刻的h\n",
    "    print(torch.stack((h_p_all[i], h_b_all[i - 6]), dim=0).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}