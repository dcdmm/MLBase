{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "589d594c-3c93-4ba0-bc02-39868d3d199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6cecfbd4-64b4-4194-8621-2774f34ec737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"PyTorch随机数种子设置大全\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)  # CPU上设置随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 当前GPU上设置随机种子\n",
    "        # torch.cuda.manual_seed_all(seed) # 所有GPU上设置随机种子\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3961e544-6cae-4fbf-afc6-0ce317dc73f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff71d8-6eb4-40cc-9f16-7737995ea71d",
   "metadata": {},
   "source": [
    "#### 数据分析与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ee6ddc8e-b1cf-45d7-bc68-305b57877bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2288791/2288791 [00:07<00:00, 299008.34it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/train.txt', 'r', encoding='utf-8') as f:\n",
    "    tmp = []\n",
    "    cnt = 1\n",
    "    for line in tqdm(f.read().split('\\n')):  # 句子与句子之间通过'\\n'分隔\n",
    "        sentence_id = f'sentence_{cnt}'\n",
    "        if line != '\\n' and len(line.strip()) > 0:\n",
    "            word_tags = line.split(' ')\n",
    "            if len(word_tags) == 2:  # 如:'枪 B-16'、'黑 I-16'、'色 I-16'\n",
    "                tmp.append([sentence_id] + word_tags)\n",
    "            elif len(word_tags) == 3:  # 如:'  O'\n",
    "                word = '[SEP]'  # 这里使用Bert模型的sep_token('[SEP]')表示空格(' ')\n",
    "                tag = word_tags[-1]\n",
    "                tmp.append([sentence_id, word, tag])\n",
    "        else:\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7fa795d4-0d5b-44e7-b181-b7700ea8ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sentence_1', '手', 'B-40'],\n",
       " ['sentence_1', '机', 'I-40'],\n",
       " ['sentence_1', '三', 'B-4'],\n",
       " ['sentence_1', '脚', 'I-4'],\n",
       " ['sentence_1', '架', 'I-4']]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6176fee9-75e5-4e32-abe6-35a8eee29934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence_1</td>\n",
       "      <td>手</td>\n",
       "      <td>B-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence_1</td>\n",
       "      <td>机</td>\n",
       "      <td>I-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence_1</td>\n",
       "      <td>三</td>\n",
       "      <td>B-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence_1</td>\n",
       "      <td>脚</td>\n",
       "      <td>I-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence_1</td>\n",
       "      <td>架</td>\n",
       "      <td>I-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id words  tags\n",
       "0  sentence_1     手  B-40\n",
       "1  sentence_1     机  I-40\n",
       "2  sentence_1     三   B-4\n",
       "3  sentence_1     脚   I-4\n",
       "4  sentence_1     架   I-4"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tmp = pd.DataFrame(tmp, columns=['sentence_id', 'words', 'tags'])  # 转换为DataFrame\n",
    "data_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "febdafe4-ea83-49ab-b873-c87a8e572044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-40': 0,\n",
       " 'I-40': 1,\n",
       " 'B-4': 2,\n",
       " 'I-4': 3,\n",
       " 'B-14': 4,\n",
       " 'I-14': 5,\n",
       " 'B-5': 6,\n",
       " 'I-5': 7,\n",
       " 'B-7': 8,\n",
       " 'I-7': 9,\n",
       " 'B-11': 10,\n",
       " 'I-11': 11,\n",
       " 'B-13': 12,\n",
       " 'I-13': 13,\n",
       " 'B-8': 14,\n",
       " 'I-8': 15,\n",
       " 'O': 16,\n",
       " 'B-16': 17,\n",
       " 'I-16': 18,\n",
       " 'B-29': 19,\n",
       " 'I-29': 20,\n",
       " 'B-9': 21,\n",
       " 'I-9': 22,\n",
       " 'B-12': 23,\n",
       " 'I-12': 24,\n",
       " 'B-18': 25,\n",
       " 'I-18': 26,\n",
       " 'B-1': 27,\n",
       " 'I-1': 28,\n",
       " 'B-3': 29,\n",
       " 'I-3': 30,\n",
       " 'B-22': 31,\n",
       " 'I-22': 32,\n",
       " 'B-37': 33,\n",
       " 'I-37': 34,\n",
       " 'B-39': 35,\n",
       " 'I-39': 36,\n",
       " 'B-10': 37,\n",
       " 'I-10': 38,\n",
       " 'B-36': 39,\n",
       " 'I-36': 40,\n",
       " 'B-34': 41,\n",
       " 'I-34': 42,\n",
       " 'B-31': 43,\n",
       " 'I-31': 44,\n",
       " 'B-38': 45,\n",
       " 'I-38': 46,\n",
       " 'B-54': 47,\n",
       " 'I-54': 48,\n",
       " 'B-6': 49,\n",
       " 'I-6': 50,\n",
       " 'B-30': 51,\n",
       " 'I-30': 52,\n",
       " 'B-15': 53,\n",
       " 'I-15': 54,\n",
       " 'B-2': 55,\n",
       " 'I-2': 56,\n",
       " 'B-49': 57,\n",
       " 'I-49': 58,\n",
       " 'B-21': 59,\n",
       " 'I-21': 60,\n",
       " 'B-47': 61,\n",
       " 'I-47': 62,\n",
       " 'B-23': 63,\n",
       " 'I-23': 64,\n",
       " 'B-20': 65,\n",
       " 'I-20': 66,\n",
       " 'B-50': 67,\n",
       " 'I-50': 68,\n",
       " 'B-46': 69,\n",
       " 'I-46': 70,\n",
       " 'B-41': 71,\n",
       " 'I-41': 72,\n",
       " 'B-43': 73,\n",
       " 'I-43': 74,\n",
       " 'B-48': 75,\n",
       " 'I-48': 76,\n",
       " 'B-19': 77,\n",
       " 'I-19': 78,\n",
       " 'B-52': 79,\n",
       " 'I-52': 80,\n",
       " 'B-33': 81,\n",
       " 'I-33': 82,\n",
       " 'B-28': 83,\n",
       " 'I-28': 84,\n",
       " 'B-32': 85,\n",
       " 'I-32': 86,\n",
       " 'B-44': 87,\n",
       " 'I-44': 88,\n",
       " 'B-25': 89,\n",
       " 'I-25': 90,\n",
       " 'B-17': 91,\n",
       " 'I-17': 92,\n",
       " 'B-42': 93,\n",
       " 'I-42': 94,\n",
       " 'B-24': 95,\n",
       " 'I-24': 96,\n",
       " 'B-53': 97,\n",
       " 'I-53': 98,\n",
       " 'B-26': 99,\n",
       " 'I-26': 100,\n",
       " 'B-35': 101,\n",
       " 'I-35': 102,\n",
       " 'B-51': 103,\n",
       " 'I-51': 104}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(data_tmp.tags.unique())}  # 标签到id的字典映射\n",
    "ids_to_labels = {v: k for v, k in enumerate(data_tmp.tags.unique())}  # id到标签的字典映射\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "04bc42bd-2a59-4fa5-999d-cefcbfb9e55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_1</th>\n",
       "      <td>手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...</td>\n",
       "      <td>B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_10</th>\n",
       "      <td>亚 信 作 废 章 财 务 现 金 付 讫 章 收 讫 受 控 文 件 银 行 付 讫 章 ...</td>\n",
       "      <td>O,O,B-4,I-4,I-4,B-5,I-5,B-9,I-9,B-4,I-4,I-4,B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_100</th>\n",
       "      <td>乐 创 （ l e c o n ） 奶 茶 店 设 备 全 套 冷 藏 冷 冻 水 吧 台 ...</td>\n",
       "      <td>B-1,I-1,O,B-1,I-1,I-1,I-1,I-1,O,B-7,I-7,I-7,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_1000</th>\n",
       "      <td>京 贺 [SEP] 暗 黑 游 戏 鼠 标 垫 超 大 电 竞 加 厚 锁 边 键 盘 垫 ...</td>\n",
       "      <td>O,O,O,B-14,I-14,B-5,I-5,B-4,I-4,I-4,B-13,I-13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_10000</th>\n",
       "      <td>英 特 尔 （ I n t e l ） 7 8 2 0 7 9 0 0 X i 9 7 9 ...</td>\n",
       "      <td>B-1,I-1,I-1,O,B-1,I-1,I-1,I-1,I-1,O,B-4,I-4,I-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         sentence  \\\n",
       "sentence_id                                                         \n",
       "sentence_1      手 机 三 脚 架 网 红 直 播 支 架 桌 面 自 拍 杆 蓝 牙 遥 控 三 脚 架 ...   \n",
       "sentence_10     亚 信 作 废 章 财 务 现 金 付 讫 章 收 讫 受 控 文 件 银 行 付 讫 章 ...   \n",
       "sentence_100    乐 创 （ l e c o n ） 奶 茶 店 设 备 全 套 冷 藏 冷 冻 水 吧 台 ...   \n",
       "sentence_1000   京 贺 [SEP] 暗 黑 游 戏 鼠 标 垫 超 大 电 竞 加 厚 锁 边 键 盘 垫 ...   \n",
       "sentence_10000  英 特 尔 （ I n t e l ） 7 8 2 0 7 9 0 0 X i 9 7 9 ...   \n",
       "\n",
       "                                                      word_labels  \n",
       "sentence_id                                                        \n",
       "sentence_1      B-40,I-40,B-4,I-4,I-4,B-14,I-14,B-5,I-5,B-4,I-...  \n",
       "sentence_10     O,O,B-4,I-4,I-4,B-5,I-5,B-9,I-9,B-4,I-4,I-4,B-...  \n",
       "sentence_100    B-1,I-1,O,B-1,I-1,I-1,I-1,I-1,O,B-7,I-7,I-7,O,...  \n",
       "sentence_1000   O,O,O,B-14,I-14,B-5,I-5,B-4,I-4,I-4,B-13,I-13,...  \n",
       "sentence_10000  B-1,I-1,I-1,O,B-1,I-1,I-1,I-1,I-1,O,B-4,I-4,I-...  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_tmp.groupby(['sentence_id'])['words'].apply(lambda x: ' '.join(x)),\n",
    "                  data_tmp.groupby(['sentence_id'])['tags'].apply(lambda x: ','.join(x))], axis=1)\n",
    "data.columns = ['sentence', 'word_labels']\n",
    "data = data.drop_duplicates()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5ed19e5a-22e3-4420-a013-1c798fad3d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    39995.000000\n",
       "mean        56.220828\n",
       "std         13.473300\n",
       "min          7.000000\n",
       "25%         46.000000\n",
       "50%         56.000000\n",
       "75%         65.000000\n",
       "max        101.000000\n",
       "Name: sentence, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 句子最大长度为101\n",
    "# 中文按字分词;英文情况下,wordPiece或BPE分词可以用更小的词片段来组成更大的词\n",
    "data['sentence'].apply(lambda x: len(x.split(' '))).describe()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fb86f124-e5de-4301-9b9b-86d2092ca331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(data, test_size=0.1, random_state=RANDOM_SEED)  # 划分训练数据集验证数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d4f0b5a3-d98d-4223-83c4-93bb6aeefa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7487.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>O P P O 闪 充 充 电 器 [SEP] X 9 0 7 0 [SEP] X 9 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_10</th>\n",
       "      <td>听 雨 轩 8 0 支 装 中 性 笔 芯 0 . 5 m m 全 针 管 水 笔 芯 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_100</th>\n",
       "      <td>联 想 I d e a p a d 7 2 0 S - 1 3 I K B 电 脑 炫 彩 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1000</th>\n",
       "      <td>A 4 纸 包 胶 y o 3 : 1 双 线 圈 3 4 孔 笔 记 本 台 挂 历 菜 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_10000</th>\n",
       "      <td>六 品 堂 半 生 半 熟 宣 纸 1 0 0 张 书 法 专 用 纸 作 品 纸 国 画 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sentence\n",
       "sentence_id                                                   \n",
       "test_1       O P P O 闪 充 充 电 器 [SEP] X 9 0 7 0 [SEP] X 9 0 ...\n",
       "test_10      听 雨 轩 8 0 支 装 中 性 笔 芯 0 . 5 m m 全 针 管 水 笔 芯 0 ...\n",
       "test_100     联 想 I d e a p a d 7 2 0 S - 1 3 I K B 电 脑 炫 彩 ...\n",
       "test_1000    A 4 纸 包 胶 y o 3 : 1 双 线 圈 3 4 孔 笔 记 本 台 挂 历 菜 ...\n",
       "test_10000   六 品 堂 半 生 半 熟 宣 纸 1 0 0 张 书 法 专 用 纸 作 品 纸 国 画 ..."
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('datasets/sample_per_line_preliminary_A.txt', 'r', encoding='utf-8') as f:\n",
    "    tmp_test = []\n",
    "    cnt_test = 1\n",
    "    for line in tqdm(f.read().split('\\n')):\n",
    "        sentence_id = f'test_{cnt_test}'\n",
    "        for word in line:\n",
    "            if word.strip():\n",
    "                # 若不为空白字符\n",
    "                tmp_test.append([sentence_id, word])\n",
    "            else:\n",
    "                tmp_test.append([sentence_id, '[SEP]'])  # 同理使用Bert模型的sep_token('[SEP]')表示空格(' ')      \n",
    "        cnt_test += 1\n",
    "\n",
    "data_tmp_test = pd.DataFrame(tmp_test, columns=['sentence_id', 'words'])  # 转换为DataFrame\n",
    "test_dataset = data_tmp_test.groupby(['sentence_id'])['words'].agg([lambda x: ' '.join(x)])  # 返回值类型为DataFrame\n",
    "test_dataset.columns = ['sentence']\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ddb6e93e-231c-4194-8f60-d005967d5a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'hfl/chinese-roberta-wwm-ext'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "pretrained = BertModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9a5fdd53-011c-4b5b-84f9-f67f9d5faa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"自定义Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, df, have_label=True):\n",
    "        self.texts = df['sentence'].values\n",
    "        self.have_label = have_label\n",
    "        if have_label:\n",
    "            self.labels = df['word_labels'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        if self.have_label:\n",
    "            label = self.labels[item]\n",
    "            return text, label  # 自定义索引方式\n",
    "        else:\n",
    "            return text,  # 测试数据集不含标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2be9b0b1-1ff4-4bff-b7b4-5877f56aa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label(index, sen_list):\n",
    "    \"\"\"递归往前找到第一个不是以'##'开头的单词\"\"\"\n",
    "    index -= 1\n",
    "    if not sen_list[index].startswith('##'):\n",
    "        return index\n",
    "    else:\n",
    "        return find_label(index, sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ea6695c1-b93c-4445-b39f-6971f2f1e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, batch_size, shuffle=True, have_label=True):\n",
    "    mda = MyDataset(df, have_label=have_label)\n",
    "\n",
    "    def collate_func(data):\n",
    "        new_data = default_collate(data)\n",
    "        encoding = tokenizer(text=list(new_data[0]),\n",
    "                             return_token_type_ids=True,\n",
    "                             padding=True,  # Pad to the longest sequence in the batch\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors='pt')\n",
    "        result_dict = {'input_ids': encoding['input_ids'],\n",
    "                       'token_type_ids': encoding['token_type_ids'],\n",
    "                       'attention_mask': encoding['attention_mask']}\n",
    "        if len(new_data) == 1:  # 测试数据集\n",
    "            return result_dict  # 测试数据集不含标签\n",
    "        else:\n",
    "            want_list = []\n",
    "            # 可通过指定tokenizer return_offsets_mapping=True或通过encoding.word_ids()简化过程\n",
    "            for i in range(encoding['input_ids'].shape[0]):\n",
    "                tokenize_sentence = tokenizer.convert_ids_to_tokens(encoding['input_ids'][i])\n",
    "                label_list = new_data[1][i].split(',')\n",
    "                label_list.insert(0, 'O')  # 对应Bert模型句子开头标签'[CLS]'\n",
    "                label_list.append('O')  # 对应Bert模型句子结束标签'[SEP]'\n",
    "                for i in range(len(tokenize_sentence)):\n",
    "                    # Bert使用wordPiece分词\n",
    "                    # For example, `input = \"unaffable\"` wil return as output `[\"un\", \"##aff\", \"##able\"]`\n",
    "                    # 如:\"unaffable\"的标签为:\"O\",output:`[\"un\", \"##aff\", \"##able\"]`的标签应为:`[\"O\", \"O\", \"O\"]`\n",
    "                    if tokenize_sentence[i].startswith('##'):\n",
    "                        insert_index = find_label(i, tokenize_sentence)\n",
    "                        insert_label = label_list[insert_index]\n",
    "                        label_list.insert(i, insert_label)\n",
    "                    if tokenize_sentence[i] == '[PAD]':\n",
    "                        label_list.append('O')  # 对应填充字符'[PAD]'\n",
    "                label_list_ids = [labels_to_ids[label] for label in label_list]\n",
    "                want_list.append(label_list_ids)\n",
    "            result_dict['labels'] = torch.tensor(want_list)\n",
    "            return result_dict\n",
    "\n",
    "    return DataLoader(mda, batch_size=batch_size, collate_fn=collate_func, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3b27e102-56ca-481e-9bf5-83bfbb3b797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(train_dataset, tokenizer, 32, shuffle=True)  # 训练数据集\n",
    "val_data_loader = create_data_loader(val_dataset, tokenizer, 32, shuffle=False)  # 验证数据集\n",
    "test_data_loader = create_data_loader(test_dataset, tokenizer, 32, shuffle=False, have_label=False)  # 测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bdb5b2c7-52ec-4cb4-ac7b-ea7d8ce957a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  523,  524,  ...,    0,    0,    0],\n",
      "        [ 101, 1912, 1297,  ...,    0,    0,    0],\n",
      "        [ 101,  155,  143,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4035, 3635,  ...,    0,    0,    0],\n",
      "        [ 101, 6844, 4500,  ...,    0,    0,    0],\n",
      "        [ 101, 2157, 4500,  ...,    0,    0,    0]])\n",
      "torch.Size([32, 89])\n",
      "tensor([[16, 16, 16,  ..., 16, 16, 16],\n",
      "        [16,  2,  3,  ..., 16, 16, 16],\n",
      "        [16, 45, 46,  ..., 16, 16, 16],\n",
      "        ...,\n",
      "        [16, 27, 28,  ..., 16, 16, 16],\n",
      "        [16, 16, 16,  ..., 16, 16, 16],\n",
      "        [16,  8,  9,  ..., 16, 16, 16]])\n",
      "torch.Size([32, 89])\n"
     ]
    }
   ],
   "source": [
    "for i in val_data_loader:\n",
    "    print(i['input_ids'])\n",
    "    print(i['input_ids'].shape)\n",
    "    print(i['labels'])\n",
    "    print(i['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55485143-6dd1-435a-8cfc-a4cf353a7179",
   "metadata": {},
   "source": [
    "#### 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "11dc62c2-6438-48a4-8cd6-e4d4a8a98865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNER(nn.Module):\n",
    "    \"\"\"Bert + Linear基础模型进行命名实体识别\"\"\"\n",
    "\n",
    "    def __init__(self, pretrained_model, num_labels, classifier_dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.pretrained = pretrained_model\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(self.pretrained.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.pretrained(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  token_type_ids=token_type_ids)\n",
    "\n",
    "        # sequence_output.shape=[batch_size, sequence_length, hidden_size]\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        # logits.shape=[batch_size, sequence_length, num_labels]\n",
    "        logits = self.classifier(sequence_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b355325d-398d-4c10-8ef7-2fec1a3177c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseNER(pretrained, len(labels_to_ids), 0.3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39348e-be28-4318-abaf-d7a04047c98c",
   "metadata": {},
   "source": [
    "### 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f81552f5-ff86-4bc4-a930-7ec29f009769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion_cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer_adamw = optim.AdamW(model.parameters(), lr=5e-5)  # 模型设备切换必须在优化器定义前执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5a5edc09-0c33-4cec-b0a3-9c28f5100cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
    "    \"\"\"\n",
    "    Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after\n",
    "    a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "    Args:\n",
    "        optimizer ([`~torch.optim.Optimizer`]):\n",
    "            The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (`int`):\n",
    "            The number of steps for the warmup phase.\n",
    "        num_training_steps (`int`):\n",
    "            The total number of training steps.\n",
    "    Return:\n",
    "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # 学习率预热(线性增加)\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # 学习率线性衰减(最小为0)\n",
    "        # num_training_steps后学习率恒为0\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "scheduler_lr = get_linear_schedule_with_warmup(optimizer_adamw, 0, len(train_data_loader) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b00a4c46-7180-4663-91b2-1977bbbec14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    for idx, i in enumerate(dataloader):\n",
    "        # 数据设备切换\n",
    "        input_ids = i['input_ids'].to(device)\n",
    "        attention_mask = i['attention_mask'].to(device)\n",
    "        token_type_ids = i['token_type_ids'].to(device)\n",
    "        labels = i['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids)\n",
    "        # out.shape=[batch_size * sequence_length, model.num_labels]\n",
    "        out = out.reshape(-1, model.num_labels)\n",
    "        # labels.shape=[batch_size * sequence_length, ]\n",
    "        labels = labels.reshape(-1)\n",
    "        loss = criterion(out, labels)  # 损失值\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=5)  # 梯度裁剪\n",
    "        optimizer.step()\n",
    "        scheduler_lr.step()\n",
    "\n",
    "        if idx % 500 == 0 and idx > 0:\n",
    "            attention_mask_flatten_bool = attention_mask.reshape(-1) == 1  # reshape顺序与out、labels reshape顺序相同\n",
    "            labels_mask = torch.masked_select(labels, attention_mask_flatten_bool)  # 布尔索引非填充区域标签(使之不参与评估准确率)\n",
    "            predict_labels_mask = torch.masked_select(torch.argmax(out, dim=1), attention_mask_flatten_bool)\n",
    "            acc = accuracy_score(labels_mask.cpu().numpy(), predict_labels_mask.cpu().numpy())\n",
    "            print('| step {:5d} | loss {:8.5f} | accuracy {:8.5f} |'.format(idx, loss.item(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "96dad531-19ce-4a9d-afab-dad11f28153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型验证\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    predict_list = []\n",
    "    y_true_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, i in enumerate(dataloader):\n",
    "            # 数据设备切换\n",
    "            input_ids = i['input_ids'].to(device)\n",
    "            attention_mask = i['attention_mask'].to(device)\n",
    "            token_type_ids = i['token_type_ids'].to(device)\n",
    "            labels = i['labels']\n",
    "\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "            # out.shape=[batch_size * sequence_length, model.num_labels]\n",
    "            out = out.reshape(-1, model.num_labels)\n",
    "            # labels.shape=[batch_size * sequence_length, ]\n",
    "            labels = labels.reshape(-1)\n",
    "\n",
    "            attention_mask_flatten_bool = attention_mask.cpu().reshape(-1) == 1  # reshape顺序与out、labels reshape顺序相同\n",
    "            labels_mask = torch.masked_select(labels, attention_mask_flatten_bool)  # 布尔索引非填充区域标签(使之不参与评估准确率)\n",
    "            predict_labels_mask = torch.masked_select(torch.argmax(out.cpu(), dim=1), attention_mask_flatten_bool)\n",
    "\n",
    "            predict_list.append(predict_labels_mask)\n",
    "            y_true_list.extend(labels_mask.tolist())\n",
    "\n",
    "    predict_all = torch.cat(predict_list, dim=0)  # 合并所有批次的预测结果\n",
    "    y_true_all = torch.tensor(y_true_list)\n",
    "    accuracy = accuracy_score(y_true_all.numpy(), predict_all.numpy())  # 评估指标\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2a8dfa62-b150-48ab-857d-154e58664d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| step   500 | loss  0.44088 | accuracy  0.77423 |\n",
      "| step  1000 | loss  0.44723 | accuracy  0.78127 |\n",
      "---------------------------------------------------------------\n",
      "| end of epoch     1 | time: 156.08s | valid accuracy  0.81043 |\n",
      "---------------------------------------------------------------\n",
      "| step   500 | loss  0.35923 | accuracy  0.82469 |\n",
      "| step  1000 | loss  0.36174 | accuracy  0.82898 |\n",
      "---------------------------------------------------------------\n",
      "| end of epoch     2 | time: 156.56s | valid accuracy  0.81976 |\n",
      "---------------------------------------------------------------\n",
      "| step   500 | loss  0.37173 | accuracy  0.81074 |\n",
      "| step  1000 | loss  0.41952 | accuracy  0.80341 |\n",
      "---------------------------------------------------------------\n",
      "| end of epoch     3 | time: 157.14s | valid accuracy  0.82326 |\n",
      "---------------------------------------------------------------\n",
      "| step   500 | loss  0.26962 | accuracy  0.87680 |\n",
      "| step  1000 | loss  0.32972 | accuracy  0.84546 |\n",
      "---------------------------------------------------------------\n",
      "| end of epoch     4 | time: 156.79s | valid accuracy  0.82443 |\n",
      "---------------------------------------------------------------\n",
      "| step   500 | loss  0.38035 | accuracy  0.82614 |\n",
      "| step  1000 | loss  0.33507 | accuracy  0.82709 |\n",
      "---------------------------------------------------------------\n",
      "| end of epoch     5 | time: 156.53s | valid accuracy  0.82482 |\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, train_data_loader, criterion_cross_entropy, optimizer_adamw, device)\n",
    "    acc_val = evaluate(model, val_data_loader, device)\n",
    "    print('-' * 63)\n",
    "    print('| end of epoch {:5d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.5f} |'.format(epoch, time.time() - epoch_start_time, acc_val))\n",
    "    print('-' * 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb92ee7-7360-45a0-8ff6-b9bbd2000394",
   "metadata": {},
   "source": [
    "### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f4020cc4-6c16-47d7-b68f-0dbd7d647a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    predict_list = []\n",
    "    with torch.no_grad():\n",
    "        for idx, i in enumerate(dataloader):\n",
    "            # 数据设备切换\n",
    "            input_ids = i['input_ids'].to(device)\n",
    "            attention_mask = i['attention_mask'].to(device)\n",
    "            token_type_ids = i['token_type_ids'].to(device)\n",
    "\n",
    "            # out.shape=[batch_size, sequence_length, model.num_labels]\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "            predict = torch.argmax(out, dim=-1)\n",
    "\n",
    "            # 将id重新映射回标签\n",
    "            predict_label = pd.DataFrame(predict.cpu().tolist()).applymap(lambda x: ids_to_labels[x])\n",
    "\n",
    "            predict_list.extend(predict_label.values.tolist())\n",
    "\n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "51c48089-3304-48aa-8c84-7176bf2a6a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-37',\n",
       " 'I-37',\n",
       " 'I-37',\n",
       " 'I-37',\n",
       " 'B-11',\n",
       " 'I-11',\n",
       " 'B-4',\n",
       " 'I-4',\n",
       " 'I-4',\n",
       " 'O',\n",
       " 'B-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'O',\n",
       " 'B-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'I-38',\n",
       " 'O',\n",
       " 'B-38',\n",
       " 'I-38',\n",
       " 'O',\n",
       " 'B-4',\n",
       " 'I-4',\n",
       " 'I-4',\n",
       " 'B-11',\n",
       " 'I-11',\n",
       " 'B-40',\n",
       " 'I-40',\n",
       " 'B-4',\n",
       " 'I-4',\n",
       " 'I-4',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-18',\n",
       " 'I-18',\n",
       " 'I-18',\n",
       " 'B-4',\n",
       " 'I-4',\n",
       " 'I-4',\n",
       " 'O',\n",
       " 'B-4',\n",
       " 'I-4',\n",
       " 'I-4',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-37',\n",
       " 'I-37',\n",
       " 'O',\n",
       " 'B-18',\n",
       " 'I-18',\n",
       " 'I-18',\n",
       " 'I-18',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result = predict(model, test_data_loader, device)\n",
    "predict_result[0]  # 模型预测标签(包含冗余部分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b9efd0bb-fc3d-4464-9155-62c2e6fce33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'o',\n",
       " 'p',\n",
       " 'p',\n",
       " 'o',\n",
       " '闪',\n",
       " '充',\n",
       " '充',\n",
       " '电',\n",
       " '器',\n",
       " '[SEP]',\n",
       " 'x',\n",
       " '9',\n",
       " '0',\n",
       " '7',\n",
       " '0',\n",
       " '[SEP]',\n",
       " 'x',\n",
       " '9',\n",
       " '0',\n",
       " '7',\n",
       " '7',\n",
       " '[SEP]',\n",
       " 'r',\n",
       " '5',\n",
       " '[SEP]',\n",
       " '快',\n",
       " '充',\n",
       " '头',\n",
       " '通',\n",
       " '用',\n",
       " '手',\n",
       " '机',\n",
       " '数',\n",
       " '据',\n",
       " '线',\n",
       " '[SEP]',\n",
       " '套',\n",
       " '餐',\n",
       " '【',\n",
       " '2',\n",
       " '.',\n",
       " '4',\n",
       " '充',\n",
       " '电',\n",
       " '头',\n",
       " '+',\n",
       " '数',\n",
       " '据',\n",
       " '线',\n",
       " '[SEP]',\n",
       " '】',\n",
       " '[SEP]',\n",
       " '安',\n",
       " '卓',\n",
       " '[SEP]',\n",
       " '1',\n",
       " '.',\n",
       " '5',\n",
       " 'm',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_list = []\n",
    "for i in test_data_loader:\n",
    "    for j in i['input_ids'].tolist():\n",
    "        tokenize_list.append(tokenizer.convert_ids_to_tokens(j))\n",
    "tokenize_list[0]  # 分词器分词结果(包括'[CLS]', '[PAD]', Bert模型句子结束标签'[SEP]', 组成英文单词的更小的词片段)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "acadcc70-f163-4095-8e65-a6a60e320e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result_remove_redundancy = []\n",
    "\n",
    "for num in range(10000):  # 共10000条句子\n",
    "    predict_num = predict_result[num]\n",
    "    tokenize_num = tokenize_list[num]\n",
    "    temp_remove_redundancy_list = []\n",
    "\n",
    "    for word_id in range(len(tokenize_num)):\n",
    "        if (tokenize_num[word_id].startswith(\"##\")) or (tokenize_num[word_id] in ['[CLS]', '[PAD]']):\n",
    "            # 去除'[CLS]'和'[PAD]'的和\"##\"开头的字的预测结果\n",
    "            # 例:英文单词\"unaffable\"的分词结果为:`[\"un\", \"##aff\", \"##able\"]`,这里只考虑\"un\"的预测结果\n",
    "            continue\n",
    "        else:\n",
    "            temp_remove_redundancy_list.append(predict_num[word_id])\n",
    "    temp_remove_redundancy_str = ' '.join(temp_remove_redundancy_list[:-1])  # 去除Bert模型句子结束标签'[SEP]'的预测结果\n",
    "    predict_result_remove_redundancy.append(temp_remove_redundancy_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "32a6f4b6-e440-4868-a879-07efa65e710a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O P P O 闪 充 充 电 器 [SEP] X 9 0 7 0 [SEP] X 9 0 7 7 [SEP] R 5 [SEP] 快 充 头 通 用 手 机 数 据 线 [SEP] 套 餐 【 2 . 4 充 电 头 + 数 据 线 [SEP] 】 [SEP] 安 卓 [SEP] 1 . 5 m\n",
      "B-37 I-37 I-37 I-37 B-11 I-11 B-4 I-4 I-4 O B-38 I-38 I-38 I-38 I-38 O B-38 I-38 I-38 I-38 I-38 O B-38 I-38 O B-4 I-4 I-4 B-11 I-11 B-40 I-40 B-4 I-4 I-4 O O O O B-18 I-18 I-18 B-4 I-4 I-4 O B-4 I-4 I-4 O O O B-37 I-37 O B-18 I-18 I-18 I-18\n"
     ]
    }
   ],
   "source": [
    "# example:\n",
    "print(test_dataset.iloc[0][0])\n",
    "print(predict_result_remove_redundancy[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}