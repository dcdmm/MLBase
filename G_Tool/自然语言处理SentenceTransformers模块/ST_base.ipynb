{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all-MiniLM-L6-v2\n",
    "    This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "'''\n",
    "model = SentenceTransformer(model_name_or_path='all-MiniLM-L6-v2', device='cuda')  # 从Huggingface加载预训练模型\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 256\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 512\n"
     ]
    }
   ],
   "source": [
    "# Change the length to 512\n",
    "# Note: You cannot increase the length higher than what is maximally supported by the respective transformer model.\n",
    "# Also note that if a model was trained on short texts, the representations for long texts might not be that good.\n",
    "model.max_seq_length = 512\n",
    "\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01371741 -0.04285155 -0.01562859 ...  0.10017834  0.12365727\n",
      "  -0.0422967 ]\n",
      " [ 0.05645248  0.05500238  0.03137961 ...  0.06650873  0.08491523\n",
      "  -0.03328493]\n",
      " [ 0.04393356  0.0589344   0.04817835 ...  0.05216279  0.05610651\n",
      "   0.10206393]]\n",
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "# Computes sentence embeddings\n",
    "embeddings_numpy = model.encode(sentences, convert_to_numpy=True)\n",
    "print(embeddings_numpy)  # type:numpy array\n",
    "print(embeddings_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0137, -0.0429, -0.0156,  ...,  0.1002,  0.1237, -0.0423],\n",
      "        [ 0.0565,  0.0550,  0.0314,  ...,  0.0665,  0.0849, -0.0333],\n",
      "        [ 0.0439,  0.0589,  0.0482,  ...,  0.0522,  0.0561,  0.1021]],\n",
      "       device='cuda:0')\n",
      "torch.Size([3, 384])\n"
     ]
    }
   ],
   "source": [
    "embeddings_tensor = model.encode(sentences, convert_to_tensor=True)\n",
    "print(embeddings_tensor)  # type:torch tensor\n",
    "print(embeddings_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
