{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.utils.data as Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 手写数字训练数据集\n",
    "mnist = np.load(\"../../../../Other/datasets/NumPy/mnist.npz\")\n",
    "X_train, y_train, X_test, y_test = torch.unsqueeze(torch.tensor(mnist['x_train']), 1).to(dtype=torch.float32), \\\n",
    "                                   torch.tensor(mnist['y_train']).to(dtype=torch.long), \\\n",
    "                                   torch.unsqueeze(torch.tensor(mnist['x_test']), 1).to(dtype=torch.float32), \\\n",
    "                                   torch.tensor(mnist['y_test']).to(dtype=torch.long)\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_data = Data.TensorDataset(X_train, y_train)\n",
    "train_loader = Data.DataLoader(dataset=train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True)\n",
    "train_X = Data.DataLoader(X_train, batch_size=batch_size)\n",
    "test_X = Data.DataLoader(X_test, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.featrues = nn.Sequential(  # 内部实现了forward函数;各模块顺序执行\n",
    "            nn.Conv2d(1, 6, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),  # 10分类问题\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.featrues(x)\n",
    "        x = x.reshape(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criteon = nn.CrossEntropyLoss()  # 定义损失函数为交叉熵\n",
    "net = LeNet()\n",
    "lenet = net.to(device)  # 模型设备转移必须在优化器定义前执行\n",
    "\n",
    "# Adagrad优化器\n",
    "optimizer = optim.Adagrad(net.parameters(),\n",
    "                          lr=learning_rate,  # 学习率\n",
    "                          eps=1e-10)  # 分母中的小常数\\delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch_model.train_evaluate import Train_Evaluate\n",
    "\n",
    "t_and_v = Train_Evaluate(model=lenet, optimizer=optimizer, criterion=criteon, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duanm\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  [0    /60000 (0  %)]\tLoss: 2.305708\n",
      "Train Epoch: 0  [2000 /60000 (3  %)]\tLoss: 1.668427\n",
      "Train Epoch: 0  [4000 /60000 (7  %)]\tLoss: 0.962614\n",
      "Train Epoch: 0  [6000 /60000 (10 %)]\tLoss: 0.726758\n",
      "Train Epoch: 0  [8000 /60000 (13 %)]\tLoss: 0.489252\n",
      "Train Epoch: 0  [10000/60000 (17 %)]\tLoss: 0.489185\n",
      "Train Epoch: 0  [12000/60000 (20 %)]\tLoss: 0.449605\n",
      "Train Epoch: 0  [14000/60000 (23 %)]\tLoss: 0.361467\n",
      "Train Epoch: 0  [16000/60000 (27 %)]\tLoss: 0.413577\n",
      "Train Epoch: 0  [18000/60000 (30 %)]\tLoss: 0.334877\n",
      "Train Epoch: 0  [20000/60000 (33 %)]\tLoss: 0.304069\n",
      "Train Epoch: 0  [22000/60000 (37 %)]\tLoss: 0.275703\n",
      "Train Epoch: 0  [24000/60000 (40 %)]\tLoss: 0.227078\n",
      "Train Epoch: 0  [26000/60000 (43 %)]\tLoss: 0.254006\n",
      "Train Epoch: 0  [28000/60000 (47 %)]\tLoss: 0.222288\n",
      "Train Epoch: 0  [30000/60000 (50 %)]\tLoss: 0.299463\n",
      "Train Epoch: 0  [32000/60000 (53 %)]\tLoss: 0.243689\n",
      "Train Epoch: 0  [34000/60000 (57 %)]\tLoss: 0.249335\n",
      "Train Epoch: 0  [36000/60000 (60 %)]\tLoss: 0.245892\n",
      "Train Epoch: 0  [38000/60000 (63 %)]\tLoss: 0.165143\n",
      "Train Epoch: 0  [40000/60000 (67 %)]\tLoss: 0.243165\n",
      "Train Epoch: 0  [42000/60000 (70 %)]\tLoss: 0.182246\n",
      "Train Epoch: 0  [44000/60000 (73 %)]\tLoss: 0.235936\n",
      "Train Epoch: 0  [46000/60000 (77 %)]\tLoss: 0.152233\n",
      "Train Epoch: 0  [48000/60000 (80 %)]\tLoss: 0.161226\n",
      "Train Epoch: 0  [50000/60000 (83 %)]\tLoss: 0.118477\n",
      "Train Epoch: 0  [52000/60000 (87 %)]\tLoss: 0.144390\n",
      "Train Epoch: 0  [54000/60000 (90 %)]\tLoss: 0.253431\n",
      "Train Epoch: 0  [56000/60000 (93 %)]\tLoss: 0.144110\n",
      "Train Epoch: 0  [58000/60000 (97 %)]\tLoss: 0.103566\n",
      "Train Epoch: 0  [60000/60000 (100%)]\tLoss: 0.122822\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1  [0    /60000 (0  %)]\tLoss: 0.218660\n",
      "Train Epoch: 1  [2000 /60000 (3  %)]\tLoss: 0.166605\n",
      "Train Epoch: 1  [4000 /60000 (7  %)]\tLoss: 0.168945\n",
      "Train Epoch: 1  [6000 /60000 (10 %)]\tLoss: 0.099028\n",
      "Train Epoch: 1  [8000 /60000 (13 %)]\tLoss: 0.213561\n",
      "Train Epoch: 1  [10000/60000 (17 %)]\tLoss: 0.085616\n",
      "Train Epoch: 1  [12000/60000 (20 %)]\tLoss: 0.205807\n",
      "Train Epoch: 1  [14000/60000 (23 %)]\tLoss: 0.141360\n",
      "Train Epoch: 1  [16000/60000 (27 %)]\tLoss: 0.166640\n",
      "Train Epoch: 1  [18000/60000 (30 %)]\tLoss: 0.077198\n",
      "Train Epoch: 1  [20000/60000 (33 %)]\tLoss: 0.118263\n",
      "Train Epoch: 1  [22000/60000 (37 %)]\tLoss: 0.068819\n",
      "Train Epoch: 1  [24000/60000 (40 %)]\tLoss: 0.079604\n",
      "Train Epoch: 1  [26000/60000 (43 %)]\tLoss: 0.104982\n",
      "Train Epoch: 1  [28000/60000 (47 %)]\tLoss: 0.134735\n",
      "Train Epoch: 1  [30000/60000 (50 %)]\tLoss: 0.126573\n",
      "Train Epoch: 1  [32000/60000 (53 %)]\tLoss: 0.131503\n",
      "Train Epoch: 1  [34000/60000 (57 %)]\tLoss: 0.130974\n",
      "Train Epoch: 1  [36000/60000 (60 %)]\tLoss: 0.058184\n",
      "Train Epoch: 1  [38000/60000 (63 %)]\tLoss: 0.132324\n",
      "Train Epoch: 1  [40000/60000 (67 %)]\tLoss: 0.104916\n",
      "Train Epoch: 1  [42000/60000 (70 %)]\tLoss: 0.092796\n",
      "Train Epoch: 1  [44000/60000 (73 %)]\tLoss: 0.136810\n",
      "Train Epoch: 1  [46000/60000 (77 %)]\tLoss: 0.104594\n",
      "Train Epoch: 1  [48000/60000 (80 %)]\tLoss: 0.084408\n",
      "Train Epoch: 1  [50000/60000 (83 %)]\tLoss: 0.179130\n",
      "Train Epoch: 1  [52000/60000 (87 %)]\tLoss: 0.133944\n",
      "Train Epoch: 1  [54000/60000 (90 %)]\tLoss: 0.081663\n",
      "Train Epoch: 1  [56000/60000 (93 %)]\tLoss: 0.091164\n",
      "Train Epoch: 1  [58000/60000 (97 %)]\tLoss: 0.110516\n",
      "Train Epoch: 1  [60000/60000 (100%)]\tLoss: 0.120173\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 2  [0    /60000 (0  %)]\tLoss: 0.109288\n",
      "Train Epoch: 2  [2000 /60000 (3  %)]\tLoss: 0.147395\n",
      "Train Epoch: 2  [4000 /60000 (7  %)]\tLoss: 0.070444\n",
      "Train Epoch: 2  [6000 /60000 (10 %)]\tLoss: 0.059178\n",
      "Train Epoch: 2  [8000 /60000 (13 %)]\tLoss: 0.082475\n",
      "Train Epoch: 2  [10000/60000 (17 %)]\tLoss: 0.049407\n",
      "Train Epoch: 2  [12000/60000 (20 %)]\tLoss: 0.099269\n",
      "Train Epoch: 2  [14000/60000 (23 %)]\tLoss: 0.079673\n",
      "Train Epoch: 2  [16000/60000 (27 %)]\tLoss: 0.135466\n",
      "Train Epoch: 2  [18000/60000 (30 %)]\tLoss: 0.102832\n",
      "Train Epoch: 2  [20000/60000 (33 %)]\tLoss: 0.154100\n",
      "Train Epoch: 2  [22000/60000 (37 %)]\tLoss: 0.090536\n",
      "Train Epoch: 2  [24000/60000 (40 %)]\tLoss: 0.113544\n",
      "Train Epoch: 2  [26000/60000 (43 %)]\tLoss: 0.085253\n",
      "Train Epoch: 2  [28000/60000 (47 %)]\tLoss: 0.149070\n",
      "Train Epoch: 2  [30000/60000 (50 %)]\tLoss: 0.079911\n",
      "Train Epoch: 2  [32000/60000 (53 %)]\tLoss: 0.043824\n",
      "Train Epoch: 2  [34000/60000 (57 %)]\tLoss: 0.113552\n",
      "Train Epoch: 2  [36000/60000 (60 %)]\tLoss: 0.136283\n",
      "Train Epoch: 2  [38000/60000 (63 %)]\tLoss: 0.111313\n",
      "Train Epoch: 2  [40000/60000 (67 %)]\tLoss: 0.151765\n",
      "Train Epoch: 2  [42000/60000 (70 %)]\tLoss: 0.171671\n",
      "Train Epoch: 2  [44000/60000 (73 %)]\tLoss: 0.066251\n",
      "Train Epoch: 2  [46000/60000 (77 %)]\tLoss: 0.194451\n",
      "Train Epoch: 2  [48000/60000 (80 %)]\tLoss: 0.087591\n",
      "Train Epoch: 2  [50000/60000 (83 %)]\tLoss: 0.145614\n",
      "Train Epoch: 2  [52000/60000 (87 %)]\tLoss: 0.029815\n",
      "Train Epoch: 2  [54000/60000 (90 %)]\tLoss: 0.089014\n",
      "Train Epoch: 2  [56000/60000 (93 %)]\tLoss: 0.093615\n",
      "Train Epoch: 2  [58000/60000 (97 %)]\tLoss: 0.092581\n",
      "Train Epoch: 2  [60000/60000 (100%)]\tLoss: 0.104594\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 3  [0    /60000 (0  %)]\tLoss: 0.071190\n",
      "Train Epoch: 3  [2000 /60000 (3  %)]\tLoss: 0.048888\n",
      "Train Epoch: 3  [4000 /60000 (7  %)]\tLoss: 0.068508\n",
      "Train Epoch: 3  [6000 /60000 (10 %)]\tLoss: 0.102499\n",
      "Train Epoch: 3  [8000 /60000 (13 %)]\tLoss: 0.067536\n",
      "Train Epoch: 3  [10000/60000 (17 %)]\tLoss: 0.072778\n",
      "Train Epoch: 3  [12000/60000 (20 %)]\tLoss: 0.137824\n",
      "Train Epoch: 3  [14000/60000 (23 %)]\tLoss: 0.066675\n",
      "Train Epoch: 3  [16000/60000 (27 %)]\tLoss: 0.043966\n",
      "Train Epoch: 3  [18000/60000 (30 %)]\tLoss: 0.133389\n",
      "Train Epoch: 3  [20000/60000 (33 %)]\tLoss: 0.155914\n",
      "Train Epoch: 3  [22000/60000 (37 %)]\tLoss: 0.055127\n",
      "Train Epoch: 3  [24000/60000 (40 %)]\tLoss: 0.129153\n",
      "Train Epoch: 3  [26000/60000 (43 %)]\tLoss: 0.053440\n",
      "Train Epoch: 3  [28000/60000 (47 %)]\tLoss: 0.117750\n",
      "Train Epoch: 3  [30000/60000 (50 %)]\tLoss: 0.105782\n",
      "Train Epoch: 3  [32000/60000 (53 %)]\tLoss: 0.093759\n",
      "Train Epoch: 3  [34000/60000 (57 %)]\tLoss: 0.070965\n",
      "Train Epoch: 3  [36000/60000 (60 %)]\tLoss: 0.027628\n",
      "Train Epoch: 3  [38000/60000 (63 %)]\tLoss: 0.086409\n",
      "Train Epoch: 3  [40000/60000 (67 %)]\tLoss: 0.063726\n",
      "Train Epoch: 3  [42000/60000 (70 %)]\tLoss: 0.100173\n",
      "Train Epoch: 3  [44000/60000 (73 %)]\tLoss: 0.090569\n",
      "Train Epoch: 3  [46000/60000 (77 %)]\tLoss: 0.091766\n",
      "Train Epoch: 3  [48000/60000 (80 %)]\tLoss: 0.068429\n",
      "Train Epoch: 3  [50000/60000 (83 %)]\tLoss: 0.123682\n",
      "Train Epoch: 3  [52000/60000 (87 %)]\tLoss: 0.077627\n",
      "Train Epoch: 3  [54000/60000 (90 %)]\tLoss: 0.075024\n",
      "Train Epoch: 3  [56000/60000 (93 %)]\tLoss: 0.089309\n",
      "Train Epoch: 3  [58000/60000 (97 %)]\tLoss: 0.093839\n",
      "Train Epoch: 3  [60000/60000 (100%)]\tLoss: 0.128640\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 4  [0    /60000 (0  %)]\tLoss: 0.068339\n",
      "Train Epoch: 4  [2000 /60000 (3  %)]\tLoss: 0.073307\n",
      "Train Epoch: 4  [4000 /60000 (7  %)]\tLoss: 0.049126\n",
      "Train Epoch: 4  [6000 /60000 (10 %)]\tLoss: 0.068244\n",
      "Train Epoch: 4  [8000 /60000 (13 %)]\tLoss: 0.051781\n",
      "Train Epoch: 4  [10000/60000 (17 %)]\tLoss: 0.108026\n",
      "Train Epoch: 4  [12000/60000 (20 %)]\tLoss: 0.065429\n",
      "Train Epoch: 4  [14000/60000 (23 %)]\tLoss: 0.044954\n",
      "Train Epoch: 4  [16000/60000 (27 %)]\tLoss: 0.055197\n",
      "Train Epoch: 4  [18000/60000 (30 %)]\tLoss: 0.045668\n",
      "Train Epoch: 4  [20000/60000 (33 %)]\tLoss: 0.090360\n",
      "Train Epoch: 4  [22000/60000 (37 %)]\tLoss: 0.062734\n",
      "Train Epoch: 4  [24000/60000 (40 %)]\tLoss: 0.095856\n",
      "Train Epoch: 4  [26000/60000 (43 %)]\tLoss: 0.077042\n",
      "Train Epoch: 4  [28000/60000 (47 %)]\tLoss: 0.042947\n",
      "Train Epoch: 4  [30000/60000 (50 %)]\tLoss: 0.040140\n",
      "Train Epoch: 4  [32000/60000 (53 %)]\tLoss: 0.122044\n",
      "Train Epoch: 4  [34000/60000 (57 %)]\tLoss: 0.053859\n",
      "Train Epoch: 4  [36000/60000 (60 %)]\tLoss: 0.040522\n",
      "Train Epoch: 4  [38000/60000 (63 %)]\tLoss: 0.090548\n",
      "Train Epoch: 4  [40000/60000 (67 %)]\tLoss: 0.057432\n",
      "Train Epoch: 4  [42000/60000 (70 %)]\tLoss: 0.135676\n",
      "Train Epoch: 4  [44000/60000 (73 %)]\tLoss: 0.064054\n",
      "Train Epoch: 4  [46000/60000 (77 %)]\tLoss: 0.065149\n",
      "Train Epoch: 4  [48000/60000 (80 %)]\tLoss: 0.035270\n",
      "Train Epoch: 4  [50000/60000 (83 %)]\tLoss: 0.084200\n",
      "Train Epoch: 4  [52000/60000 (87 %)]\tLoss: 0.051730\n",
      "Train Epoch: 4  [54000/60000 (90 %)]\tLoss: 0.110230\n",
      "Train Epoch: 4  [56000/60000 (93 %)]\tLoss: 0.051659\n",
      "Train Epoch: 4  [58000/60000 (97 %)]\tLoss: 0.061052\n",
      "Train Epoch: 4  [60000/60000 (100%)]\tLoss: 0.070722\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[0.15863898396492004, 0.14775756001472473],\n [0.10963381826877594, 0.10272551327943802],\n [0.08657703548669815, 0.07734762877225876],\n [0.07940352708101273, 0.07293645292520523],\n [0.06758454442024231, 0.06527812033891678]]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_reslut = t_and_v.train_eval(train_loader=train_loader, valid_sets=[(train_X, y_train), (test_X, y_test)])\n",
    "metric_reslut  # 每一轮验证数据集的损失值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}