{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67a87128e70d4826970eb578a3f42c74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 9600\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1200\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1200\n    })\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataset\n",
    "dataset_all = load_dataset(path='seamew/ChnSentiCorp')  # 从Hugging Face\n",
    "dataset_all  # 类型:DatasetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1449e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = dataset_all['train']\n",
    "dataset_train  # 类型:Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1}\n",
      "{'text': ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', '房间太小。其他的都一般。。。。。。。。。'], 'label': [1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 索引\n",
    "print(dataset_train[0])\n",
    "\n",
    "# 切片\n",
    "print(dataset_train[0: 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "6f179e2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-14246461b49d6134.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 未排序的label是乱序的\n",
    "print(dataset_train['label'][:10])\n",
    "\n",
    "# Create a new dataset sorted according to a column.\n",
    "sorted_dataset = dataset_train.sort(column='label')  # 根据`label`进行排序\n",
    "print(sorted_dataset)  # 类型:Dataset\n",
    "print(sorted_dataset['label'][:10])\n",
    "print(sorted_dataset['label'][-10:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0580b95d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached sorted indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-14246461b49d6134.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-468feea96a2c2225.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "sorted_dataset = dataset_train.sort(column='label')\n",
    "\n",
    "# Create a new Dataset where the rows are shuffled.\n",
    "shuffled_dataset = sorted_dataset.shuffle(seed=42)\n",
    "print(shuffled_dataset)  # 类型:Dataset\n",
    "print(shuffled_dataset['label'][:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4b645946",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 6\n})"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataset with rows selected following the list/array of indices.\n",
    "dataset_select = dataset_train.select([0, 10, 20, 30, 40, 50])\n",
    "dataset_select  # 类型:DataSet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "90d50fce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4800\n    })\n})"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_size (:obj:`numpy.random.Generator`, optional): Size of the test split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.\n",
    "    If int, represents the absolute number of test samples.\n",
    "    If None, the value is set to the complement of the train size.\n",
    "    If train_size is also None, it will be set to 0.25.\n",
    "train_size (:obj:`numpy.random.Generator`, optional): Size of the train split\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
    "    If int, represents the absolute number of train samples.\n",
    "    If None, the value is automatically set to the complement of the test size.\n",
    "\"\"\"\n",
    "# Return a dictionary (:obj:`datasets.DatsetDict`) with two random train and test subsets (`train` and `test` ``Dataset`` splits).\n",
    "dataset_train.train_test_split(test_size=0.5)  #  类型:DataSetDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "b7563dea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 2400\n})"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the `index`-nth shard from dataset split into `num_shards` pieces.\n",
    "dataset_train.shard(\n",
    "    # How many shards to split the dataset into.\n",
    "    num_shards=4,\n",
    "    index=1,\n",
    ")  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "71352b68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### rename_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['textA', 'label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename a column in the dataset, and move the features associated to the original column under the new column name.\n",
    "dataset_train.rename_column('text', 'textA')  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "408abc59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### remove_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['label'],\n    num_rows: 9600\n})"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove one or several column(s) in the dataset and the features associated to them.\n",
    "dataset_train.remove_columns(['text'])  # 类型:Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-736176c5ef1ce4f5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2\n",
      "})\n",
      "2 ['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', '选择的事例太离奇了，夸大了心理咨询的现实意义，让人失去了信任感！如果说这样写的效果能在一开始抓住读者的眼球，但是看到案例主人公心理问题的原因解释时就逐渐失去了兴趣，反正有点拣了芝麻丢了西瓜的感觉。']\n"
     ]
    }
   ],
   "source": [
    "def filter_func(data):\n",
    "    return data['text'].startswith('选择')\n",
    "\n",
    "\n",
    "# Apply a filter function to all the elements in the table in batches and update the table so that the dataset only includes examples according to the filter function.\n",
    "start_with_ar = dataset_train.filter(filter_func)\n",
    "print(start_with_ar)  # 类型:Dataset\n",
    "print(len(start_with_ar), start_with_ar['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "252d3de3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85\\cache-f3e1e232b2fa3670.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n",
      "['My sentence: 选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'My sentence: 15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'My sentence: 房间太小。其他的都一般。。。。。。。。。', 'My sentence: 1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'My sentence: 今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。']\n"
     ]
    }
   ],
   "source": [
    "def map_func(data):\n",
    "    data['text'] = 'My sentence: ' + data['text']\n",
    "    return data\n",
    "\n",
    "\n",
    "# Apply a function to all the elements in the table (individually or in batches) and update the table (if function does update examples).\n",
    "datatset_map = dataset_train.map(map_func)\n",
    "print(datatset_map)  # 类型:Dataset\n",
    "print(datatset_map['text'][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0f02e0f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\seamew___chn_senti_corp\\default\\0.0.0\\1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_init = load_dataset(path='seamew/ChnSentiCorp', split='train')\n",
    "print(dataset_init)\n",
    "\n",
    "# Saves a dataset dict to a filesystem using either :class:`~filesystems.S3FileSystem` or ``fsspec.spec.AbstractFileSystem``.\n",
    "dataset_init.save_to_disk(\"dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 9600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loads a dataset that was previously saved using :meth:`Dataset.save_to_disk` from a dataset directory,\n",
    "# or from a filesystem using either :class:`datasets.filesystems.S3FileSystem` or any implementation of ``fsspec.spec.AbstractFileSystem``.\n",
    "dataset_load = load_from_disk(\"dataset\")\n",
    "print(dataset_load)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "de71789e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 导出为其他格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "111dbfe514f042bc8b4b4e120e80b787"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edd5b0273c314a1b9442102451380e17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "3202787"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_csv_kwargs: Parameters to pass to pandas's :func:`pandas.DataFrame.to_csv`\n",
    "dataset_train.to_csv('to_data/data.csv')\n",
    "\n",
    "# to_json_kwargs: Parameters to pass to pandas's `pandas.DataFrame.to_json\n",
    "dataset_train.to_json('to_data/data.json',\n",
    "                      force_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3038a9aff263dc4e\n",
      "Reusing dataset csv (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\csv\\default-3038a9aff263dc4e\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78e4de85bb8d46ab993d95914b5250c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'text', 'label'],\n        num_rows: 9600\n    })\n})"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取单个csv文件\n",
    "load_dataset('csv', data_files='to_data/data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-f061df7ddfdf13ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\csv\\default-f061df7ddfdf13ec\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08e01b74ca2a4df9b2710574f5dfccab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a14e897c257443e5b0eaff35cce73d8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\csv\\default-f061df7ddfdf13ec\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "628c4e1d7c484196a2d171af7a894379"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'text', 'label'],\n        num_rows: 19200\n    })\n})"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取多个csv文件\n",
    "load_dataset('csv', data_files=['to_data/data.csv', 'to_data/data.csv'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-93b712f1277dbbd6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\csv\\default-93b712f1277dbbd6\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05a81387a1b64af492422df814253c5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86c1ac3e38154b8f8a521aed48e72700"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\csv\\default-93b712f1277dbbd6\\0.0.0\\6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bdcd823399845e39d76ceada17fadf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'text', 'label'],\n        num_rows: 19200\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'text', 'label'],\n        num_rows: 9600\n    })\n    valid: Dataset({\n        features: ['Unnamed: 0', 'text', 'label'],\n        num_rows: 9600\n    })\n})"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过字典映射生成训练、测试、验证数据集\n",
    "load_dataset('csv', data_files={'train': ['to_data/data.csv', 'to_data/data.csv'],\n",
    "                                'test': 'to_data/data.csv',\n",
    "                                'valid': 'to_data/data.csv'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-fd60eda23f43650a\n",
      "Reusing dataset json (C:\\Users\\duanm\\.cache\\huggingface\\datasets\\json\\default-fd60eda23f43650a\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e7f795b133c47e1a7b9fc9bc3a2d6a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 9600\n    })\n})"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取单个json文件\n",
    "load_dataset('json', data_files='to_data/data.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a80b7c09aa2bfcb5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\json\\default-a80b7c09aa2bfcb5\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8725a1ed38c427c96e933f529419a34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff9086b51abc4ab29ff78c3987fd950b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\json\\default-a80b7c09aa2bfcb5\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "837a4f79e871460d9ab97d947be12e88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 19200\n    })\n})"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取多个json文件\n",
    "load_dataset('json', data_files=['to_data/data.json', 'to_data/data.json'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2b072cf09a41560a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\json\\default-2b072cf09a41560a\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77cbe2ac462e4d68ba0f0f75f2c901b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe65a5d725e0428284d9c70e62567cd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:\\Users\\duanm\\.cache\\huggingface\\datasets\\json\\default-2b072cf09a41560a\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2b99dfda38848ddb03e120d6da15701"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 19200\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 9600\n    })\n    valid: Dataset({\n        features: ['text', 'label'],\n        num_rows: 9600\n    })\n})"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过字典映射生成训练、测试、验证数据集\n",
    "load_dataset('json', data_files={'train': ['to_data/data.json', 'to_data/data.json'],\n",
    "                                'test': 'to_data/data.json',\n",
    "                                'valid': 'to_data/data.json'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}