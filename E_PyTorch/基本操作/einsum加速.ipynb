{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参考numpy.einsum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(25).reshape(5, 5)\n",
    "A"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(300)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全部元素求和\n",
    "torch.einsum('ij->', A) # \\sum_{i,j} A_{i,j}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(60)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵的迹\n",
    "# \\sum_{i,j} A_{i,i}\n",
    "# 即:\\sum_{i} A_{i,j}\n",
    "torch.einsum('ii->', A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 10,  35,  60,  85, 110])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 某一维度求和\n",
    "# \\sum_j A_{i=0,j}, \\sum_j A_{i=1,j}, \\sum_j A_{i=2,j}, ......\n",
    "torch.einsum('ij->i', A)  # 保留维度i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0,  6, 12, 18, 24])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取对角线\n",
    "# \\sum_{j} A_{i,i}\n",
    "# 即:A_{0,0}, A_{1,1}, A_{2,2}, ......\n",
    "torch.einsum('ii->i', A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0,  5, 10, 15, 20],\n        [ 1,  6, 11, 16, 21],\n        [ 2,  7, 12, 17, 22],\n        [ 3,  8, 13, 18, 23],\n        [ 4,  9, 14, 19, 24]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转置\n",
    "# B_{i,j} = A_{j, i}\n",
    "B = torch.einsum('ij->ji', A)\n",
    "B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor(30)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "y = torch.arange(5)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# 向量内积\n",
    "print(torch.einsum('i,i->', x, y))  # \\sum_i x_i y_i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([[ 0,  0,  0,  0],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 0,  2,  4,  6],\n",
      "        [ 0,  3,  6,  9],\n",
      "        [ 0,  4,  8, 12]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5)\n",
    "y = torch.arange(4)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "# 向量外积\n",
    "c = torch.einsum('i,j->ij', x, y)  # c_{ij} = x_i * y_j\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([0, 1, 2])\n",
      "tensor(42)\n",
      "tensor([ 5, 14, 23])\n",
      "tensor([ 0, 12, 30])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(9).reshape(3, 3)\n",
    "b = torch.arange(3)\n",
    "print(A)\n",
    "print(b)\n",
    "\n",
    "# \\sum_{i,j} A_{i,j} * b_{j}\n",
    "print(torch.einsum('ij,j->', A, b))\n",
    "\n",
    "# \\sum_j A_{i=0,j} * b_j, \\sum_j A_{i=1,j} * b_j, \\sum_j A_{i=2,j} * b_j, ......\n",
    "print(torch.einsum('ij,j->i', A, b))\n",
    "\n",
    "# \\sum_i A_{i,j=0} * b_j, \\sum_i A_{i,j=1} * b_j, \\sum_i A_{i,j=2} * b_j, ......\n",
    "print(torch.einsum('ij,j->j', A, b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "tensor([[10, 13],\n",
      "        [28, 40]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 6).reshape(2, 3)\n",
    "b = torch.arange(0, 6).reshape(3, 2)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 矩阵乘法\n",
    "c = torch.einsum('ik,kj->ij', a, b)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[ 0,  2,  6],\n",
      "        [12, 20, 30]])\n",
      "tensor(70)\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 6).reshape(2, 3)\n",
    "b = torch.arange(1, 7).reshape(2, 3)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 矩阵对应元素相乘\n",
    "c0 = torch.einsum('ij,ij->ij', a, b)\n",
    "print(c0)\n",
    "\n",
    "# 矩阵对应元素相乘并求和\n",
    "c1 = torch.einsum('ij,ij->', a, b)\n",
    "print(c1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "tensor([[[   0,   12,   24],\n",
      "         [  45,   60,   75],\n",
      "         [ 108,  126,  144],\n",
      "         [ 189,  210,  231]],\n",
      "\n",
      "        [[ 576,  624,  672],\n",
      "         [ 765,  816,  867],\n",
      "         [ 972, 1026, 1080],\n",
      "         [1197, 1254, 1311]]])\n"
     ]
    }
   ],
   "source": [
    "ba = torch.arange(0, 24).reshape((2, 3, 4))\n",
    "bb = torch.arange(0, 24).reshape((2, 4, 3))\n",
    "print(ba)\n",
    "\n",
    "# 批量矩阵乘法\n",
    "bc = torch.einsum('bij,bjk->bjk', ba, bb)\n",
    "# bc = torch.einsum('...ij,...jk->...jk', ba, bb)  # 与上等价(前面或后面任意个维度可用 ... 代替)\n",
    "print(bc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 5, 4])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 批量转置\n",
    "ba = torch.arange(0, 120).reshape((2, 3, 4, 5))\n",
    "torch.einsum('...ij->...ji', ba).shape  # 最后两个维度转置\n",
    "# torch.einsum('mnij->mnji', ba)  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([0, 1, 2, 3])\n",
      "\n",
      "tensor([[[ 0,  0,  0,  0],\n",
      "         [ 0,  1,  2,  3],\n",
      "         [ 0,  2,  4,  6]],\n",
      "\n",
      "        [[ 0,  3,  6,  9],\n",
      "         [ 0,  4,  8, 12],\n",
      "         [ 0,  5, 10, 15]]])\n",
      "tensor([[[ 0,  0,  0],\n",
      "         [ 0,  1,  2],\n",
      "         [ 0,  2,  4],\n",
      "         [ 0,  3,  6]],\n",
      "\n",
      "        [[ 0,  0,  0],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  8, 10],\n",
      "         [ 9, 12, 15]]])\n",
      "tensor([[[ 0,  0,  0],\n",
      "         [ 0,  1,  2],\n",
      "         [ 0,  2,  4],\n",
      "         [ 0,  3,  6]],\n",
      "\n",
      "        [[ 0,  0,  0],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  8, 10],\n",
      "         [ 9, 12, 15]]])\n",
      "\n",
      "tensor([[ 0,  6, 12],\n",
      "        [18, 24, 30]])\n",
      "tensor([[ 0,  6, 12],\n",
      "        [18, 24, 30]])\n",
      "\n",
      "tensor([18, 72])\n",
      "tensor([18, 72])\n",
      "\n",
      "tensor(90)\n",
      "tensor(90)\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6).reshape(2, 3)\n",
    "b = torch.arange(4).reshape(4)\n",
    "\n",
    "print(a)\n",
    "print(b, end='\\n\\n')\n",
    "\n",
    "# 1\n",
    "print(torch.einsum('qj,k->qjk', a, b))\n",
    "print(torch.swapaxes(torch.einsum('qj,k->qjk', a, b), 1, 2))\n",
    "print(torch.einsum('qj,k->qkj', a, b), end='\\n\\n')  # 与上等价\n",
    "\n",
    "# 2\n",
    "print(torch.sum(torch.einsum('qj,k->qjk', a, b), dim=-1))\n",
    "print(torch.einsum('qj,k->qj', a, b), end='\\n\\n')  # 与上等价\n",
    "\n",
    "# 3\n",
    "print(torch.sum(torch.einsum('qj,k->qj', a, b), dim=-1))\n",
    "print(torch.einsum('qj,k->q', a, b), end='\\n\\n')  # 与上等价\n",
    "\n",
    "# 4\n",
    "print(torch.sum(torch.einsum('qj,k->q', a, b), dim=-1))\n",
    "print(torch.einsum('qj,k->', a, b))  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 20, 10])\n"
     ]
    }
   ],
   "source": [
    "Q = torch.rand(32, 20, 8, 1)\n",
    "K = torch.rand(32, 10, 1, 8)\n",
    "\n",
    "# 相同部分(n h d)必须满足相等或可广播\n",
    "M = torch.einsum(\"nqhd,nkhd->nhqk\", Q, K)\n",
    "print(M.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}