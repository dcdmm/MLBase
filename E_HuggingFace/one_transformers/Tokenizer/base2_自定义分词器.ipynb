{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from tokenizers import processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28630f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'Ġlove', 'Ġyou', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_m0 = AutoTokenizer.from_pretrained(\"E:\\huggingface_models\\Qwen2.5-0.5B-Instruct\",\n",
    "                                             add_bos_token=False, add_eos_token=False)\n",
    "print(tokenizer_m0(\"i love you!\").tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer(PreTrainedTokenizerFast):  # 必须继承自PreTrainedTokenizerFast\n",
    "    \"\"\"自定义分词器\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        bos_token=\"<|im_start|>\",\n",
    "        add_bos_token=True,\n",
    "        add_eos_token=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            bos_token=bos_token,\n",
    "            add_bos_token=add_bos_token,\n",
    "            add_eos_token=add_eos_token,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._add_bos_token = add_bos_token\n",
    "        self._add_eos_token = add_eos_token\n",
    "        self.update_post_processor()\n",
    "\n",
    "    def update_post_processor(self):\n",
    "        bos = self.bos_token\n",
    "        bos_token_id = self.bos_token_id\n",
    "        if bos is None and self._add_bos_token:\n",
    "            raise ValueError(\"add_bos_token = True but bos_token = None\")\n",
    "\n",
    "        eos = self.eos_token\n",
    "        eos_token_id = self.eos_token_id\n",
    "        if eos is None and self.add_eos_token:\n",
    "            raise ValueError(\"add_eos_token = True but eos_token = None\")\n",
    "\n",
    "        single = f\"{(bos + ':0 ') if self._add_eos_token else ''}$A:0{(' ' + eos + ':0') if self._add_eos_token else ''}\"\n",
    "        pair = f\"{single}{(' ' + bos + ':1') if self._add_bos_token else ''} $B:1{(' ' + eos + ':1') if self._add_eos_token else ''}\"\n",
    "\n",
    "        special_tokens = []\n",
    "        if self._add_bos_token:\n",
    "            special_tokens.append((bos, bos_token_id))\n",
    "        if self._add_eos_token:\n",
    "            special_tokens.append((eos, eos_token_id))\n",
    "        self._tokenizer.post_processor = processors.TemplateProcessing(\n",
    "            single=single, pair=pair, special_tokens=special_tokens\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58dc6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Qwen2Tokenizer'. \n",
      "The class this function is called from is 'CustomTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|im_start|>', 'i', 'Ġlove', 'Ġyou', '!', '<|im_end|>']\n"
     ]
    }
   ],
   "source": [
    "tokenizer_m1 = CustomTokenizer.from_pretrained(\"E:\\huggingface_models\\Qwen2.5-0.5B-Instruct\",\n",
    "                                               add_bos_token=True, add_eos_token=True, bos_token=\"<|im_start|>\")\n",
    "print(tokenizer_m1(\"i love you!\").tokens())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
