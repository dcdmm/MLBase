{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 3])"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)  # a.shape=[5,]\n",
    "b = torch.ones(3)  # b.shape=[3,]\n",
    "c = torch.ones(2)  # c.shape=[2,]\n",
    "\n",
    "'''\n",
    "``pad_sequence`` stacks a list of Tensors along a new dimension,\n",
    "and pads them to equal length. For example, if the input is list of\n",
    "sequences with size ``L x *`` and if batch_first is False, and ``T x B x *``\n",
    "otherwise.\n",
    "\n",
    "`B` is batch size. It is equal to the number of elements in ``sequences``.\n",
    "`T` is length of the longest sequence.\n",
    "`L` is length of the sequence.\n",
    "`*` is any number of trailing dimensions, including none.\n",
    "'''\n",
    "pad_false = pad_sequence([a, b, c])  # 默认batch_first=False\n",
    "pad_false.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.]])"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_false"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 5])"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
    "    ``T x B x *`` otherwise. Default: False.\n",
    "'''\n",
    "pad_true = pad_sequence([a, b, c],\n",
    "                        batch_first=True,  # batch为第一个维度\n",
    "                        padding_value=-999)  # padding_value (float, optional) – value for padded elements. Default: 0.\n",
    "pad_true.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[   1.,    1.,    1.,    1.,    1.],\n        [   1.,    1.,    1., -999., -999.],\n        [   1.,    1., -999., -999., -999.]])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "a1 = torch.tensor([[0, 1, 2, 3],\n",
    "                   [4, 5, 6, 7],\n",
    "                   [8, 9, 10, 11]])  # a1.shape=[3, 4]\n",
    "b1 = torch.tensor([[-1, -2],\n",
    "                   [-3, -4],\n",
    "                   [-5, -6]])  # b1.shape=[3, 2]\n",
    "c1 = torch.tensor([[-11,\n",
    "                    -12,\n",
    "                    -13]])  # c1.shape=[1, 3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 4, 3])"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.transpose(a1, 0, 1).shape=[4, 3]\n",
    "# torch.transpose(b1, 0, 1).shape=[2, 3]\n",
    "# torch.transpose(c1, 0, 1).shape=[3, 1]\n",
    "d1 = pad_sequence([torch.transpose(a1, 0, 1),\n",
    "                   torch.transpose(b1, 0, 1),\n",
    "                   c1,\n",
    "                   torch.transpose(c1, 0, 1)],\n",
    "                  batch_first=True)\n",
    "d1.shape  # 填充第0个维度,其他维度必须相等或可广播"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[ -1,  -2,   0,   0],\n         [ -3,  -4,   0,   0],\n         [ -5,  -6,   0,   0]],\n\n        [[-11,   0,   0,   0],\n         [-12,   0,   0,   0],\n         [-13,   0,   0,   0]],\n\n        [[-11, -12, -13,   0],\n         [-11, -12, -13,   0],\n         [-11, -12, -13,   0]]])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(d1, 1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[  0,   1,   2,   3],\n         [  4,   5,   6,   7],\n         [  8,   9,  10,  11]],\n\n        [[ -1,  -2,   0,   0],\n         [ -3,  -4,   0,   0],\n         [ -5,  -6,   0,   0]],\n\n        [[-11,   0,   0,   0],\n         [-12,   0,   0,   0],\n         [-13,   0,   0,   0]],\n\n        [[-11, -12, -13,   0],\n         [-11, -12, -13,   0],\n         [-11, -12, -13,   0]]])"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(pad_sequence([torch.transpose(a1, 0, 1),\n",
    "                              torch.transpose(b1, 0, 1),\n",
    "                              c1,\n",
    "                              torch.broadcast_to(torch.transpose(c1, 0, 1), (3, 3))],\n",
    "                             batch_first=True), 1, 2)  # 与上等价"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}