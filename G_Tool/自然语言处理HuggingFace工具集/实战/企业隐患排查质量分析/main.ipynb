{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02300F1794034C63B6064796B7B5C927",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## 基于文本挖掘的企业隐患排查质量分析模型\n",
    "\n",
    "### 赛题背景\n",
    "企业自主填报安全生产隐患,对于将风险消除在事故萌芽阶段具有重要意义.企业在填报隐患时,往往存在不认真填报的情况,“虚报、假报”隐患内容,增大了企业监管的难度.\n",
    "采用大数据手段分析隐患内容,找出不切实履行主体责任的企业,向监管部门进行推送,实现精准执法,能够提高监管手段的有效性,增强企业安全责任意识\n",
    "\n",
    "### 数据说明\n",
    "\n",
    "训练集数据包含\"id、level_1（一级标准）、level_2（二级标准）、level_3（三级标准）、level_4（四级标准）、content（隐患内容）和label（标签）”共7个字段.\n",
    "其中“id”为主键,无业务意义;“一级标准、二级标准、三级标准、四级标准”为《深圳市安全隐患自查和巡查基本指引（2016年修订版）》规定的排查指引,一级标准对应不同隐患类型,\n",
    "二至四级标准是对一级标准的细化,企业自主上报隐患时,根据不同类型隐患的四级标准开展隐患自查工作;“隐患内容”为企业上报的具体隐患;“标签”标识的是该条隐患的合格性,\n",
    "“1”表示隐患填报不合格,“0”表示隐患填报合格."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B88590A13F5A42D58654435B041F0EDC",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6568FF9040D54AA98B9BB8D2A4192775",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"PyTorch随机数种子设置大全\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)  # CPU上设置随机种子\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # 当前GPU上设置随机种子\n",
    "        # torch.cuda.manual_seed_all(seed) # 所有GPU上设置随机种子\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "id": "568D068121B7450F8C815FABFA7AD65B",
    "notebookId": "62414cd806764100170aaf30",
    "jupyter": {},
    "tags": [],
    "slideshow": {
     "slide_type": "slide"
    },
    "trusted": true
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape= (12000, 7)\n",
      "test.shape= (18000, 6)\n",
      "sub.shape= (18000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')  # 训练数据集\n",
    "test = pd.read_csv('data/test.csv')  # 测试数据集\n",
    "sub = pd.read_csv('data/sub.csv')  # 提交结果样例\n",
    "\n",
    "print('train.shape=', train.shape)\n",
    "print('test.shape=', test.shape)\n",
    "print('sub.shape=', sub.shape)"
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1377ED12D9A14D798ED163867EF80105",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id            level_1  level_2           level_3  \\\n0   0  工业/危化品类（现场）—2016版  （二）电气安全  6、移动用电产品、电动工具及照明   \n1   1  工业/危化品类（现场）—2016版  （一）消防检查            1、防火巡查   \n2   2  工业/危化品类（现场）—2016版  （一）消防检查            2、防火检查   \n\n                                             level_4  \\\n0  1、移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。   \n1                           3、消防设施、器材和消防安全标志是否在位、完整；   \n2                           6、重点工种人员以及其他员工消防知识的掌握情况；   \n\n                      content  label  \n0  使用移动手动电动工具,外接线绝缘皮破损,应停止使用.      0  \n1                          一般      1  \n2                     消防知识要加强      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>level_1</th>\n      <th>level_2</th>\n      <th>level_3</th>\n      <th>level_4</th>\n      <th>content</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（二）电气安全</td>\n      <td>6、移动用电产品、电动工具及照明</td>\n      <td>1、移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>\n      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>一般</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>2、防火检查</td>\n      <td>6、重点工种人员以及其他员工消防知识的掌握情况；</td>\n      <td>消防知识要加强</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3317610F2D0541E79076B303E08398B9",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       12000 non-null  int64 \n",
      " 1   level_1  12000 non-null  object\n",
      " 2   level_2  12000 non-null  object\n",
      " 3   level_3  12000 non-null  object\n",
      " 4   level_4  12000 non-null  object\n",
      " 5   content  11998 non-null  object\n",
      " 6   label    12000 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 656.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id            level_1  level_2 level_3  \\\n6193  6193  工业/危化品类（现场）—2016版  （一）消防检查  1、防火巡查   \n9248  9248  工业/危化品类（现场）—2016版  （一）消防检查  1、防火巡查   \n\n                                level_4 content  label  \n6193           3、消防设施、器材和消防安全标志是否在位、完整；     NaN      1  \n9248  4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；     NaN      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>level_1</th>\n      <th>level_2</th>\n      <th>level_3</th>\n      <th>level_4</th>\n      <th>content</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6193</th>\n      <td>6193</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9248</th>\n      <td>9248</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>4、常闭式防火门是否处于关闭状态，防火卷帘下是否堆放物品影响使用；</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info()  # content列缺失值数为2\n",
    "\n",
    "train[train['content'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "398319F049244103831D4A60C0D86D5B",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       18000 non-null  int64 \n",
      " 1   level_1  18000 non-null  object\n",
      " 2   level_2  18000 non-null  object\n",
      " 3   level_3  18000 non-null  object\n",
      " 4   level_4  18000 non-null  object\n",
      " 5   content  17996 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 843.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "          id             level_1  level_2 level_3  \\\n970      970   工业/危化品类（现场）—2016版  （一）消防检查  1、防火巡查   \n13006  13006   工业/危化品类（现场）—2016版  （一）消防检查  1、防火巡查   \n16845  16845   工业/危化品类（现场）—2016版  （一）消防检查  1、防火巡查   \n17742  17742  商贸服务教文卫类（现场）—2016版  （二）电气安全   1、配电房   \n\n                                                 level_4 content  \n970                             3、消防设施、器材和消防安全标志是否在位、完整；     NaN  \n13006                           3、消防设施、器材和消防安全标志是否在位、完整；     NaN  \n16845                           3、消防设施、器材和消防安全标志是否在位、完整；     NaN  \n17742  2、配电房内电缆线应放置在电缆沟内，并应加设盖板。配电柜前后面应放置绝缘垫，其绝缘垫的长度应...     NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>level_1</th>\n      <th>level_2</th>\n      <th>level_3</th>\n      <th>level_4</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>970</th>\n      <td>970</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13006</th>\n      <td>13006</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16845</th>\n      <td>16845</td>\n      <td>工业/危化品类（现场）—2016版</td>\n      <td>（一）消防检查</td>\n      <td>1、防火巡查</td>\n      <td>3、消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17742</th>\n      <td>17742</td>\n      <td>商贸服务教文卫类（现场）—2016版</td>\n      <td>（二）电气安全</td>\n      <td>1、配电房</td>\n      <td>2、配电房内电缆线应放置在电缆沟内，并应加设盖板。配电柜前后面应放置绝缘垫，其绝缘垫的长度应...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.info()  # content列缺失值数为4\n",
    "test[test['content'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "02470A0A5E854686B39D79EF0D244BE6",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10712\n",
      "1     1288\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'label count')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train['label'].value_counts())\n",
    "\n",
    "sns.countplot(data=train, x='label')\n",
    "plt.xlabel('label count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "031146057A934C7D840591C8447CBA30",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 缺失值填充\n",
    "train['content'] = train['content'].fillna('空值')\n",
    "test['content'] = test['content'].fillna('空值')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "98768A238FC94EB38C8CD8BC320B6AD1",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 同质部分去除\n",
    "train['level_1'] = train['level_1'].apply(lambda x: x.split('（')[0])\n",
    "train['level_2'] = train['level_2'].apply(lambda x: x.split('）')[-1])\n",
    "train['level_3'] = train['level_3'].apply(lambda x: re.split(r'[0-9]、', x)[-1])\n",
    "train['level_4'] = train['level_4'].apply(lambda x: re.split(r'[0-9]、', x)[-1])\n",
    "\n",
    "test['level_1'] = test['level_1'].apply(lambda x: x.split('（')[0])\n",
    "test['level_2'] = test['level_2'].apply(lambda x: x.split('）')[-1])\n",
    "test['level_3'] = test['level_3'].apply(lambda x: re.split(r'[0-9]、', x)[-1])\n",
    "test['level_4'] = test['level_4'].apply(lambda x: re.split(r'[0-9]、', x)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7BF549DA95F441E7A90700934FF1CE35",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id  level_1 level_2         level_3  \\\n0   0  工业/危化品类    电气安全  移动用电产品、电动工具及照明   \n1   1  工业/危化品类    消防检查            防火巡查   \n2   2  工业/危化品类    消防检查            防火检查   \n\n                                           level_4  \\\n0  移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。   \n1                           消防设施、器材和消防安全标志是否在位、完整；   \n2                           重点工种人员以及其他员工消防知识的掌握情况；   \n\n                      content  label  \n0  使用移动手动电动工具,外接线绝缘皮破损,应停止使用.      0  \n1                          一般      1  \n2                     消防知识要加强      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>level_1</th>\n      <th>level_2</th>\n      <th>level_3</th>\n      <th>level_4</th>\n      <th>content</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>工业/危化品类</td>\n      <td>电气安全</td>\n      <td>移动用电产品、电动工具及照明</td>\n      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>\n      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>工业/危化品类</td>\n      <td>消防检查</td>\n      <td>防火巡查</td>\n      <td>消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>一般</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>工业/危化品类</td>\n      <td>消防检查</td>\n      <td>防火检查</td>\n      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>\n      <td>消防知识要加强</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EF0B46777C3B42E9822C85A9AB73C60C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['text'] = train['content'] + '[SEP]' + train['level_1'] + '[SEP]' + train['level_2'] + '[SEP]' + train[\n",
    "    'level_3'] + '[SEP]' + train['level_4']\n",
    "test['text'] = test['content'] + '[SEP]' + test['level_1'] + '[SEP]' + test['level_2'] + '[SEP]' + test[\n",
    "    'level_3'] + '[SEP]' + test['level_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CA7737C77F784DF48F11590B18115615",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id  level_1 level_2         level_3  \\\n0   0  工业/危化品类    电气安全  移动用电产品、电动工具及照明   \n1   1  工业/危化品类    消防检查            防火巡查   \n2   2  工业/危化品类    消防检查            防火检查   \n\n                                           level_4  \\\n0  移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。   \n1                           消防设施、器材和消防安全标志是否在位、完整；   \n2                           重点工种人员以及其他员工消防知识的掌握情况；   \n\n                      content  label  \\\n0  使用移动手动电动工具,外接线绝缘皮破损,应停止使用.      0   \n1                          一般      1   \n2                     消防知识要加强      0   \n\n                                                text  \n0  使用移动手动电动工具,外接线绝缘皮破损,应停止使用.[SEP]工业/危化品类[SEP]电气安...  \n1  一般[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]消防设施、器材和消...  \n2  消防知识要加强[SEP]工业/危化品类[SEP]消防检查[SEP]防火检查[SEP]重点工种...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>level_1</th>\n      <th>level_2</th>\n      <th>level_3</th>\n      <th>level_4</th>\n      <th>content</th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>工业/危化品类</td>\n      <td>电气安全</td>\n      <td>移动用电产品、电动工具及照明</td>\n      <td>移动使用的用电产品和I类电动工具的绝缘线，必须采用三芯(单相)或四芯(三相)多股铜芯橡套软线。</td>\n      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.</td>\n      <td>0</td>\n      <td>使用移动手动电动工具,外接线绝缘皮破损,应停止使用.[SEP]工业/危化品类[SEP]电气安...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>工业/危化品类</td>\n      <td>消防检查</td>\n      <td>防火巡查</td>\n      <td>消防设施、器材和消防安全标志是否在位、完整；</td>\n      <td>一般</td>\n      <td>1</td>\n      <td>一般[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]消防设施、器材和消...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>工业/危化品类</td>\n      <td>消防检查</td>\n      <td>防火检查</td>\n      <td>重点工种人员以及其他员工消防知识的掌握情况；</td>\n      <td>消防知识要加强</td>\n      <td>0</td>\n      <td>消防知识要加强[SEP]工业/危化品类[SEP]消防检查[SEP]防火检查[SEP]重点工种...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E576107EFDE74A06803DD16968E7D8DD",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train['text_len'] = train['text'].map(len)\n",
    "test['text_len'] = test['text'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2C3B56F9DDFC4F748A5D5A610A67011C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    12000.000000\nmean        80.439833\nstd         21.913662\nmin         43.000000\n25%         66.000000\n50%         75.000000\n75%         92.000000\nmax        298.000000\nName: text_len, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "605DA118577C49BA88C1ED1210C905BC",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    18000.000000\nmean        80.762611\nstd         22.719823\nmin         43.000000\n25%         66.000000\n50%         76.000000\n75%         92.000000\nmax        520.000000\nName: text_len, dtype: float64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2F126F17400546E4B3B1C07EC3BAA4C4",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1b136913130>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x360 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAE9CAYAAABTFKyvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABHzElEQVR4nO3deXxU9b3/8dcnk4WEhADZCAkhYRFZRGRzxV2g1Wpva+t61eqv2p9Lt1t7sYutrVVb+6utVdurVm1drlaslbpUWve6EhZlhwABErYQSEgg+3x/f8yBhhjIAJk5k8n7+Xic5syZ7/me94RTk0/OOd+vOecQERERERGR3ifB7wAiIiIiIiLiDxWEIiIiIiIivZQKQhERERERkV5KBaGIiIiIiEgvpYJQRERERESkl1JBKCIiIiIi0ksl+h0gGrKzs11xcbHfMURERERERHwxf/787c65nI7be0VBWFxcTGlpqd8xREREREREfGFm6zvbrltGRUREREREeikVhCIiIiIiIr2UCkIREREREZFeqlc8QygiIiIiIt2jpaWFiooKGhsb/Y4inejTpw+FhYUkJSWF1V4FoYiIiIiIhK2iooKMjAyKi4sxM7/jSDvOOaqrq6moqKCkpCSsfXTLqIiIiIiIhK2xsZGsrCwVgzHIzMjKyjqkq7cqCEVERERE5JCoGIxdh/pvo4JQRERERESkl1JBKCIiIiIih6+oCMy6bykq6vKQNTU1PPDAA4cc9bOf/Sw1NTWHvN9jjz3Gpk2bDnm/ve64444u26Snpx92/0dCg8qIiIiIiMjh27gR3nij+/o744wum+wtCK+//vr9tre2tpKYeOAS5+WXXz6sSI899hjjxo1j8ODBh7X/HXfcwfe+973D2jfSdIVQeqZg0O8EIiIiIuKTWbNmsWbNGiZMmMCUKVOYNm0a559/PmPGjAHg85//PJMmTWLs2LE8+OCD+/YrLi5m+/btlJeXM3r0aL761a8yduxYpk+fTkNDQ6fHmj17NqWlpVx22WVMmDCBhoYG5s+fz2mnncakSZOYMWMGmzdvpra2llGjRrFy5UoALrnkEh566CFmzZpFQ0MDEyZM4LLLLgvr8919991MmTKF8ePH86Mf/QjgkDIfChWE0vM4ByefDN/9bmhdRERERHqVu+66i+HDh7No0SLuvvtuFixYwG9+8xtWrVoFwCOPPML8+fMpLS3l3nvvpbq6+lN9rF69mhtuuIGlS5fSv39/nnvuuU6PdeGFFzJ58mSefPJJFi1aRGJiIjfddBOzZ89m/vz5XH311Xz/+98nMzOT++67j6uuuoqnn36anTt38tWvfpW77rqL1NRUFi1axJNPPtnlZ5s7dy6rV6/mo48+YtGiRcyfP5+33377kDIfCt0yKj3Phx+yY0M9a59Zw2SbBXfdFbrfXERERER6palTp+437969997L888/D8DGjRtZvXo1WVlZ++1TUlLChAkTAJg0aRLl5eVhHWvlypUsWbKEc845B4C2tjby8/MBOOecc3j22We54YYb+Pjjjw/rs8ydO5e5c+dy3HHHAVBfX8/q1aspKio67MwHo4JQep577+XX+T/n4bVnsv4vE0kaPhyuvdbvVCIiIiLik759++5bf/PNN/nnP//J+++/T1paGqeffnqn8/KlpKTsWw8EAmHffumcY+zYsbz//vufei8YDLJ8+XLS0tLYuXMnhYWFh/xZnHPccsstXHfddfttLy8vP+zMB6NbRqVn2bYNXnqJZ7dMoyWYwPMTboMXXvA7lYiIiIhEUUZGBnV1dZ2+V1tby4ABA0hLS2PFihV88MEH3Xq8UaNGUVVVta8gbGlpYenSpQDcc889jB49mqeeeoqvfOUrtLS0AJCUlLRvvSszZszgkUceob6+HoDKykq2bdt2xJ/hQHSFUHqWhx9mxcRL2bEohesv2MSvPziDL2//WuhZQt02KiIiIhJ9Q4aENTLoIfXXhaysLE4++WTGjRtHamoqeXl5+96bOXMmv//97xk9ejSjRo3ihBNOOOJIV111FV/72tdITU3l/fffZ/bs2Xz961+ntraW1tZWvvnNb5KYmMjDDz/MRx99REZGBqeeeiq33347t912G9deey3jx49n4sSJXT5HOH36dJYvX86JJ54IhKajeOKJJwgEAkf8OTpjrhcMyjF58mRXWlrqdww5Us7B0KHcftxsFtaUcP35lVx+x2heSjifie/+Fo46yu+EIiIiInFv+fLljB492u8YchCd/RuZ2Xzn3OSObXXLqPQcGzdCQwPPLhnDtGNqCATgcydW85uk78B77/mdTkRERESkx1FBKD1HaSlri8+gcnsKxwzbDcC5J1Tz/PZpVM1d6HM4EREREenpbrjhBiZMmLDf8uijj3Zb/9XV1Z/qf8KECZ1OixEteoZQeo7SUmYHv8jJ42oIeH/KyExv47Sjt/LgP0r4vr/pRERERKSHu//++yPaf1ZWFosWLYroMQ6VrhBKz/Hhhzy7dRrTxtfut/mCs3dzf/VFtFTV+JNLRERERKSHUkEoPYNzbJy/jbKabCaMqN/vrRFFzeSn1vL8PeX+ZBMRERER6aFUEErPsH49f2k9n5PG1ZHYyYi7M0tW8KdnU6OfS0RERESkB1NBKD3D/Pk8k3AxpxxT2+nbI44KsKqyb5RDiYiIiIj0bCoIpUfY8sZyljYOZ9Kouk7fzx+RxoaGHNraohxMREREpJcrKgKz7luKiro+Zk1NDQ888MBh5f31r3/Nnj17DtrmjjvuOKy+AcrLy3nqqacO2ubNN9/kvPPOO+xjdCeNMio9wtzXA0wp2kZyouv0/T55/elPDRVrBzB0ZHKU04mIiIj0Xhs3whtvdF9/Z5zRdZu9BeH1119/yP3/+te/5vLLLyctLe2Abe644w6+973vHXLf8O+C8NJLLz2s/aNNVwgl9jnHx2vSKSkOHrhNIEBh0lbWvLc1erlERERExBezZs1izZo1TJgwgZtvvpm7776bKVOmMH78eH70ox8BsHv3bs4991yOPfZYxo0bxzPPPMO9997Lpk2bOOOMMzjjAJXnrFmzaGhoYMKECVx22WUAPPHEE0ydOpUJEyZw3XXX0dbWxrx58xg/fjyNjY3s3r2bsWPHsmTJEmbNmsU777zDhAkTuOeee7r8LLt37+bqq69m6tSpHHfccbzwwgsAPPbYY3zhC19g5syZjBw5ku9+97vd9N3bX0SvEJrZTOA3QAB42Dl3V4f3U4A/AZOAauAi51y5mZ0D3AUkA83Azc6517193gTygQavm+nOuW2R/Bzis/JyPnHHcEbxwZsNTq+lbB6ceeWQqMQSEREREX/cddddLFmyhEWLFjF37lxmz57NRx99hHOO888/n7fffpuqqioGDx7MSy+9BEBtbS2ZmZn86le/4o033iA7O/uAfd9333375gtcvnw5zzzzDO+++y5JSUlcf/31PPnkk1xxxRWcf/75/OAHP6ChoYHLL7+ccePGcdddd/HLX/6SF198MazP8rOf/YwzzzyTRx55hJqaGqZOncrZZ58NwKJFi1i4cCEpKSmMGjWKm266iSFDuvd33YgVhGYWAO4HzgEqgHlmNsc5t6xds2uAnc65EWZ2MfBz4CJgO/A559wmMxsHvAoUtNvvMudcaaSyS4xZtoxlTOXq/KqDNhuU2cjqpRppVERERKQ3mTt3LnPnzuW4444DoL6+ntWrVzNt2jT+67/+i//+7//mvPPOY9q0aYfV/2uvvcb8+fOZMmUKAA0NDeTm5gJw6623MmXKFPr06cO999572PnnzJnDL3/5SwAaGxvZsGEDAGeddRaZmZkAjBkzhvXr1/ecghCYCpQ559YCmNnTwAVA+4LwAuDH3vps4D4zM+fcwnZtlgKpZpbinGuKYF6JUbUL11ITPJu8AZUHbTc4p5kF65KilEpEREREYoFzjltuuYXrrrvuU+8tWLCAl19+mR/84AecddZZ3HrrrYfV/5VXXsmdd975qfeqq6upr6+npaWFxsZG+vY99FHvnXM899xzjBo1ar/tH374ISkpKfteBwIBWltbD7n/rkTyGcICYGO71xXsf5VvvzbOuVagFsjq0OaLwIIOxeCjZrbIzH5oZtbZwc3sWjMrNbPSqqqDX1mS2Lb0/V2U9N9BQhdna0FhAmuqMqMTSkRERER8k5GRQV1daPT5GTNm8Mgjj1BfXw9AZWUl27ZtY9OmTaSlpXH55Zdz8803s2DBgk/teyBJSUm0tLQAoat0s2fPZtu20FNqO3bsYP369QBcd911/PSnP+Wyyy7jv//7v8Puv70ZM2bw29/+FudCgycuXLiwiz26V0yPMmpmYwndRjq93ebLnHOVZpYBPAf8J6HnEPfjnHsQeBBg8uTJnQ9NKT3CkuUBivMaumw3uCSZdQ15OBcaslhEREREIm/IkPBGBj2U/rqSlZXFySefzLhx4/jMZz7DpZdeyoknnghAeno6TzzxBGVlZdx8880kJCSQlJTE7373OwCuvfZaZs6cyeDBg3njAMOjXnvttYwfP56JEyfy5JNPcvvttzN9+nSCwSBJSUncf//9vPXWWyQlJXHppZfS1tbGSSedxOuvv860adMIBAIce+yxXHXVVXzrW9866Gf54Q9/yDe/+U3Gjx9PMBikpKQk7OcPu4PtrUS7vWOzE4EfO+dmeK9vAXDO3dmuzatem/fNLBHYAuQ455yZFQKvA19xzr17gGNcBUx2zt14sCyTJ092paV65LCnuqnPg7SddhZf/kwXf2lpbeXCm0tYXJ5B/lBNPSEiIiISCcuXL2f06NF+x5CD6OzfyMzmO+cmd2wbyVtG5wEjzazEzJKBi4E5HdrMAa701i8EXveKwf7AS8Cs9sWgmSWaWba3ngScByyJ4GcQv23fzietYyguDuMPF4mJFCZtoexdTT0hIiIiIhKOiN0y6pxrNbMbCY0QGgAecc4tNbOfAKXOuTnAH4DHzawM2EGoaAS4ERgB3Gpme5/8nA7sBl71isEA8E/goUh9BokBK1eyjLHcmL8prOaD02opm9fGtEs19YSIiIiIHNzxxx9PU9P+41Y+/vjjHHPMMd3S/6uvvrrv2cK9SkpKeP7557ul/+4Q0WcInXMvAy932HZru/VG4Eud7Hc7cPsBup3UnRkltlXNK6eJ48jObAmr/aDMBlYvielHY0VEREQkRnz44YcR7X/GjBnMmDEjosc4UpG8ZVTkiC19r5bh/beHPUjM4JwWVq3V1BMiIiIikRSpcUjkyB3qv40KQolpS5bA0JyuRxjdq6AAVm/rF8FEIiIiIr1bnz59qK6uVlEYg5xzVFdX06dPn7D30b11EtMWV/Sn6Phg2O0LSpJZt1tTT4iIiIhESmFhIRUVFWiu79jUp08fCgsLw26vglBiV1MTn9QP48sjwr+Q3a8ggwTXRvW2NrLzAhEMJyIiItI7JSUlUVJS4ncM6Sa6ZVRilltdxnIbQ0lBc/g7JSVRGNhE2YfVkQsmIiIiIhInVBBKzNr8fjmBBEf/9LZD2m9w6k7K5tdEJpSIiIiISBxRQSgxa8l7uxjWb/sh7zcovZ7VSw7hqqKIiIiISC+lglBi1tLFQYZm7T7k/Qb338OqMp3aIiIiIiJd0W/NErM+Xp9J0eDwJqRvryC3hdWb+kYgkYiIiIhIfFFBKDFr8c5CSkYc+kihBQWwrnZABBKJiIiIiMQXFYQSk4LVO1nZNpKSYYd+ig7IT6WpNZGamu7PJSIiIiIST1QQSkza8M56MgJ7SE8Lf1L6vWzgAIZYBWvWRCCYiIiIiEgcUUEoMWnJOzspSd92eDunpZHPJso+2dO9oURERERE4owKQolJyxY1M2RA/eHtbEZ+ai1lC+u6N5SIiIiISJxRQSgxaXFZKkV5hz+X4OB+9axceugjlIqIiIiI9CYqCCUmLduWzdCh7rD3HzSwmXXrD32EUhERERGR3kQFocQcF3Ssaixi6FEph91HdlaQTduTuzGViIiIiEj8SfQ7gEhHFQurSDUjI+vwC8KcvACb69NxDsy6MZyIiIiISBzRFUKJOcve2Epxny1H1EdabjoJro3a2m4KJSIiIiISh1QQSsxZXrqbIf2OsJIbOJA8q6KysnsyiYiIiIjEIxWEEnMWL0ugKLvhyDrJzCQ7uJXKDW3dE0pEREREJA6pIJSYs3RjP4YWHmEhFwiQlbSLyiU7uyeUiIiIiEgcUkEoMcU5WLFrMEOHH/l4RwPTGqlctbsbUomIiIiIxCcVhBJTtm1qxYJt9C/qd8R9ZWU0s3GtJqcXERERETkQFYQSU5a9sZWSxAos5cjnEMzp18zGSs05ISIiIiJyICoIJaYse3cHRRnd89xfdjZUbj/8uQxFREREROKdCkKJKUs/bqNwYPc895eda2yuy+iWvkRERERE4pEKQokpS9amMjS/uVv6GjAohZrmNJq7pzsRERERkbijglBiyorqXIqLu+e5v0DWAAbaTjZv7pbuRERERETijgpCiRk7dsCe1mSyhx35CKMApKeT47ZRuU6XCEVEREREOqOCUGLG8nn1lFg51j+zezoMBMhOrqVyqSanFxERERHpjApCiRnL3qqiKK0KrPumihiY2kDlivpu609EREREJJ6oIJSYsWR+I0P6d2/xltW3iYo1Td3ap4iIiIhIvFBBKDFjycpkhuY2dGuf2ZnNbKzQ5PQiIiIiIp1RQSgxY8XW/gwtct3aZ/bAIBVVyd3ap4iIiIhIvFBBKDFh1y7Y0dSXvJLUbu03Jy+BTbV9u7VPEREREZF4oYJQYsKKJa0Us57AoNxu7Td7cDKbGwfguvfCo4iIiIhIXFBBKDFh2VtVFCVvgZSUbu03NSeDZNfMTs08ISIiIiLyKREtCM1sppmtNLMyM5vVyfspZvaM9/6HZlbsbT/HzOab2WLv65nt9pnkbS8zs3vNunGOAvHNwn/VUzygtvs7Tk8nl21Urmns/r5FRERERHq4iBWEZhYA7gc+A4wBLjGzMR2aXQPsdM6NAO4Bfu5t3w58zjl3DHAl8Hi7fX4HfBUY6S0zI/UZJHoWLklm+KDd3d9xQgLZSTVULt7R/X2LiIiIiPRwkbxCOBUoc86tdc41A08DF3RocwHwR299NnCWmZlzbqFzbpO3fSmQ6l1NzAf6Oec+cM454E/A5yP4GSQKnIPFm7MYPiwYkf6zU/dQuXxXRPoWEREREenJIlkQFgAb272u8LZ12sY51wrUAlkd2nwRWOCca/LaV3TRp/QwlZWQ0NbKwJL+Eel/QN8m3TIqIiIiItKJRL8DHIyZjSV0G+n0w9j3WuBagKKiom5OJt3p49IWRrpVWF73jjC6V3a/Ztav1zCjIiIiIiIdRfIKYSUwpN3rQm9bp23MLBHIBKq914XA88AVzrk17doXdtEnAM65B51zk51zk3Nyco7wo0gkLXpjB8WpWyApKSL9Zw8IUrE1Mn2LiIiIiPRkkSwI5wEjzazEzJKBi4E5HdrMITRoDMCFwOvOOWdm/YGXgFnOuXf3NnbObQZ2mdkJ3uiiVwAvRPAzSBQs/KCZYVmRe8YvO9fYVKPJ6UVEREREOopYQeg9E3gj8CqwHPizc26pmf3EzM73mv0ByDKzMuDbwN6pKW4ERgC3mtkib9l7P+H1wMNAGbAGeCVSn0Gi4+PVaQwvjNwzfjkFKWxqGBCx/kVEREREeqqIPkPonHsZeLnDtlvbrTcCX+pkv9uB2w/QZykwrnuTil/27IGNtRkUlUTuVOw/qA91wb40NXX7vPciIiIiIj1aRCemF+nKkiVQHKggqTAvYsdIyOhLNtvZtKo+YscQEREREemJVBCKrz4ubWFY6yqI5MA/ZuQk1VC5qCpyxxARERER6YFUEIqvFr6xk5KMKkiM7Awo2an1VC6rjegxRERERER6GhWE4quFCxzDB0d+0viBaZqcXkRERESkIxWE4hvnYOnGTIYPC0b8WAP7tbBxfVvEjyMiIiIi0pOoIBTflJdDmttN5vAIPj/oyR7QRsUWTU4vIiIiItKeCkLxzcfzWxkRXAkFBRE/Vk6usXGnJqcXEREREWlPBaH4ZtHr1RSnbo3K5IA5+Yls2qPJ6UVERERE2lNBKL5Z8H4Tw/J2R+VY2UNS2dqWTbDNReV4IiIiIiI9gQpC8c0na/oyYmhrVI6Vkp5MGrvZvmpHVI4nIiIiItITqCAUX+zaBdt296VgVPSe68tNqqFiwbaoHU9EREREJNapIBRfLF7UxjC3hkBRYdSOmZNap8npRURERETaUUEovljwahUjUiogNTVqx8xOa6CiTJPTi4iIiIjspYJQfPHG35sYm7c9qscc2K+Fig2anF5EREREZC8VhBJ1zsE7SwcyfnRzVI+bPTDIhk2JUT2miIiIiEgs67IgNLOjzOw1M1vivR5vZj+IfDSJV6tWQXLrbvKOyYvqcbNzEti4Iz2qxxQRERERiWXhXCF8CLgFaAFwzn0CXBzJUBLf3p5Tw3hbDIMGRfW4OYOT2NSgyelFRERERPYKpyBMc8591GFbdCaPk7j0xl9rGZe3HRKie8dyTmEym9pyoTm6t6qKiIiIiMSqcH4j325mwwEHYGYXApsjmkri2tsf92P8qOiP9tm3r+EsgV3LKqJ+bBERERGRWBROQXgD8D/A0WZWCXwT+L+RDCXxa/16aGp0FI7PivqxzSAvaScVC6uifmwRERERkVjU5ZCLzrm1wNlm1hdIcM7VRT6WxKu3XqrjWLcIKyzw5fg5qXVULK1ljC9HFxERERGJLQcsCM3s2wfYDoBz7lcRyiRx7M3ndjA2ZxsEBvpy/Ky+jVSu3uPLsUVEREREYs3BrhBmRC2F9Bpvlfbl++MbfDt+VmabJqcXEREREfEcsCB0zt0WzSAS/zZvcuyoS6L4xOhON9FeVpZjQ1myb8cXEREREYkl4UxMP8zM/mZmVWa2zcxeMLNh0Qgn8eWdP61jfPJyEvL9Kwhz8hLYWNPPt+OLiIiIiMSScEYZfQr4M5APDAaeBf43kqEkPr35bBVjh9SFhvv0SU5BMhVN2RAM+pZBRERERCRWhDsx/ePOuVZveQLoE+lgEn/eXJLN+EldDmwbUdnZsJl82LLF1xwiIiIiIrEgnILwFTObZWbFZjbUzL4LvGxmA83Mn6Eipcep/mgNG1vyGDkp09cc/fu2Uk86jas3+ppDRERERCQWhHO55sve1+s6bL8YcICeJ5QuvXPfxxzTfwyBpHD+BhE5CQmQnbSLTR9XMew0X6OIiIiIiPgunInpS6IRROLbX15MZuLRewjvonRk5abVUbFsl/6SISIiIiK9XpcFoZkFgHOB4vbtNTG9hKvpw0XMqZnGw2evB/wfzCU7o4mKska/Y4iIiIiI+C6cW0b/BjQCi4mF3+alx/n7D99lxMBMsgfGxukzMLONyo2xkUVERERExE/hFISFzrnxEU8i8amujiffyOfUmS1+J9knO9vY8LEGyhURERERCXeU0ekRTyJxafdjz/Kqm8Fpxzf5HWWf7EGJbKzNBOf8jiIiIiIi4qtwCsIPgOfNrMHMdplZnZntinQwiQ9/++VKxhbsJDO9ze8o++TkQgWFsH2731FERERERHwVTkH4K+BEQhPU93POZTjn+kU4l8SDefN4cuvZnHpi7NwuCpDTv4VNVgDr1vkdRURERETEV+EUhBuBJc7p/jo5NDX3PMpbwWmccmyd31H2k9Wvhe3BgbSuVkEoIiIiIr1bOIPKrAXeNLNXgH0PgmnaCTmonTv56/NBJh5VR3pqbI3omRiA/sl72Lp4GwV+hxERERER8VE4BeE6b0n2FpGu/fGPPJl2LadO2u13kk7l9N1D5bJaFYQiIiIi0qt1WRA652473M7NbCbwGyAAPOycu6vD+ynAn4BJQDVwkXOu3MyygNnAFOAx59yN7fZ5E8gHGrxN051z2w43o0SAc1Td+798sPt6vj1mhd9pOpWT2UzFmiam+h1ERERERMRHXRaEZpYDfBcYC+ybvM05d2YX+wWA+4FzgApgnpnNcc4ta9fsGmCnc26EmV0M/By4CGgEfgiM85aOLnPOlXaVXXzy3ns8X3c2J4ytJzUltm4X3Ssry1GxJuB3DBERERERX4UzqMyTwAqgBLgNKAfmhbHfVKDMObfWOdcMPA1c0KHNBcAfvfXZwFlmZs653c65fxEqDKWnee45/pr8ZU4cG7uzkwzMDlBRmw5tsTMdhoiIiIhItIVTEGY55/4AtDjn3nLOXQ0c9Oqgp4DQCKV7VXjbOm3jnGsFaoGsMPp+1MwWmdkPzczCaC/R4hx7/vJ33qkew5SjY2t00fZyBraxIWkEVFT4HUVERERExDfhFIR7J5HbbGbnmtlxwMAIZurKZc65Y4Bp3vKfnTUys2vNrNTMSquqqqIasFdbvpw3aicyqqiBjLTYvfqWO6CF8sAwWLvW7ygiIiIiIr4JpyC83cwygf8CvgM8DHwrjP0qgSHtXhd62zptY2aJQCahwWUOyDlX6X2tA56CzscFcc496Jyb7JybnJOTE0Zc6RZ//Stz+l/BlNGxe3UQoCC7iXWtQzQ5vYiIiIj0al0WhM65F51ztc65Jc65M5xzk5xzc8Loex4w0sxKzCwZuBjouN8c4Epv/ULgdeecO1CHZpZoZtneehJwHrAkjCwSJW72c7y44yROHBO7zw9CaHL6XW19qV+hW0ZFREREpPfqsiA0s1+YWT8zSzKz18ysyswu72o/75nAG4FXgeXAn51zS83sJ2Z2vtfsD0CWmZUB3wZmtTtuOfAr4CozqzCzMUAK8KqZfQIsInSF8aFD+LwSSZs28cnqVAIpiQzJbfI7zUElJEBhxi7WfFzvdxQREREREd+EMzH9dOfcd83sPwiNMPoF4G3gia52dM69DLzcYdut7dYbgS8dYN/iA3Q7KYzM4oeXX+ZveddwQuEuesJQPwVZjZStMY71O4iIiIiIiE/CeYZwb9F4LvCsc642gnmkJ3vnHV6oP4vjR8f27aJ7DcoLUrYl3e8YIiIiIiK+CacgfNHMVhC6MveaN1G95geUT9n2Xhkrawcxfvhuv6OEZXA+rNwzBPbs8TuKiIiIiIgvwhlUZhZwEjDZOdcC7OHTE8xLb1dXxysbxjLl6HqSEg84LlBMKchpZnXyWFizxu8oIiIiIiK+COcKIc65Hc65Nm99t3NuS2RjSY8zfz4v9Lko5qebaK8gp5k1rgRWrfI7ioiIiIiIL8IqCEW60vxeKa/tOZHje1BBmNO/mR2t/WhYprkIRURERKR3OmBBaGYne19TohdHeqp3Xt7F0IG7GJDR6neUsAUSYHBGHWtLd/gdRURERETEFwe7Qniv9/X9aASRnu3tjzM5dmTPG5ylYGAjZSt6ThErIiIiItKdDjYPYYuZPQgUmNm9Hd90zn09crGkR9m8mcWNRzG2pOfdgZw/qI2yT1L9jiEiIiIi4ouDFYTnAWcDM4D50YkjPdK8eSxNnMC5+T3vCmF+vrHyoyLYtQv69fM7joiIiIhIVB2wIHTObQeeNrPlzrmPo5hJepimd0spb/4MQ3KX+R3lkBXkNPNy8jhYvRomTfI7joiIiIhIVIVzj1+1mT1vZtu85TkzK4x4MukxVr2zlYLMepJ7yPyD7RVkN7EmqKknRERERKR3CqcgfBSYAwz2lr9520QAWLo6mZJBjX7HOCyDBjSzrWUgTcs0Ob2IiIiI9D7hFIS5zrlHnXOt3vIYkBPhXNJTNDWxZEc+Qwp73tVBgEAABqXXsW7BTr+jiIiIiIhEXTgF4XYzu9zMAt5yOVAd6WDSQ5SV8XHKVIbmN/ud5LAVZjVStrLN7xgiIiIiIlEXTkF4NfBlYAuwGbgQ+EokQ0kPsnIly9xoSvIb/E5y2AblBSmrTAXXM69yioiIiIgcroNNOwGAc249cH4UskgP1LikjMrm8yjMqfI7ymHLH+RY1TYcqqshO9vvOCIiIiIiUdPzZhKXmLLiw1qG9NtFYsDvJIevILuZVcljNdKoiIiIiPQ6KgjliCxZHqA4t+dNSN9eQY439cTy5X5HERERERGJKhWEcvicY0nlgB47wuhe+QOb2dSUTcuCxX5HERERERGJqi4LQjPLMrPfmtkCM5tvZr8xs6xohJMYt307nwTHUlzUs0foTEp05GbsYf28bX5HERERERGJqnCuED4NbAO+SGiE0SrgmUiGkh5ixQqW2ViK85v8TnLECnJbKFvR6ncMEREREZGoCqcgzHfO/dQ5t85bbgfyIh1MYt/uT9awpS2HgqyeXxDm5wUpaxkK23SVUERERER6j3AKwrlmdrGZJXjLl4FXIx1MYt/y93YyNGMHgR48wuhe+VnNrEqfCIv1HKGIiIiI9B4HLAjNrM7MdgFfBZ4Cmr3laeDa6MSTWLZ0cZDi7Hq/Y3SLguwmVthoFYQiIiIi0qscsCB0zmU45/p5XxOcc4nekuCc6xfNkBKbFm/oR1FBzx5QZq+jChuYXzcSt3CR31FERERERKImMZxGZnY+cKr38k3n3IuRiyQ9QjDIJ7uKObXY/E7SLXL6t5CS7Fg1r5ZRfocREREREYmScKaduAv4BrDMW75hZndGOpjEuC1bWGZjKSmMn5E5xw3bw7trBkEw6HcUEREREZGoCGdQmc8C5zjnHnHOPQLMBM6NbCyJdXVLN1DtBjIoq9nvKN1m9PBm/hU4Ddat8zuKiIiIiEhUhFMQAvRvt54ZgRzSwyx7v5aStK0Ewj2DeoBjSnbzL3eyBpYRERERkV4jnGcI7wAWmtkbgBF6lnBWRFNJzFv6cStD++30O0a3KslvYHNrEdXvryLr836nERERERGJvINe3zGzBCAInAD8BXgOONE590wUskkMKyuD/IE9f0L69gIJMHZQNe/NjY+pNEREREREunLQgtA5FwS+65zb7Jyb4y1bopRNYlj5lj7kZsff4CtHj2jjX8sGamAZEREREekVwnkC7J9m9h0zG2JmA/cuEU8mMa28dgB5+QG/Y3S7cUe38DbTYOlSv6OIiIiIiERcOAXhRcANwNvAfG8pjWQoiXHBIBubcsgtSvE7SbcbM3QPn7SNpenN9/2OIiIiIiIScV0WhM65kk6WYdEIJ7GpbdNWtjKInBy/k3S/tD5BivrVsuBvlX5HERERERGJuC5HGTWzPsD1wCmAA94Bfu+ca4xwNolRm+Zvpn8gmeRE53eUiBhT0sB785I40e8gIiIiIiIRFs4to38CxgK/Be7z1h+PZCiJbRsW7SC/T43fMSJmzGjHW/UTYfNmv6OIiIiIiERUOPMQjnPOjWn3+g0zWxapQBL71i/fQ276Hr9jRMy44Xv4PSfh/vVP7EsX+h1HRERERCRiwrlCuMDMTtj7wsyOR4PK9Gob1raQndnsd4yIyRvQQmKSsebF5X5HERERERGJqHAKwknAe2ZWbmblwPvAFDNbbGafHGxHM5tpZivNrMzMZnXyfoqZPeO9/6GZFXvbs8zsDTOrN7P7OuwzyTt2mZnda2YW7oeV7lFemUxudnw+P7jXuKJdvDt3N7j4/pwiIiIi0ruFc8vozMPp2MwCwP3AOUAFMM/M5jjn2t9ueg2w0zk3wswuBn5OaJqLRuCHwDhvae93wFeBD4GXvXyvHE5GOTzrdvbn1BPiuw4fPRrennssVy5aBMcdF95OjY1w551QVQWBAFx/fagjEREREZEY1WVB6Jxbf5h9TwXKnHNrAczsaeACoH1BeAHwY299NnCfmZlzbjfwLzMb0b5DM8sH+jnnPvBe/wn4PCoIo8c5NjbmkFfYArT5nSZipoyu59uvnMfOB+9kwO+6Lghbtu7gb6f9ksUNw1ma/HmWVeXQ738289qSjaQeNSQKiUVEREREDl04t4wergJgY7vXFd62Tts451qBWiCriz4ruuhTIsht3cZGV0hent9JImtIbhOnjN3Jj/9YDK2tB23rtm7j6pHv8MPN11N21LmMPH4gN12zm9Tcfnz/+H9AdXV0QouIiIiIHKJIFoS+MrNrzazUzEqrqqr8jhM3apdV4iyB9NT4vTq415X/UcvjTRex8rH3D9yotZXvTX6VRQkT+X/fr+aac7dwzuSdjBrSwNe/1swTDV/knS/dG73QIiIiIiKHIJIFYSXQ/l65Qm9bp23MLBHIBA52OaXS6+dgfQLgnHvQOTfZOTc5JyfnEKPLgWxYtIP8lB30hqF8+qe3cdGYT/jWrekHbPPAOc/z1Lazuf3b1fRJ3n8Amsz0Nr7+pc1c+eZX2P3JmkjHFRERERE5ZJEsCOcBI82sxMySgYuBOR3azAGu9NYvBF537sDDOjrnNgO7zOwEb3TRK4AXuj+6HMj65XvI7Vvvd4yo+Y8vGEu25PCPB9d96r0XbpjLj98+gztvrCSzX+f7nzKpkVH5tdx80YYIJxUREREROXQRKwi9ZwJvBF4FlgN/ds4tNbOfmNn5XrM/AFlmVgZ8G9g3NYU3xcWvgKvMrMLMxnhvXQ88DJQBa9CAMlG1YU0LOekNfseImuQB6Vw7bTnfuKGV1i3bAVi7Fn543kKu/t1kfnrFagYPOfjYTDdctYfnV47htWe2RyOyiIiIiEjY7CAX5OLG5MmTXWlpqd8x4sLNR71ATd/BXHZlkt9RosY5uPmn/ZiQtIRVGZNZWpHJWbzGuVdkMXRM37D6+OCRpTy0YQard2STELdP7oqIiIhIrDKz+c65yR2361dTOSTl29PJzfU7RXSZwQ3XNLLOhnNW4ps8fcbvuf7mvmEXgwDHX5CP1e3i7X82RzCpiIiIiMihCWdiepF91tcP5NT8oN8xoq6koJkfzgIY4y2HxrIGMjN7Pg/+JMDp04d2dzwRERERkcOiK4QSvtZWNrbkk1vYe24X7U7nnLKHFz/IoabG7yQiIiIiIiEqCCVszes3U00W2QN63xXC7pA59Wim8BH/+2Cd31FERERERAAVhHIIKhZsIztxJ4GA30l6qJQUZgwv48Hf9J5RWkVEREQktqkglLBtWFzLoD61fsfo0Sad3o8t24yPP/Y7iYiIiIiICkI5BOtXNZGbvtvvGD1a4KjhzAi8xkO/2OF3FBERERERFYQSvg3lbWT307QJRyQQYOaELTz1l1QaG/0OIyIiIiK9nQpCCVv5phRyB7b5HaPHG3T8UEayir8+7/yOIiIiIiK9nApCCdu6nZnk5amIOWLFxcxIfJ0H79HttyIiIiLiLxWEEraNe7LJLdAchEfMjFMmNbDgkwCbNvkdRkRERER6MxWEEhbX2ERFMJ+8wYl+R4kLyRPHcUrCezz9tK64ioiIiIh/VBBKWLYv3kyKtZDW1/yOEh+GDOGMlPd54sE9ficRERERkV5MBaGEZcPCagYla6qEbmPGhMkBKjY4Vq3yO4yIiIiI9FYqCCUs65fWk5e6y+8YcSUwcQKnuzd46smg31FEREREpJdSQShh2VDWTE6GJs7rVvn5nJExjycebsLpUUIRERER8YEKQgnLuvVGTqYmpe9uR0/pR3NtA/Pn+51ERERERHojFYQSlvJtaeRm69bG7mYTj+PMlld54k9tfkcRERERkV5IBaGEZUPdAPIGB/yOEX+ysjgzZzFPP95Km2pCEREREYkyFYQSlo1NueQVag7CSCiaksfAYBVvveV3EhERERHpbVQQSpcattVR5zIYkJvsd5T4NHEipze8whOPtvidRERERER6GRWE0qUN87aSF6giIaBJ6SMiI4Mzhq3nL39x7NE89SIiIiISRSoIpUsbPqkhr0+t3zHiWs6UEsYmreYvf/E7iYiIiIj0JioIpUsbVuwht+9uv2PEt2OO4ZyGOTz8QJPfSURERESkF1FBKF0qX9tGToYKlYhKTuakY+v5ZJFj3Tq/w4iIiIhIb6GCULpUXplMzgANeBJpyZPGc2byOzz6qN9JRERERKS3UEEoXSqvTmfQIA0oE3EjRjAz+AqP/k8zwaDfYURERESkN1BBKF3auCeLXE1KH3mBACNOyCa9ZSevv+53GBERERHpDVQQykEF2xybW3PJHZLid5TeYdIkpje8wEMP6hKhiIiIiESeCkI5qC3LdpBhdaSka1L6qMjL48y8JbzyYhs7d/odRkRERETinQpCOagNC6oYlLTD7xi9SuaUUUxNX8bTT/udRERERETinQpCOaj1S+rIS93ld4zeZeJEptfO5sEHWv1OIiIiIiJxTgWhHNSG1U1kpzf4HaN3SU1l0vhmqjY2MG+e32FEREREJJ6pIJSDWleeQE5ms98xep3A8VM4117mvt86v6OIiIiISBxTQSgHVb4lhbwcFSVRN3w4n038B3/9SxvV1X6HEREREZF4pYJQDmpDbSZ5g3WaRJ0ZmccfzUn9l/OHP/gdRkRERETilX7Tl4OqaMwhT3MQ+mPKFD63/VHuvy9IUNMSioiIiEgEqCCUA9pVWUcTyfTLS/U7Su+UmcnoUUH6Ntfw97/7HUZERERE4pEKQjmgDR9sIj+xCkswv6P0WjbtFM5rms1vNbiMiIiIiERARAtCM5tpZivNrMzMZnXyfoqZPeO9/6GZFbd77xZv+0ozm9Fue7mZLTazRWZWGsn8vd2GRTs0B6Hfhg/nzLQP+eBfraxb53cYEREREYk3ESsIzSwA3A98BhgDXGJmYzo0uwbY6ZwbAdwD/NzbdwxwMTAWmAk84PW31xnOuQnOucmRyi+wYcUectP3+B2jdzOjzymTmZH+Hg884HcYEREREYk3kbxCOBUoc86tdc41A08DF3RocwHwR299NnCWmZm3/WnnXJNzbh1Q5vUnUVS+Nkh2ZovfMWTSJD6360keeaiNujq/w4iIiIhIPIlkQVgAbGz3usLb1mkb51wrUAtkdbGvA+aa2XwzuzYCucVTvjmZ3GwNb+m75GQKTilhYtoKfvc7v8OIiIiISDzpiYPKnOKcm0joVtQbzOzUzhqZ2bVmVmpmpVVVVdFNGCfKa/qTNzjQdUOJvNNO4+Ka3/P/ftFKQ4PfYUREREQkXkSyIKwEhrR7Xeht67SNmSUCmUD1wfZ1zu39ug14ngPcSuqce9A5N9k5NzknJ+eIP0yv4xwbG3PIK+rjdxIBSEtj+OlDODphFQ895HcYEREREYkXkSwI5wEjzazEzJIJDRIzp0ObOcCV3vqFwOvOOedtv9gbhbQEGAl8ZGZ9zSwDwMz6AtOBJRH8DL1Wy5ZqqlwOOYN64kXkODVtGpfsfphf/KyF5ma/w4iIiIhIPIjYb/veM4E3Aq8Cy4E/O+eWmtlPzOx8r9kfgCwzKwO+Dczy9l0K/BlYBvwduME51wbkAf8ys4+Bj4CXnHOasjsCNs2rZGCglkTdMRo7UlM5+uwhFDau5k9/1LyEIiIiInLkLHRBLr5NnjzZlZZqysJD8c5P3uCmXwzh17fX+x1F2mtr45NfvMKv2r5B2ZYMEhP9DiQiIiIiPYGZze9s2j7dDyidWr9sN7npu/2OIR0FAoy/4jiyatby9AM7/E4jIiIiIj2cCkLp1NqyNnI0B2FsKijgkuNWcNusPbQ0tPqdRkRERER6MBWE0qklGzMpytfIJbFq0kUjyEnYwT1nveh3FBERERHpwVQQSqeW7iyguMT8jiEHYIkBbvhaG3d9eDobb3vE7zgiIiIi0kOpIJRPaa1vZE3LEIYeleJ3FDmIgkLj86dUc9Mdg+DJJ/2OIyIiIiI9kApC+ZSy1zeQG9hBn1SdHrHu4vPqWZB+Ki9f/yI895zfcURERESkh9Fv/PIpS9/aTnF6ld8xJAzJSY4bv7SVG5IepOHab8Arr/gdSURERER6EBWE8ilLFjRTNEDzD/YUU4+uY1hRKz+b8jxcfjl89JHfkURERESkh1BBKJ+yuCyVoYOa/I4hh+Br52/igfcmsPDSu+Fzn4PVq/2OJCIiIiI9gApC+ZSlVTkUD9Op0ZPk9G/h/56/iUteuIiGi66C88+HPXv8jiUiIiIiMU6/9ct+WpqCrGsaTNGoVL+jyCE6e9JOCnOa+O7Gm6CoCG66ye9IIiIiIhLjVBDKfla/s4W8hCpS+mnKiZ7GDL7xxUpmv53D3Gk/hX/+E556yu9YIiIiIhLDVBDKfpa+WUVx2ja/Y8hhykhr4+aLN3LVPcdS/c2fwte/Dps3+x1LRERERGKUCkLZz5LSRooG1PkdQ47AxJH1nDahhmue+wxu5mfghhv8jiQiIiIiMUoFoexn8cpkhuY1+h1DjtBXPrOFVRvT+HXf78OCBfDCC35HEhEREZEYpIJQ9rN0SxbFxeZ3DDlCyYmOW69czx3PDOOdz/0Crr8e6nTlV0RERET2p4JQ9mluhvLGPI0wGicGDWzm5os38uWnLmDTUafDbbf5HUlEREREYowKQtln1Qc7GGxbSM7K8DuKdJOpR9fx2eOr+ULlvTT/4XFYtszvSCIiIiISQ1QQyj5LXyqnOH17aP4CiRuXnb2NxJQA3y56NnTrqHN+RxIRERGRGKGCUPZZ8t4uhuQ0+B1DullCAvz3JRt5cesU7lt2huYmFBEREZF9VBDKPp+sSKK4SFeP4lFGWht3/J91/KThZl64YS7s2OF3JBERERGJASoIJcQ5lu0YRPEYDSgTrwZnN/OTr27k6j338eEV9/sdR0RERERigApCAaBp2Ro2BAspLEnyO4pE0NFFDXznkgrOf+VrlP3pPb/jiIiIiIjPVBAKACvnrKSgTzXJibplNN6deFwTl5+8jhlXF7BlyXa/44iIiIiIj1QQCgBL36yieOAuv2NIlHzuC8mcPnQtZ56wm+rt+iOAiIiISG+lglAAeG9hKsOKWv2OIVF0+f/tx3GJizl7/FZqa/1OIyIiIiJ+UEEoBBubmV11GqecGPQ7ikSRJQb4P1/vy7Cd85lx3FZ27/Y7kYiIiIhEmwpC4b0/riY9qZHiIhWEvY0NHMAN30omq/ITPjtZVwpFREREehsVhMIzD9Vy6pByv2OITxJyc/j211vJWlfKlJIqVi3TrcMiIiIivYUKwl4uGIRnFx3FaSerCOjNAgX5fP0HmZyfMpeTjq3n779b63ckEREREYkCFYS93LtPrSeTWoomDPQ7ivgtPZ3zbh7Nj076J1fckMGdx/2Z5sUr/U4lIiIiIhGkgrCXe/q+Kk4pXAcJOhUESEjgmP8YwX03b2BO5USKjh3AT4c9yvbHX4GWFr/TiYiIiEg3UxXQi7W1wez5JZx2YrPfUSTG5OYHuPN79dz5rW18lHA8w686hav6PccjM56h9OkyGhr8TigiIiIi3SHR7wDin3/9ZRsDgrUUTc7zO4rEqJIhrfzXjXB13Xpee2sCzy5p5BeXQ3mwiYL+uxlcnMygYX0ZlG/k5UFqKqSkQHIyJCWF/ujQ2vrvxSx0MToh4d/rgcC/twUC/14SEyEtDdLT/71kZcGAAbqgLSIiItJdVBD2Yk//ahPTBm+BwCC/o0iMG5DRyoXntcJ5QHAXLatfpHLBVqpXbmfnsjR2DjqaFf2G0JI+kNbUDFqT02hNSCIQsP2KPgDnQoMZObf/ejAIwbYgwcYWgk0ttLUEaWo2GloCNLQms7spQG2tsWcP9O8POTlQXAyjRsFRR4W+Tp0aKhxFREREJDzmnPM7Q8RNnjzZlZaW+h0jprTV1pM/oJFfXb2YwnED/I4jPVlNDaxdC5s3Q1VVaKmpCT1z2K8fZGZCRkaoUktNDV0+NAtdMmxuhtra0LJjR+hrWlqofUpKqP+9bVpaoKSE1pGj2TVyEjsGj2VzwwAqKmDLFti4EVauhGOOgenT4Zxz4KSTQsWoiIiISG9nZvOdc5M7btcVwl7q7W89T1bqaSoG5cj17w8TJ356e1MT7N4NdXXQ0AB79oSKwJaW0CXBvfeFjhgBffv+u3A8UAXX0ACVlSRu3MjA155l4Jq7GNGvH0yYAMcdBxeNpXFAPkuWGgsWwJ//HKpLL7kE/vM/Q03MIvh9EBEREemBdIWwF9pVvoNTR1RyxtmJXDCzye84IocnGAxdlSwrgw0bQlcpg0EoKQkVmUVFbEgo5rWVhbw+vx9pfRO4/HK49PIEhg/3O7yIiIhIdB3oCqEKwl6msRGmDy8jK1jF17+bqismEj+cC91aumlTaNm5M3Qbal0drq6epQ0lvNlyMm9yBiWB9Vze96+clz+f4UUtMHIkjB4N48eHLiVmZPj9aURERES6lS8FoZnNBH4DBICHnXN3dXg/BfgTMAmoBi5yzpV7790CXAO0AV93zr0aTp+dUUEY0toKX5xQxu6yLdxyiyOQqV96pZdxjtbGVhasSOWtTwYyr2wAaYlNTB+8hBl932XyrtcpWv8ONqQQpkyBE06AY48NPZg4QLdXi4iISM8V9YLQzALAKuAcoAKYB1zinFvWrs31wHjn3NfM7GLgP5xzF5nZGOB/ganAYOCfwFHebgftszMqCMEFHdectJylCxr56c27SM7p73ckEd85B+s296F0VQafrEmnrDKV3Y0JjMrdybi+5QxtLSOvfi251cvJ7bOLzKH9SR+eR8bRBaSPHkLq2GHYUSM1tKmIiIjEPD8GlZkKlDnn1noBngYuANoXbxcAP/bWZwP3mZl52592zjUB68yszOuPMPqUdqq2OebcvZKnHqxja0Mmd3+zluQcXekQgdAgM8MGNzJscCNfPr0KgLo9Acq39GHdlkGsry3kkz1nU5OTSE0t7N4EDWuN3S8lsrslmRaXSB8a6WM1pCa10CcF+qQlkJKWQJ/0RNIzA2QOCNBvYCKZAxPIzjZysh052Y7c7CBZA4IMHAgDBhqJKQFNsCgiIiJRF8mCsADY2O51BXD8gdo451rNrBbI8rZ/0GHfAm+9qz7jX1sbNU+8yNN/709zawKtLY62Vkfd7gSqdyVSvTPA9tokPtg5it0ujQLSOalgB+dP38aGygSorPX7E4jEtGRgVBKQffB2QWc0tybQtLOBxh27aa7ZQ8uuRpq3ttC0ro1GUthDX7aRxjrSqSODWjKpoT87GUAryZ32awRJp55UGkhjz76lD42hJaGZPoEWkhIdiYkQSEwgMclISAxN+miBBMzAmREMWmieRwetbQm0BhNocQFaXYCWYCJNLolmQsVtK4kECRC0AEESSEiApMQgyYmO5MQgKUlBUpPb9i19kttISQzuey8x4DBzGI4EA+dcaL5Jb65JnMMFHW5voPYTUu73+R1mofo4IQAJCUaCudDrhFDfhsMIYt7+5h3E6NBXgrG3M2cJkGA4C4Dt7SEBt7c3Z7Q5o7UtgTZntAVD36/WNtv3OhQ71N45vFyhTIGEIIkJjsSE0PcikBAkYI5AQmhJsNDn8vb2ziFwLnTsYBBa22y/pbkldI41t4TWW9oSaGn3fjDo7et9Gw3nfaLQJ0tKaCMpoZVEC5IcaCM5oZXkRO/fLcmRGHAkJTkSA958oQHb971vn3Pf99e1+zcL/aN2/n8O8/64kWCh9X3/oN7rjl9D3xi8//HaG0yaHJquRkQkyjreRLn3dfuv++ZRDnaYVzm4//57x+wI/Rz797Lvv7f276V9+/ZjfXSWp2OWjnnaZwop6HTy8biddsLMrgWu9V42mdkSP/N0pz6QnM+AY9YxrMu2KTSyHefmVMKc2VEIJ51qYycBdGVW/i3gLXsFCRAkwUK/xidQB9QdaOegt7QcyhGrgJzDiSrSTQ7jHHw8IkGk19J/B8Vvfp+DjQWdbY1kQVgJDGn3utDb1lmbCjNLBDIJDS5zsH276hMA59yDwIMAZlba2f2yItFiZqUtbpPOQfFN6L+D63UOim90DorfdA6K32L1HIzkAyvzgJFmVmJmycDFwJwObeYAV3rrFwKvu9AoN3OAi80sxcxKgJHAR2H2KSIiIiIiImGI2BVC75nAG4FXCd0Z9YhzbqmZ/QQodc7NAf4APO4NGrODUIGH1+7PhAaLaQVucM61AXTWZ6Q+g4iIiIiISDzrFRPTm9m13i2kIr7QOSh+0zkoftM5KH7TOSh+i9VzsFcUhCIiIiIiIvJpmvRKRERERESkl4rrgtDMZprZSjMrM7NZfueR+GRmj5jZtvZTm5jZQDP7h5mt9r4O8Labmd3rnZOfmNlE/5JLvDCzIWb2hpktM7OlZvYNb7vOQ4kKM+tjZh+Z2cfeOXibt73EzD70zrVnvAHh8AaNe8bb/qGZFfv6ASRumFnAzBaa2Yvea52DEjVmVm5mi81skZmVetti/mdx3BaEZhYA7gc+A4wBLjGzMf6mkjj1GDCzw7ZZwGvOuZHAa95rCJ2PI73lWuB3Ucoo8a0V+C/n3BjgBOAG7793Og8lWpqAM51zxwITgJlmdgLwc+Ae59wIYCdwjdf+GmCnt/0er51Id/gGsLzda52DEm1nOOcmtJvyLuZ/FsdtQQhMBcqcc2udc83A08AFPmeSOOSce5vQKLntXQD80Vv/I/D5dtv/5EI+APqbWX5Ugkrccs5tds4t8NbrCP0yVIDOQ4kS71yq914meYsDzgRme9s7noN7z83ZwFlmZtFJK/HKzAqBc4GHvdeGzkHxX8z/LI7ngrAA2NjudYW3TSQa8pxzm731LUCet67zUiLKu+3pOOBDdB5KFHm36i0CtgH/ANYANc65Vq9J+/Ns3znovV8LZEU1sMSjXwPfBYLe6yx0Dkp0OWCumc03s2u9bTH/szhi8xCKSIhzzpmZhvOViDOzdOA54JvOuV3t/9it81AizZsveIKZ9QeeB472N5H0JmZ2HrDNOTffzE73OY70Xqc45yrNLBf4h5mtaP9mrP4sjucrhJXAkHavC71tItGwde9lf+/rNm+7zkuJCDNLIlQMPumc+4u3WeehRJ1zrgZ4AziR0C1Qe//43P4823cOeu9nAtXRTSpx5mTgfDMrJ/SY0JnAb9A5KFHknKv0vm4j9IexqfSAn8XxXBDOA0Z6o0slAxcDc3zOJL3HHOBKb/1K4IV226/wRpY6AahtdxuByGHxnnv5A7DcOferdm/pPJSoMLMc78ogZpYKnEPoWdY3gAu9Zh3Pwb3n5oXA604TI8sRcM7d4pwrdM4VE/qd73Xn3GXoHJQoMbO+Zpaxdx2YDiyhB/wsjuuJ6c3ss4TuJw8AjzjnfuZvIolHZva/wOlANrAV+BHwV+DPQBGwHviyc26H94v7fYRGJd0DfMU5V+pDbIkjZnYK8A6wmH8/O/M9Qs8R6jyUiDOz8YQGSwgQ+mPzn51zPzGzYYSu1gwEFgKXO+eazKwP8Dih5113ABc759b6k17ijXfL6Hecc+fpHJRo8c61572XicBTzrmfmVkWMf6zOK4LQhERERERETmweL5lVERERERERA5CBaGIiIiIiEgvpYJQRERERESkl1JBKCIiIiIi0kupIBQREREREemlVBCKiEiPZmb1Eehzgjd10d7XPzaz7xxBf18ys+Vm9kb3JDzsHOVmlu1nBhERiS0qCEVERD5tAvDZrhodgmuArzrnzujGPkVERI6YCkIREYkbZnazmc0zs0/M7DZvW7F3de4hM1tqZnPNLNV7b4rXdpGZ3W1mS8wsGfgJcJG3/SKv+zFm9qaZrTWzrx/g+JeY2WKvn597224FTgH+YGZ3d2ifb2Zve8dZYmbTvO2/M7NSL+9t7dqXm9mdXvtSM5toZq+a2Roz+5rX5nSvz5fMbKWZ/d7MPvXz3swuN7OPvL7+x8wCR/jtFxGRHkgFoYiIxAUzmw6MBKYSusI3ycxO9d4eCdzvnBsL1ABf9LY/ClznnJsAtAE455qBW4FnnHMTnHPPeG2PBmZ4/f/IzJI6HH8w8HPgTO/4U8zs8865nwClwGXOuZs7xL4UeNU7/rHAIm/7951zk4HxwGlmNr7dPhu89u8AjwEXAicAt7VrMxW4CRgDDAe+0CHraOAi4OR2n/0yRESk11FBKCIi8WK6tywEFhAq4EZ6761zzi3y1ucDxWbWH8hwzr3vbX+qi/5fcs41Oee2A9uAvA7vTwHedM5VOedagSeBUzt20sE84Ctm9mPgGOdcnbf9y2a2wPssYwkVdnvN8b4uBj50ztU556qAJu8zAXzknFvrnGsD/pfQFcr2zgImAfPMbJH3elgXWUVEJA4l+h1ARESkmxhwp3Puf/bbaFYMNLXb1AakHkb/Hfs44p+hzrm3vauY5wKPmdmvCF35+w4wxTm308weA/p0kiPYIVOwXSbX8VAdXhvwR+fcLUf6GUREpGfTFUIREYkXrwJXm1k6gJkVmFnugRo752qAOjM73tt0cbu364CMQzz+R4Ru78z2nse7BHjrYDuY2VBgq3PuIeBhYCLQD9gN1JpZHvCZQ8wBMNXMSrxnBy8C/tXh/deAC/d+f8xsoJdFRER6GV0hFBGRuOCcm+s9G/e+mQHUA5fjPRt4ANcAD5lZkFDxVuttfwOY5d1OeWeYx99sZrO8fY3QLaYvdLHb6cDNZtbi5b3CObfOzBYCK4CNwLvhHL+DecB9wAgvz/Mdsi4zsx8Ac72isQW4AVh/GMcSEZEezJzreBeJiIhI72Bm6c65em99FpDvnPuGz7GOiJmdDnzHOXeez1FERKQH0BVCERHpzc41s1sI/TxcD1zlbxwREZHo0hVCERERERGRXkqDyoiIiIiIiPRSKghFRERERER6KRWEIiIiIiIivZQKQhERERERkV5KBaGIiIiIiEgvpYJQRERERESkl/r/N5ENXmWkZTIAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 观察训练数据集与测试数据集分布情况(分布基本一直)\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.subplot(111)\n",
    "sns.kdeplot(train['text_len'], ax=ax, color='red', fill=True)\n",
    "sns.kdeplot(test['text_len'], ax=ax, color='b', fill=True)\n",
    "ax.set_xlim([0, max(max(train['text_len']), max(test['text_len']))])\n",
    "plt.xlabel(\"length of sample\")\n",
    "plt.ylabel(\"prob of sample\")\n",
    "plt.legend(['train_text_len', 'test_text_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "166.0"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本长度大部分(99.5%)在166以内\n",
    "np.percentile(train['text_len'], q=99.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F5A9F54663E04B128FAD69A72EED6A06",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizerFast(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-chinese'\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "E1881286B22C461589B25C4BDAAD759D",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8E4F8C9456A0414F87BCD69332078B81",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((10800, 9), (600, 9), (600, 9))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(train, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class EnterpriseDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'texts': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "97EDA241BCE748728614E887629050D1",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = EnterpriseDataset(\n",
    "        texts=df['text'].values,\n",
    "        labels=df['label'].values,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0E70614960044063916BDB4A74F2E67B",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texts': ['指示标识不清楚[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；', '发现本月有灭火器过期，已安排购买灭火器更换[SEP]商贸服务教文卫类[SEP]消防检查[SEP]防火检查[SEP]灭火器材配置及有效情况。', '安全出口标志灯有一个有故障，已买回安装改正。[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；', '堵了消防通道[SEP]工业/危化品类[SEP]消防检查[SEP]防火巡查[SEP]安全出口、疏散通道是否畅通，安全疏散指示标志、应急照明是否完好；'], 'input_ids': tensor([[ 101, 2900, 4850, 3403, 6399,  679, 3926, 3504,  102, 2339,  689,  120,\n",
      "         1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125,\n",
      "         2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887,\n",
      "         3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403,\n",
      "         2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1355, 4385, 3315, 3299, 3300, 4127, 4125, 1690, 6814, 3309, 8024,\n",
      "         2347, 2128, 2961, 6579,  743, 4127, 4125, 1690, 3291, 2940,  102, 1555,\n",
      "         6588, 3302, 1218, 3136, 3152, 1310, 5102,  102, 3867, 7344, 3466, 3389,\n",
      "          102, 7344, 4125, 3466, 3389,  102, 4127, 4125, 1690, 3332, 6981, 5390,\n",
      "         1350, 3300, 3126, 2658, 1105,  511,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 2128, 1059, 1139, 1366, 3403, 2562, 4128, 3300,  671,  702, 3300,\n",
      "         3125, 7397, 8024, 2347,  743, 1726, 2128, 6163, 3121, 3633,  511,  102,\n",
      "         2339,  689,  120, 1314, 1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,\n",
      "          102, 7344, 4125, 2337, 3389,  102, 2128, 1059, 1139, 1366,  510, 4541,\n",
      "         3141, 6858, 6887, 3221, 1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141,\n",
      "         2900, 4850, 3403, 2562,  510, 2418, 2593, 4212, 3209, 3221, 1415, 2130,\n",
      "         1962, 8039,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 1843,  749, 3867, 7344, 6858, 6887,  102, 2339,  689,  120, 1314,\n",
      "         1265, 1501, 5102,  102, 3867, 7344, 3466, 3389,  102, 7344, 4125, 2337,\n",
      "         3389,  102, 2128, 1059, 1139, 1366,  510, 4541, 3141, 6858, 6887, 3221,\n",
      "         1415, 4517, 6858, 8024, 2128, 1059, 4541, 3141, 2900, 4850, 3403, 2562,\n",
      "          510, 2418, 2593, 4212, 3209, 3221, 1415, 2130, 1962, 8039,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0])}\n",
      "4\n",
      "torch.Size([4, 166])\n",
      "torch.Size([4, 166])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_data_loader:\n",
    "    print(data)\n",
    "    print(len(data['texts']))\n",
    "    print(data['input_ids'].shape)\n",
    "    print(data['attention_mask'].shape)\n",
    "    print(data['labels'].shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "744AC22398C44CA193AB6862B6D3F525",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "bert_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "F717B21056594C30AA9B6EAAEE2DF670",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EnterpriseDangerClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(EnterpriseDangerClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)  # 两个类别\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "C29305B6195244138AC6334074B8E080",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "EnterpriseDangerClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (drop): Dropout(p=0.3, inplace=False)\n  (out): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [0, 1]\n",
    "model = EnterpriseDangerClassifier(len(class_names))\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "C5D20F5457D74EC0A6FC1E45EE0CFC1F",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
    "    \"\"\"\n",
    "    Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after\n",
    "    a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "    Args:\n",
    "        optimizer ([`~torch.optim.Optimizer`]):\n",
    "            The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (`int`):\n",
    "            The number of steps for the warmup phase.\n",
    "        num_training_steps (`int`):\n",
    "            The total number of training steps.\n",
    "    Return:\n",
    "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # 学习率预热(线性增加)\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # 学习率线性衰减(最小为0)\n",
    "        # num_training_steps后学习率恒为0\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "EPOCHS = 10  # 训练轮数\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(total_steps / 10),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "F3A7C4E943F745638530A082A33607D7",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "        model,\n",
    "        data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        n_examples\n",
    "):\n",
    "    model = model.train()  # train模式\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"labels\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "07B61775682345F48F850C4220D55104",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()  # 验证预测模式\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "E9EF8438F0FC4C8CAD5A19AD09461C67",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.498337963949544 accuracy 0.8903703703703704\n",
      "Val   loss 0.4272330579161644 accuracy 0.9\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [81]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m train_acc, train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m accuracy \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     21\u001B[0m val_acc, val_loss \u001B[38;5;241m=\u001B[39m eval_model(\n\u001B[0;32m     22\u001B[0m     model,\n\u001B[0;32m     23\u001B[0m     val_data_loader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mlen\u001B[39m(df_val)\n\u001B[0;32m     27\u001B[0m )\n",
      "Input \u001B[1;32mIn [79]\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001B[0m\n\u001B[0;32m     25\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     26\u001B[0m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m)\n\u001B[1;32m---> 27\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     29\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:65\u001B[0m, in \u001B[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     64\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\optimization.py:360\u001B[0m, in \u001B[0;36mAdamW.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    357\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;66;03m# In-place operations to update the averages at the same time\u001B[39;00m\n\u001B[0;32m    359\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mmul_(beta1)\u001B[38;5;241m.\u001B[39madd_(grad, alpha\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m beta1))\n\u001B[1;32m--> 360\u001B[0m \u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[0;32m    361\u001B[0m denom \u001B[38;5;241m=\u001B[39m exp_avg_sq\u001B[38;5;241m.\u001B[39msqrt()\u001B[38;5;241m.\u001B[39madd_(group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    363\u001B[0m step_size \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = defaultdict(list)  # 记录10轮loss和acc\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98EF4DC4DB51475995A6A60C2A4C4E5C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25479A603E32438886CA8C0921D9F1DE",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = EnterpriseDangerClassifier(len(class_names))\n",
    "# model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66DECB3A065C4590BEC06632A252B3B4",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## 8 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFC3246AA92741A88AA94FE763C171C2",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5E3F47AF73514FA7BC7EE7F262BCA2BE",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "\n",
    "    raw_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            texts = d[\"texts\"]\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)  # 类别\n",
    "\n",
    "            probs = F.softmax(outputs, dim=1)  # 概率\n",
    "\n",
    "            raw_texts.extend(texts)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(probs)\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return raw_texts, predictions, prediction_probs, real_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AAE7B2F59834781925E338953F12BD2",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "    model,\n",
    "    test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6632B0B6ACC04AE685C40868F85AFF4A",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[str(label) for label in class_names]))  # 分类报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6B2B8C0B0C464960BCF677BAA4B9C062",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "    hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "    hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label');\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A09CE57FAE0D41B2B6E11760BB234133",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = 2\n",
    "\n",
    "sample_text = y_texts[idx]\n",
    "true_label = y_test[idx]\n",
    "pred_df = pd.DataFrame({\n",
    "    'class_names': class_names,\n",
    "    'values': y_pred_probs[idx]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40BC211A91494B6095C19117FA4E696E",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(wrap(sample_text)))\n",
    "print()\n",
    "print(f'True label: {class_names[true_label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BC7225D16DB4B0E9BC04D57EE0A04F1",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
    "plt.ylabel('sentiment')\n",
    "plt.xlabel('probability')\n",
    "plt.xlim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD8EC942665E49CA8880B29EA1BDB8D1",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## 9 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2CB82A2F814468A8FB31B6174F699E7",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_text = \"电源插头应按规定正确接线\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F36ECC0D21254FBBBD5A00E3A068D7AB",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode_plus(\n",
    "    sample_text,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F908DEA0481C406A982BE776EB00E5B9",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": "input_ids = encoded_text['input_ids'].to(device)\nattention_mask = encoded_text['attention_mask'].to(device)\n\noutput = model(input_ids, attention_mask)\n_, prediction = torch.max(output, dim=1)\n\nprint(f'Sample text: {sample_text}')\nprint(f'Danger label  : {class_names[prediction]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA87BB483C5F46F7BC87B517AE027657",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "file_extension": ".py",
   "version": "3.5.2",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}